{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled80.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMIDFRgk06nAxOL7vs37bJL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ykitaguchi77/Strabismus_AI_project/blob/main/5-fold%20crossvalidation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h5CVPFZ3z0ON"
      },
      "source": [
        "#**Strabismus 5-fold crossvalidation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-ropSQkzzmq"
      },
      "source": [
        "\"\"\"\n",
        "CSVを作成し、ファイル名-正解-予測を記載\n",
        "\n",
        "データを5分割（division1~5)\n",
        "set1: 1がtest、2~5がtrain\n",
        "set2: 2がtest、1、3~5がtrain\n",
        "set3:\n",
        "set4: \n",
        "set5: 5がtest、1~4がtrain\n",
        "それぞれのdivisionに、exoとcontのフォルダを置いておく\n",
        "\n",
        "各セットについてトレーニング→CSVに予測の結果を記載していく\n",
        "全てのデータが揃ったら、正解-予測のデータから、正解率、感度、特異度、ROC curveの計算を行う\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dyW4AJj14_og"
      },
      "source": [
        "#**Split dataset for Crossvalidation**\n",
        "trainセットを５分割、うち1つをvalセット、残りの合計をtestセットに分割"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "id": "PnyR-OC25V0Q",
        "outputId": "1afd2fe0-d02b-412f-8885-12fb9c712506"
      },
      "source": [
        "import random\n",
        "import glob\n",
        "import os\n",
        "import shutil\n",
        "import numpy as np\n",
        "import time\n",
        "import pandas as pd\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "'''\n",
        "-----orig_data-----grav\n",
        "                |--cont\n",
        "↓\n",
        "↓\n",
        "\n",
        "-----dst_data[0]------dst_train[0]----grav\n",
        "  |                |               |-- cont\n",
        "  |                |--dst_val[0]------grav\n",
        "  |                                |--cont\n",
        "  |\n",
        "  |--dst_data[1]------dst_train[1]----grav\n",
        "  |                |               |-- cont\n",
        "  |                |--dst_val[1]------grav\n",
        "  |                                |--cont\n",
        "  ...\n",
        "  |--dst_data[1]------dst_train[9]----grav\n",
        "                   |               |-- cont\n",
        "                   |--dst_val[9]------grav\n",
        "                                   |--cont\n",
        "'''"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n-----orig_data-----grav\\n                |--cont\\n↓\\n↓\\n\\n-----dst_data[0]------dst_train[0]----grav\\n  |                |               |-- cont\\n  |                |--dst_val[0]------grav\\n  |                                |--cont\\n  |\\n  |--dst_data[1]------dst_train[1]----grav\\n  |                |               |-- cont\\n  |                |--dst_val[1]------grav\\n  |                                |--cont\\n  ...\\n  |--dst_data[1]------dst_train[9]----grav\\n                   |               |-- cont\\n                   |--dst_val[9]------grav\\n                                   |--cont\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-XraZlu5a5d"
      },
      "source": [
        "def get_path(orig_path, dst_path, split_num):\n",
        "    classes = os.listdir(orig_path) #クラス名を取得\n",
        "    #データの分割数を設定\n",
        "    data_list = [0]*len(classes)\n",
        "    k=0\n",
        "    for i in classes:\n",
        "        data_list[k] = glob.glob(orig_path+'/'+i+'/*')\n",
        "        k+=1\n",
        "    split_length = int(len(data_list)/split_num)\n",
        "    return data_list, classes, split_length\n",
        "\n",
        "def makefolder(orig_path, dst_path, classes):\n",
        "    #フォルダを作成\n",
        "    if os.path.exists(dst_path):\n",
        "        shutil.rmtree(dst_path)\n",
        "        print(\"Existing dataset deleted.\")\n",
        "    elif not os.path.exists(dst_path):  # ディレクトリがなかったら\n",
        "        os.mkdir(dst_path)  # 作成したいフォルダ名を作成\n",
        "        for i in range(split_num):\n",
        "            os.mkdir(dst_path+'/'+str(i))\n",
        "            os.mkdir(dst_path+'/'+str(i)+'/train')\n",
        "            os.mkdir(dst_path+'/'+str(i)+'/val')\n",
        "            for j in classes:\n",
        "                os.mkdir(dst_path+'/'+str(i)+'/train/'+j)\n",
        "                os.mkdir(dst_path+'/'+str(i)+'/val/'+j)\n",
        "\n",
        "def split_data_list(data_list, split_num):\n",
        "    split_data, dst_data, dst_train, dst_val, dst_test = [0]*split_num, [0]*split_num, [0]*split_num, [0]*split_num, [0]*split_num\n",
        "\n",
        "    #データの分割\n",
        "    split_data = list(np.array_split(data_list, split_num))\n",
        "\n",
        "    #データセット全体と分割したデータの差分を取り、dst_dataに格納\n",
        "\n",
        "    dst_data = [0] * split_num\n",
        "    for i in range(split_num):\n",
        "        dst_data[i] = [x for x in data_list if x not in split_data[i]]\n",
        "\n",
        "    #トレーニングセット、バリデーションセット、テストセットのリスト作成\n",
        "    for i in range(split_num):\n",
        "        dst_train[i] = dst_data[i]\n",
        "        dst_val[i] = split_data[i]  #テストセット\n",
        "    \n",
        "    return dst_train, dst_val\n",
        "\n",
        "def copy_to_folders(split_num, class_name, dst_train, dst_val, dst_path):\n",
        "    k=0\n",
        "    for i in range(split_num):\n",
        "        dst_path_train = dst_path +'/'+str(i)+'/train/'+class_name\n",
        "        dst_path_val = dst_path +'/'+str(i)+'/val/'+class_name\n",
        "        for p in dst_train[k]:  # 選択したファイルを目的フォルダにコピー\n",
        "            shutil.copy(p, dst_path_train)\n",
        "            #print(p)\n",
        "            print(dst_path_train)\n",
        "\n",
        "        for p in dst_val[k]:  # 選択したファイルを目的フォルダにコピー\n",
        "            shutil.copy(p, dst_path_val)\n",
        "            #print(p)    \n",
        "            print(dst_path_val)\n",
        "\n",
        "        k+=1    "
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmDnaPiLHxm4"
      },
      "source": [
        "#パスの設定\n",
        "orig_path = \"/content/drive/MyDrive/Deep_learning/Strabismus/Dataset_250px_20211111\"\n",
        "dst_path = \"/content/drive/MyDrive/Deep_learning/Strabismus/Dataset_250px_shuffle_crossvalidation_eso\"  # フォルダ名\n",
        "csv_path = dst_path + \"/img_list.csv\""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JIxM04cGIfQo",
        "outputId": "f4c663e5-ce7d-4cb8-a886-b99d9807b825"
      },
      "source": [
        "#Dataの分割の設定\n",
        "split_num = 5  #データをいくつに分割するかを記載\n",
        "data_list, classes, split_length = get_path(orig_path, dst_path, split_num)\n",
        "print(classes)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['cont', 'eso', 'exo']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HnfDmSsjI8yX"
      },
      "source": [
        "#作成するデータのクラスを設定し直す\n",
        "#疾患群を後ろにする\n",
        "classes = ['cont', 'eso']"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHp4Whs25lbn"
      },
      "source": [
        "#5-foldデータセットの作成\n",
        "#作成済みの場合には省略\n",
        "makefolder(orig_path, dst_path, classes)\n",
        "print(classes)\n",
        "k=0\n",
        "for i in range(len(classes)):\n",
        "    random.shuffle(data_list[k]) #shuffleをするときはこれを入れる\n",
        "    dst_train, dst_val = split_data_list(data_list[k], split_num)\n",
        "    print(classes[k])\n",
        "    copy_to_folders(split_num, classes[k], dst_train, dst_val, dst_path)\n",
        "    k+=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1SlzcdphHIA7"
      },
      "source": [
        "#**Make CSV file**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFwa0-VP-fR5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "7dddc42d-1efc-4ad0-895d-c2bfddc36de6"
      },
      "source": [
        "classes = os.listdir(dst_path+\"/0/val/\")\n",
        "split_num = 5\n",
        "img_num = len(glob.glob(dst_path+\"/*/val/*/*\"))\n",
        "#print(glob.glob(dst_path+\"/*/val/*/*\"))\n",
        "#print(img_num)\n",
        "\n",
        "#Make CSV file\n",
        "cols = [\"num\", \"division\", \"class\", \"prediction\"]\n",
        "df_cross = pd.DataFrame(index=list(range(img_num)), columns=cols)\n",
        "\n",
        "t=0\n",
        "for i in range(split_num):\n",
        "    for j in classes:\n",
        "        #print(str(i) + \", \"+str(j))\n",
        "        img_list = os.listdir(dst_path+\"/\"+str(i)+\"/val/\"+str(j))\n",
        "        #print(img_list)\n",
        "        for k in img_list:\n",
        "            df_cross.iloc[t,0]=str(k)\n",
        "            df_cross.iloc[t,1]=str(i)\n",
        "            df_cross.iloc[t,2]=str(j)\n",
        "            t+=1\n",
        "df_cross"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>num</th>\n",
              "      <th>division</th>\n",
              "      <th>class</th>\n",
              "      <th>prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5059.jpg</td>\n",
              "      <td>0</td>\n",
              "      <td>cont</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4484.jpg</td>\n",
              "      <td>0</td>\n",
              "      <td>cont</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1985.jpg</td>\n",
              "      <td>0</td>\n",
              "      <td>cont</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6768.jpg</td>\n",
              "      <td>0</td>\n",
              "      <td>cont</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1785.jpg</td>\n",
              "      <td>0</td>\n",
              "      <td>cont</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>659</th>\n",
              "      <td>1107.jpg</td>\n",
              "      <td>4</td>\n",
              "      <td>eso</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>660</th>\n",
              "      <td>1557.jpg</td>\n",
              "      <td>4</td>\n",
              "      <td>eso</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>661</th>\n",
              "      <td>21.jpg</td>\n",
              "      <td>4</td>\n",
              "      <td>eso</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>662</th>\n",
              "      <td>334.jpg</td>\n",
              "      <td>4</td>\n",
              "      <td>eso</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>663</th>\n",
              "      <td>2359.jpg</td>\n",
              "      <td>4</td>\n",
              "      <td>eso</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>664 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          num division class prediction\n",
              "0    5059.jpg        0  cont        NaN\n",
              "1    4484.jpg        0  cont        NaN\n",
              "2    1985.jpg        0  cont        NaN\n",
              "3    6768.jpg        0  cont        NaN\n",
              "4    1785.jpg        0  cont        NaN\n",
              "..        ...      ...   ...        ...\n",
              "659  1107.jpg        4   eso        NaN\n",
              "660  1557.jpg        4   eso        NaN\n",
              "661    21.jpg        4   eso        NaN\n",
              "662   334.jpg        4   eso        NaN\n",
              "663  2359.jpg        4   eso        NaN\n",
              "\n",
              "[664 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXnQMFDKL7gF"
      },
      "source": [
        "#CSV fileを保存\n",
        "csv = df_cross.to_csv(csv_path, encoding='utf_8_sig')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cRZtvJGoHZIp"
      },
      "source": [
        "#**Training & evaluation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZCjIXc4ULq1",
        "outputId": "41eb9881-9a79-43c4-eee7-6fbf4336500d"
      },
      "source": [
        "from __future__ import print_function, division\n",
        "!pip install torch_optimizer\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch_optimizer as optim\n",
        "import torch.utils.data as data\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "import math\n",
        "import shutil\n",
        "\n",
        "import glob\n",
        "import os.path as osp\n",
        "import random\n",
        "import json\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "%matplotlib inline\n",
        "\n",
        "import pandas as pd\n",
        "import csv\n",
        "\n",
        "#サポートパッチのインポート\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "\n",
        "plt.ion()   # interactive mode\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "!pip install efficientnet_pytorch\n",
        "from efficientnet_pytorch import EfficientNet \n",
        "\n",
        "import numpy as np\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch_optimizer\n",
            "  Downloading torch_optimizer-0.3.0-py3-none-any.whl (61 kB)\n",
            "\u001b[?25l\r\u001b[K     |█████▎                          | 10 kB 37.6 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 20 kB 25.4 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 30 kB 18.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 40 kB 16.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 51 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 61 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 61 kB 592 kB/s \n",
            "\u001b[?25hCollecting pytorch-ranger>=0.1.1\n",
            "  Downloading pytorch_ranger-0.1.1-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: torch>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from torch_optimizer) (1.10.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.5.0->torch_optimizer) (3.10.0.2)\n",
            "Installing collected packages: pytorch-ranger, torch-optimizer\n",
            "Successfully installed pytorch-ranger-0.1.1 torch-optimizer-0.3.0\n",
            "Collecting efficientnet_pytorch\n",
            "  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from efficientnet_pytorch) (1.10.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->efficientnet_pytorch) (3.10.0.2)\n",
            "Building wheels for collected packages: efficientnet-pytorch\n",
            "  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16446 sha256=37cb77366014d3baa687c8c77967cc65da2895cfe895b82fb9f3da97bea75c99\n",
            "  Stored in directory: /root/.cache/pip/wheels/0e/cc/b2/49e74588263573ff778da58cc99b9c6349b496636a7e165be6\n",
            "Successfully built efficientnet-pytorch\n",
            "Installing collected packages: efficientnet-pytorch\n",
            "Successfully installed efficientnet-pytorch-0.7.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YiozE-KzUZPp"
      },
      "source": [
        "#Module群\n",
        "\n",
        "#Define ResNet5-VGGFace\n",
        "class Resnet50_ft_dag(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Resnet50_ft_dag, self).__init__()\n",
        "        self.meta = {'mean': [131.0912, 103.8827, 91.4953],\n",
        "                     'std': [1, 1, 1],\n",
        "                     'imageSize': [224, 224, 3]}\n",
        "        self.conv1_7x7_s2 = nn.Conv2d(3, 64, kernel_size=[7, 7], stride=(2, 2), padding=(3, 3), bias=False)\n",
        "        self.conv1_7x7_s2_bn = nn.BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv1_relu_7x7_s2 = nn.ReLU()\n",
        "        self.pool1_3x3_s2 = nn.MaxPool2d(kernel_size=[3, 3], stride=[2, 2], padding=(0, 0), dilation=1, ceil_mode=True)\n",
        "        self.conv2_1_1x1_reduce = nn.Conv2d(64, 64, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv2_1_1x1_reduce_bn = nn.BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv2_1_1x1_reduce_relu = nn.ReLU()\n",
        "        self.conv2_1_3x3 = nn.Conv2d(64, 64, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
        "        self.conv2_1_3x3_bn = nn.BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv2_1_3x3_relu = nn.ReLU()\n",
        "        self.conv2_1_1x1_increase = nn.Conv2d(64, 256, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv2_1_1x1_increase_bn = nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv2_1_1x1_proj = nn.Conv2d(64, 256, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv2_1_1x1_proj_bn = nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv2_1_relu = nn.ReLU()\n",
        "        self.conv2_2_1x1_reduce = nn.Conv2d(256, 64, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv2_2_1x1_reduce_bn = nn.BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv2_2_1x1_reduce_relu = nn.ReLU()\n",
        "        self.conv2_2_3x3 = nn.Conv2d(64, 64, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
        "        self.conv2_2_3x3_bn = nn.BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv2_2_3x3_relu = nn.ReLU()\n",
        "        self.conv2_2_1x1_increase = nn.Conv2d(64, 256, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv2_2_1x1_increase_bn = nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv2_2_relu = nn.ReLU()\n",
        "        self.conv2_3_1x1_reduce = nn.Conv2d(256, 64, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv2_3_1x1_reduce_bn = nn.BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv2_3_1x1_reduce_relu = nn.ReLU()\n",
        "        self.conv2_3_3x3 = nn.Conv2d(64, 64, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
        "        self.conv2_3_3x3_bn = nn.BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv2_3_3x3_relu = nn.ReLU()\n",
        "        self.conv2_3_1x1_increase = nn.Conv2d(64, 256, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv2_3_1x1_increase_bn = nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv2_3_relu = nn.ReLU()\n",
        "        self.conv3_1_1x1_reduce = nn.Conv2d(256, 128, kernel_size=[1, 1], stride=(2, 2), bias=False)\n",
        "        self.conv3_1_1x1_reduce_bn = nn.BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv3_1_1x1_reduce_relu = nn.ReLU()\n",
        "        self.conv3_1_3x3 = nn.Conv2d(128, 128, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
        "        self.conv3_1_3x3_bn = nn.BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv3_1_3x3_relu = nn.ReLU()\n",
        "        self.conv3_1_1x1_increase = nn.Conv2d(128, 512, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv3_1_1x1_increase_bn = nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv3_1_1x1_proj = nn.Conv2d(256, 512, kernel_size=[1, 1], stride=(2, 2), bias=False)\n",
        "        self.conv3_1_1x1_proj_bn = nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv3_1_relu = nn.ReLU()\n",
        "        self.conv3_2_1x1_reduce = nn.Conv2d(512, 128, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv3_2_1x1_reduce_bn = nn.BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv3_2_1x1_reduce_relu = nn.ReLU()\n",
        "        self.conv3_2_3x3 = nn.Conv2d(128, 128, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
        "        self.conv3_2_3x3_bn = nn.BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv3_2_3x3_relu = nn.ReLU()\n",
        "        self.conv3_2_1x1_increase = nn.Conv2d(128, 512, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv3_2_1x1_increase_bn = nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv3_2_relu = nn.ReLU()\n",
        "        self.conv3_3_1x1_reduce = nn.Conv2d(512, 128, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv3_3_1x1_reduce_bn = nn.BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv3_3_1x1_reduce_relu = nn.ReLU()\n",
        "        self.conv3_3_3x3 = nn.Conv2d(128, 128, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
        "        self.conv3_3_3x3_bn = nn.BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv3_3_3x3_relu = nn.ReLU()\n",
        "        self.conv3_3_1x1_increase = nn.Conv2d(128, 512, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv3_3_1x1_increase_bn = nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv3_3_relu = nn.ReLU()\n",
        "        self.conv3_4_1x1_reduce = nn.Conv2d(512, 128, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv3_4_1x1_reduce_bn = nn.BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv3_4_1x1_reduce_relu = nn.ReLU()\n",
        "        self.conv3_4_3x3 = nn.Conv2d(128, 128, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
        "        self.conv3_4_3x3_bn = nn.BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv3_4_3x3_relu = nn.ReLU()\n",
        "        self.conv3_4_1x1_increase = nn.Conv2d(128, 512, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv3_4_1x1_increase_bn = nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv3_4_relu = nn.ReLU()\n",
        "        self.conv4_1_1x1_reduce = nn.Conv2d(512, 256, kernel_size=[1, 1], stride=(2, 2), bias=False)\n",
        "        self.conv4_1_1x1_reduce_bn = nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv4_1_1x1_reduce_relu = nn.ReLU()\n",
        "        self.conv4_1_3x3 = nn.Conv2d(256, 256, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
        "        self.conv4_1_3x3_bn = nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv4_1_3x3_relu = nn.ReLU()\n",
        "        self.conv4_1_1x1_increase = nn.Conv2d(256, 1024, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv4_1_1x1_increase_bn = nn.BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv4_1_1x1_proj = nn.Conv2d(512, 1024, kernel_size=[1, 1], stride=(2, 2), bias=False)\n",
        "        self.conv4_1_1x1_proj_bn = nn.BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv4_1_relu = nn.ReLU()\n",
        "        self.conv4_2_1x1_reduce = nn.Conv2d(1024, 256, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv4_2_1x1_reduce_bn = nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv4_2_1x1_reduce_relu = nn.ReLU()\n",
        "        self.conv4_2_3x3 = nn.Conv2d(256, 256, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
        "        self.conv4_2_3x3_bn = nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv4_2_3x3_relu = nn.ReLU()\n",
        "        self.conv4_2_1x1_increase = nn.Conv2d(256, 1024, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv4_2_1x1_increase_bn = nn.BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv4_2_relu = nn.ReLU()\n",
        "        self.conv4_3_1x1_reduce = nn.Conv2d(1024, 256, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv4_3_1x1_reduce_bn = nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv4_3_1x1_reduce_relu = nn.ReLU()\n",
        "        self.conv4_3_3x3 = nn.Conv2d(256, 256, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
        "        self.conv4_3_3x3_bn = nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv4_3_3x3_relu = nn.ReLU()\n",
        "        self.conv4_3_1x1_increase = nn.Conv2d(256, 1024, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv4_3_1x1_increase_bn = nn.BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv4_3_relu = nn.ReLU()\n",
        "        self.conv4_4_1x1_reduce = nn.Conv2d(1024, 256, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv4_4_1x1_reduce_bn = nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv4_4_1x1_reduce_relu = nn.ReLU()\n",
        "        self.conv4_4_3x3 = nn.Conv2d(256, 256, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
        "        self.conv4_4_3x3_bn = nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv4_4_3x3_relu = nn.ReLU()\n",
        "        self.conv4_4_1x1_increase = nn.Conv2d(256, 1024, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv4_4_1x1_increase_bn = nn.BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv4_4_relu = nn.ReLU()\n",
        "        self.conv4_5_1x1_reduce = nn.Conv2d(1024, 256, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv4_5_1x1_reduce_bn = nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv4_5_1x1_reduce_relu = nn.ReLU()\n",
        "        self.conv4_5_3x3 = nn.Conv2d(256, 256, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
        "        self.conv4_5_3x3_bn = nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv4_5_3x3_relu = nn.ReLU()\n",
        "        self.conv4_5_1x1_increase = nn.Conv2d(256, 1024, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv4_5_1x1_increase_bn = nn.BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv4_5_relu = nn.ReLU()\n",
        "        self.conv4_6_1x1_reduce = nn.Conv2d(1024, 256, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv4_6_1x1_reduce_bn = nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv4_6_1x1_reduce_relu = nn.ReLU()\n",
        "        self.conv4_6_3x3 = nn.Conv2d(256, 256, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
        "        self.conv4_6_3x3_bn = nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv4_6_3x3_relu = nn.ReLU()\n",
        "        self.conv4_6_1x1_increase = nn.Conv2d(256, 1024, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv4_6_1x1_increase_bn = nn.BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv4_6_relu = nn.ReLU()\n",
        "        self.conv5_1_1x1_reduce = nn.Conv2d(1024, 512, kernel_size=[1, 1], stride=(2, 2), bias=False)\n",
        "        self.conv5_1_1x1_reduce_bn = nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv5_1_1x1_reduce_relu = nn.ReLU()\n",
        "        self.conv5_1_3x3 = nn.Conv2d(512, 512, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
        "        self.conv5_1_3x3_bn = nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv5_1_3x3_relu = nn.ReLU()\n",
        "        self.conv5_1_1x1_increase = nn.Conv2d(512, 2048, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv5_1_1x1_increase_bn = nn.BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv5_1_1x1_proj = nn.Conv2d(1024, 2048, kernel_size=[1, 1], stride=(2, 2), bias=False)\n",
        "        self.conv5_1_1x1_proj_bn = nn.BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv5_1_relu = nn.ReLU()\n",
        "        self.conv5_2_1x1_reduce = nn.Conv2d(2048, 512, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv5_2_1x1_reduce_bn = nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv5_2_1x1_reduce_relu = nn.ReLU()\n",
        "        self.conv5_2_3x3 = nn.Conv2d(512, 512, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
        "        self.conv5_2_3x3_bn = nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv5_2_3x3_relu = nn.ReLU()\n",
        "        self.conv5_2_1x1_increase = nn.Conv2d(512, 2048, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv5_2_1x1_increase_bn = nn.BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv5_2_relu = nn.ReLU()\n",
        "        self.conv5_3_1x1_reduce = nn.Conv2d(2048, 512, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv5_3_1x1_reduce_bn = nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv5_3_1x1_reduce_relu = nn.ReLU()\n",
        "        self.conv5_3_3x3 = nn.Conv2d(512, 512, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
        "        self.conv5_3_3x3_bn = nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv5_3_3x3_relu = nn.ReLU()\n",
        "        self.conv5_3_1x1_increase = nn.Conv2d(512, 2048, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv5_3_1x1_increase_bn = nn.BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv5_3_relu = nn.ReLU()\n",
        "        self.pool5_7x7_s1 = nn.AvgPool2d(kernel_size=[7, 7], stride=[1, 1], padding=0)\n",
        "        self.classifier = nn.Conv2d(2048, 8631, kernel_size=[1, 1], stride=(1, 1))\n",
        "\n",
        "    def forward(self, data):\n",
        "        conv1_7x7_s2 = self.conv1_7x7_s2(data)\n",
        "        conv1_7x7_s2_bn = self.conv1_7x7_s2_bn(conv1_7x7_s2)\n",
        "        conv1_7x7_s2_bnxx = self.conv1_relu_7x7_s2(conv1_7x7_s2_bn)\n",
        "        pool1_3x3_s2 = self.pool1_3x3_s2(conv1_7x7_s2_bnxx)\n",
        "        conv2_1_1x1_reduce = self.conv2_1_1x1_reduce(pool1_3x3_s2)\n",
        "        conv2_1_1x1_reduce_bn = self.conv2_1_1x1_reduce_bn(conv2_1_1x1_reduce)\n",
        "        conv2_1_1x1_reduce_bnxx = self.conv2_1_1x1_reduce_relu(conv2_1_1x1_reduce_bn)\n",
        "        conv2_1_3x3 = self.conv2_1_3x3(conv2_1_1x1_reduce_bnxx)\n",
        "        conv2_1_3x3_bn = self.conv2_1_3x3_bn(conv2_1_3x3)\n",
        "        conv2_1_3x3_bnxx = self.conv2_1_3x3_relu(conv2_1_3x3_bn)\n",
        "        conv2_1_1x1_increase = self.conv2_1_1x1_increase(conv2_1_3x3_bnxx)\n",
        "        conv2_1_1x1_increase_bn = self.conv2_1_1x1_increase_bn(conv2_1_1x1_increase)\n",
        "        conv2_1_1x1_proj = self.conv2_1_1x1_proj(pool1_3x3_s2)\n",
        "        conv2_1_1x1_proj_bn = self.conv2_1_1x1_proj_bn(conv2_1_1x1_proj)\n",
        "        conv2_1 = torch.add(conv2_1_1x1_proj_bn, 1, conv2_1_1x1_increase_bn)\n",
        "        conv2_1x = self.conv2_1_relu(conv2_1)\n",
        "        conv2_2_1x1_reduce = self.conv2_2_1x1_reduce(conv2_1x)\n",
        "        conv2_2_1x1_reduce_bn = self.conv2_2_1x1_reduce_bn(conv2_2_1x1_reduce)\n",
        "        conv2_2_1x1_reduce_bnxx = self.conv2_2_1x1_reduce_relu(conv2_2_1x1_reduce_bn)\n",
        "        conv2_2_3x3 = self.conv2_2_3x3(conv2_2_1x1_reduce_bnxx)\n",
        "        conv2_2_3x3_bn = self.conv2_2_3x3_bn(conv2_2_3x3)\n",
        "        conv2_2_3x3_bnxx = self.conv2_2_3x3_relu(conv2_2_3x3_bn)\n",
        "        conv2_2_1x1_increase = self.conv2_2_1x1_increase(conv2_2_3x3_bnxx)\n",
        "        conv2_2_1x1_increase_bn = self.conv2_2_1x1_increase_bn(conv2_2_1x1_increase)\n",
        "        conv2_2 = torch.add(conv2_1x, 1, conv2_2_1x1_increase_bn)\n",
        "        conv2_2x = self.conv2_2_relu(conv2_2)\n",
        "        conv2_3_1x1_reduce = self.conv2_3_1x1_reduce(conv2_2x)\n",
        "        conv2_3_1x1_reduce_bn = self.conv2_3_1x1_reduce_bn(conv2_3_1x1_reduce)\n",
        "        conv2_3_1x1_reduce_bnxx = self.conv2_3_1x1_reduce_relu(conv2_3_1x1_reduce_bn)\n",
        "        conv2_3_3x3 = self.conv2_3_3x3(conv2_3_1x1_reduce_bnxx)\n",
        "        conv2_3_3x3_bn = self.conv2_3_3x3_bn(conv2_3_3x3)\n",
        "        conv2_3_3x3_bnxx = self.conv2_3_3x3_relu(conv2_3_3x3_bn)\n",
        "        conv2_3_1x1_increase = self.conv2_3_1x1_increase(conv2_3_3x3_bnxx)\n",
        "        conv2_3_1x1_increase_bn = self.conv2_3_1x1_increase_bn(conv2_3_1x1_increase)\n",
        "        conv2_3 = torch.add(conv2_2x, 1, conv2_3_1x1_increase_bn)\n",
        "        conv2_3x = self.conv2_3_relu(conv2_3)\n",
        "        conv3_1_1x1_reduce = self.conv3_1_1x1_reduce(conv2_3x)\n",
        "        conv3_1_1x1_reduce_bn = self.conv3_1_1x1_reduce_bn(conv3_1_1x1_reduce)\n",
        "        conv3_1_1x1_reduce_bnxx = self.conv3_1_1x1_reduce_relu(conv3_1_1x1_reduce_bn)\n",
        "        conv3_1_3x3 = self.conv3_1_3x3(conv3_1_1x1_reduce_bnxx)\n",
        "        conv3_1_3x3_bn = self.conv3_1_3x3_bn(conv3_1_3x3)\n",
        "        conv3_1_3x3_bnxx = self.conv3_1_3x3_relu(conv3_1_3x3_bn)\n",
        "        conv3_1_1x1_increase = self.conv3_1_1x1_increase(conv3_1_3x3_bnxx)\n",
        "        conv3_1_1x1_increase_bn = self.conv3_1_1x1_increase_bn(conv3_1_1x1_increase)\n",
        "        conv3_1_1x1_proj = self.conv3_1_1x1_proj(conv2_3x)\n",
        "        conv3_1_1x1_proj_bn = self.conv3_1_1x1_proj_bn(conv3_1_1x1_proj)\n",
        "        conv3_1 = torch.add(conv3_1_1x1_proj_bn, 1, conv3_1_1x1_increase_bn)\n",
        "        conv3_1x = self.conv3_1_relu(conv3_1)\n",
        "        conv3_2_1x1_reduce = self.conv3_2_1x1_reduce(conv3_1x)\n",
        "        conv3_2_1x1_reduce_bn = self.conv3_2_1x1_reduce_bn(conv3_2_1x1_reduce)\n",
        "        conv3_2_1x1_reduce_bnxx = self.conv3_2_1x1_reduce_relu(conv3_2_1x1_reduce_bn)\n",
        "        conv3_2_3x3 = self.conv3_2_3x3(conv3_2_1x1_reduce_bnxx)\n",
        "        conv3_2_3x3_bn = self.conv3_2_3x3_bn(conv3_2_3x3)\n",
        "        conv3_2_3x3_bnxx = self.conv3_2_3x3_relu(conv3_2_3x3_bn)\n",
        "        conv3_2_1x1_increase = self.conv3_2_1x1_increase(conv3_2_3x3_bnxx)\n",
        "        conv3_2_1x1_increase_bn = self.conv3_2_1x1_increase_bn(conv3_2_1x1_increase)\n",
        "        conv3_2 = torch.add(conv3_1x, 1, conv3_2_1x1_increase_bn)\n",
        "        conv3_2x = self.conv3_2_relu(conv3_2)\n",
        "        conv3_3_1x1_reduce = self.conv3_3_1x1_reduce(conv3_2x)\n",
        "        conv3_3_1x1_reduce_bn = self.conv3_3_1x1_reduce_bn(conv3_3_1x1_reduce)\n",
        "        conv3_3_1x1_reduce_bnxx = self.conv3_3_1x1_reduce_relu(conv3_3_1x1_reduce_bn)\n",
        "        conv3_3_3x3 = self.conv3_3_3x3(conv3_3_1x1_reduce_bnxx)\n",
        "        conv3_3_3x3_bn = self.conv3_3_3x3_bn(conv3_3_3x3)\n",
        "        conv3_3_3x3_bnxx = self.conv3_3_3x3_relu(conv3_3_3x3_bn)\n",
        "        conv3_3_1x1_increase = self.conv3_3_1x1_increase(conv3_3_3x3_bnxx)\n",
        "        conv3_3_1x1_increase_bn = self.conv3_3_1x1_increase_bn(conv3_3_1x1_increase)\n",
        "        conv3_3 = torch.add(conv3_2x, 1, conv3_3_1x1_increase_bn)\n",
        "        conv3_3x = self.conv3_3_relu(conv3_3)\n",
        "        conv3_4_1x1_reduce = self.conv3_4_1x1_reduce(conv3_3x)\n",
        "        conv3_4_1x1_reduce_bn = self.conv3_4_1x1_reduce_bn(conv3_4_1x1_reduce)\n",
        "        conv3_4_1x1_reduce_bnxx = self.conv3_4_1x1_reduce_relu(conv3_4_1x1_reduce_bn)\n",
        "        conv3_4_3x3 = self.conv3_4_3x3(conv3_4_1x1_reduce_bnxx)\n",
        "        conv3_4_3x3_bn = self.conv3_4_3x3_bn(conv3_4_3x3)\n",
        "        conv3_4_3x3_bnxx = self.conv3_4_3x3_relu(conv3_4_3x3_bn)\n",
        "        conv3_4_1x1_increase = self.conv3_4_1x1_increase(conv3_4_3x3_bnxx)\n",
        "        conv3_4_1x1_increase_bn = self.conv3_4_1x1_increase_bn(conv3_4_1x1_increase)\n",
        "        conv3_4 = torch.add(conv3_3x, 1, conv3_4_1x1_increase_bn)\n",
        "        conv3_4x = self.conv3_4_relu(conv3_4)\n",
        "        conv4_1_1x1_reduce = self.conv4_1_1x1_reduce(conv3_4x)\n",
        "        conv4_1_1x1_reduce_bn = self.conv4_1_1x1_reduce_bn(conv4_1_1x1_reduce)\n",
        "        conv4_1_1x1_reduce_bnxx = self.conv4_1_1x1_reduce_relu(conv4_1_1x1_reduce_bn)\n",
        "        conv4_1_3x3 = self.conv4_1_3x3(conv4_1_1x1_reduce_bnxx)\n",
        "        conv4_1_3x3_bn = self.conv4_1_3x3_bn(conv4_1_3x3)\n",
        "        conv4_1_3x3_bnxx = self.conv4_1_3x3_relu(conv4_1_3x3_bn)\n",
        "        conv4_1_1x1_increase = self.conv4_1_1x1_increase(conv4_1_3x3_bnxx)\n",
        "        conv4_1_1x1_increase_bn = self.conv4_1_1x1_increase_bn(conv4_1_1x1_increase)\n",
        "        conv4_1_1x1_proj = self.conv4_1_1x1_proj(conv3_4x)\n",
        "        conv4_1_1x1_proj_bn = self.conv4_1_1x1_proj_bn(conv4_1_1x1_proj)\n",
        "        conv4_1 = torch.add(conv4_1_1x1_proj_bn, 1, conv4_1_1x1_increase_bn)\n",
        "        conv4_1x = self.conv4_1_relu(conv4_1)\n",
        "        conv4_2_1x1_reduce = self.conv4_2_1x1_reduce(conv4_1x)\n",
        "        conv4_2_1x1_reduce_bn = self.conv4_2_1x1_reduce_bn(conv4_2_1x1_reduce)\n",
        "        conv4_2_1x1_reduce_bnxx = self.conv4_2_1x1_reduce_relu(conv4_2_1x1_reduce_bn)\n",
        "        conv4_2_3x3 = self.conv4_2_3x3(conv4_2_1x1_reduce_bnxx)\n",
        "        conv4_2_3x3_bn = self.conv4_2_3x3_bn(conv4_2_3x3)\n",
        "        conv4_2_3x3_bnxx = self.conv4_2_3x3_relu(conv4_2_3x3_bn)\n",
        "        conv4_2_1x1_increase = self.conv4_2_1x1_increase(conv4_2_3x3_bnxx)\n",
        "        conv4_2_1x1_increase_bn = self.conv4_2_1x1_increase_bn(conv4_2_1x1_increase)\n",
        "        conv4_2 = torch.add(conv4_1x, 1, conv4_2_1x1_increase_bn)\n",
        "        conv4_2x = self.conv4_2_relu(conv4_2)\n",
        "        conv4_3_1x1_reduce = self.conv4_3_1x1_reduce(conv4_2x)\n",
        "        conv4_3_1x1_reduce_bn = self.conv4_3_1x1_reduce_bn(conv4_3_1x1_reduce)\n",
        "        conv4_3_1x1_reduce_bnxx = self.conv4_3_1x1_reduce_relu(conv4_3_1x1_reduce_bn)\n",
        "        conv4_3_3x3 = self.conv4_3_3x3(conv4_3_1x1_reduce_bnxx)\n",
        "        conv4_3_3x3_bn = self.conv4_3_3x3_bn(conv4_3_3x3)\n",
        "        conv4_3_3x3_bnxx = self.conv4_3_3x3_relu(conv4_3_3x3_bn)\n",
        "        conv4_3_1x1_increase = self.conv4_3_1x1_increase(conv4_3_3x3_bnxx)\n",
        "        conv4_3_1x1_increase_bn = self.conv4_3_1x1_increase_bn(conv4_3_1x1_increase)\n",
        "        conv4_3 = torch.add(conv4_2x, 1, conv4_3_1x1_increase_bn)\n",
        "        conv4_3x = self.conv4_3_relu(conv4_3)\n",
        "        conv4_4_1x1_reduce = self.conv4_4_1x1_reduce(conv4_3x)\n",
        "        conv4_4_1x1_reduce_bn = self.conv4_4_1x1_reduce_bn(conv4_4_1x1_reduce)\n",
        "        conv4_4_1x1_reduce_bnxx = self.conv4_4_1x1_reduce_relu(conv4_4_1x1_reduce_bn)\n",
        "        conv4_4_3x3 = self.conv4_4_3x3(conv4_4_1x1_reduce_bnxx)\n",
        "        conv4_4_3x3_bn = self.conv4_4_3x3_bn(conv4_4_3x3)\n",
        "        conv4_4_3x3_bnxx = self.conv4_4_3x3_relu(conv4_4_3x3_bn)\n",
        "        conv4_4_1x1_increase = self.conv4_4_1x1_increase(conv4_4_3x3_bnxx)\n",
        "        conv4_4_1x1_increase_bn = self.conv4_4_1x1_increase_bn(conv4_4_1x1_increase)\n",
        "        conv4_4 = torch.add(conv4_3x, 1, conv4_4_1x1_increase_bn)\n",
        "        conv4_4x = self.conv4_4_relu(conv4_4)\n",
        "        conv4_5_1x1_reduce = self.conv4_5_1x1_reduce(conv4_4x)\n",
        "        conv4_5_1x1_reduce_bn = self.conv4_5_1x1_reduce_bn(conv4_5_1x1_reduce)\n",
        "        conv4_5_1x1_reduce_bnxx = self.conv4_5_1x1_reduce_relu(conv4_5_1x1_reduce_bn)\n",
        "        conv4_5_3x3 = self.conv4_5_3x3(conv4_5_1x1_reduce_bnxx)\n",
        "        conv4_5_3x3_bn = self.conv4_5_3x3_bn(conv4_5_3x3)\n",
        "        conv4_5_3x3_bnxx = self.conv4_5_3x3_relu(conv4_5_3x3_bn)\n",
        "        conv4_5_1x1_increase = self.conv4_5_1x1_increase(conv4_5_3x3_bnxx)\n",
        "        conv4_5_1x1_increase_bn = self.conv4_5_1x1_increase_bn(conv4_5_1x1_increase)\n",
        "        conv4_5 = torch.add(conv4_4x, 1, conv4_5_1x1_increase_bn)\n",
        "        conv4_5x = self.conv4_5_relu(conv4_5)\n",
        "        conv4_6_1x1_reduce = self.conv4_6_1x1_reduce(conv4_5x)\n",
        "        conv4_6_1x1_reduce_bn = self.conv4_6_1x1_reduce_bn(conv4_6_1x1_reduce)\n",
        "        conv4_6_1x1_reduce_bnxx = self.conv4_6_1x1_reduce_relu(conv4_6_1x1_reduce_bn)\n",
        "        conv4_6_3x3 = self.conv4_6_3x3(conv4_6_1x1_reduce_bnxx)\n",
        "        conv4_6_3x3_bn = self.conv4_6_3x3_bn(conv4_6_3x3)\n",
        "        conv4_6_3x3_bnxx = self.conv4_6_3x3_relu(conv4_6_3x3_bn)\n",
        "        conv4_6_1x1_increase = self.conv4_6_1x1_increase(conv4_6_3x3_bnxx)\n",
        "        conv4_6_1x1_increase_bn = self.conv4_6_1x1_increase_bn(conv4_6_1x1_increase)\n",
        "        conv4_6 = torch.add(conv4_5x, 1, conv4_6_1x1_increase_bn)\n",
        "        conv4_6x = self.conv4_6_relu(conv4_6)\n",
        "        conv5_1_1x1_reduce = self.conv5_1_1x1_reduce(conv4_6x)\n",
        "        conv5_1_1x1_reduce_bn = self.conv5_1_1x1_reduce_bn(conv5_1_1x1_reduce)\n",
        "        conv5_1_1x1_reduce_bnxx = self.conv5_1_1x1_reduce_relu(conv5_1_1x1_reduce_bn)\n",
        "        conv5_1_3x3 = self.conv5_1_3x3(conv5_1_1x1_reduce_bnxx)\n",
        "        conv5_1_3x3_bn = self.conv5_1_3x3_bn(conv5_1_3x3)\n",
        "        conv5_1_3x3_bnxx = self.conv5_1_3x3_relu(conv5_1_3x3_bn)\n",
        "        conv5_1_1x1_increase = self.conv5_1_1x1_increase(conv5_1_3x3_bnxx)\n",
        "        conv5_1_1x1_increase_bn = self.conv5_1_1x1_increase_bn(conv5_1_1x1_increase)\n",
        "        conv5_1_1x1_proj = self.conv5_1_1x1_proj(conv4_6x)\n",
        "        conv5_1_1x1_proj_bn = self.conv5_1_1x1_proj_bn(conv5_1_1x1_proj)\n",
        "        conv5_1 = torch.add(conv5_1_1x1_proj_bn, 1, conv5_1_1x1_increase_bn)\n",
        "        conv5_1x = self.conv5_1_relu(conv5_1)\n",
        "        conv5_2_1x1_reduce = self.conv5_2_1x1_reduce(conv5_1x)\n",
        "        conv5_2_1x1_reduce_bn = self.conv5_2_1x1_reduce_bn(conv5_2_1x1_reduce)\n",
        "        conv5_2_1x1_reduce_bnxx = self.conv5_2_1x1_reduce_relu(conv5_2_1x1_reduce_bn)\n",
        "        conv5_2_3x3 = self.conv5_2_3x3(conv5_2_1x1_reduce_bnxx)\n",
        "        conv5_2_3x3_bn = self.conv5_2_3x3_bn(conv5_2_3x3)\n",
        "        conv5_2_3x3_bnxx = self.conv5_2_3x3_relu(conv5_2_3x3_bn)\n",
        "        conv5_2_1x1_increase = self.conv5_2_1x1_increase(conv5_2_3x3_bnxx)\n",
        "        conv5_2_1x1_increase_bn = self.conv5_2_1x1_increase_bn(conv5_2_1x1_increase)\n",
        "        conv5_2 = torch.add(conv5_1x, 1, conv5_2_1x1_increase_bn)\n",
        "        conv5_2x = self.conv5_2_relu(conv5_2)\n",
        "        conv5_3_1x1_reduce = self.conv5_3_1x1_reduce(conv5_2x)\n",
        "        conv5_3_1x1_reduce_bn = self.conv5_3_1x1_reduce_bn(conv5_3_1x1_reduce)\n",
        "        conv5_3_1x1_reduce_bnxx = self.conv5_3_1x1_reduce_relu(conv5_3_1x1_reduce_bn)\n",
        "        conv5_3_3x3 = self.conv5_3_3x3(conv5_3_1x1_reduce_bnxx)\n",
        "        conv5_3_3x3_bn = self.conv5_3_3x3_bn(conv5_3_3x3)\n",
        "        conv5_3_3x3_bnxx = self.conv5_3_3x3_relu(conv5_3_3x3_bn)\n",
        "        conv5_3_1x1_increase = self.conv5_3_1x1_increase(conv5_3_3x3_bnxx)\n",
        "        conv5_3_1x1_increase_bn = self.conv5_3_1x1_increase_bn(conv5_3_1x1_increase)\n",
        "        conv5_3 = torch.add(conv5_2x, 1, conv5_3_1x1_increase_bn)\n",
        "        conv5_3x = self.conv5_3_relu(conv5_3)\n",
        "        pool5_7x7_s1 = self.pool5_7x7_s1(conv5_3x)\n",
        "        classifier_preflatten = self.classifier(pool5_7x7_s1)\n",
        "        classifier = classifier_preflatten.view(classifier_preflatten.size(0), -1)\n",
        "        #return classifier, pool5_7x7_s1 　出力を変更しておかないと次元が合わないと言われる\n",
        "        return classifier\n",
        "\n",
        "def resnet50_ft_dag(weights_path=None, **kwargs):\n",
        "    \"\"\"\n",
        "    load imported model instance\n",
        "\n",
        "    Args:\n",
        "        weights_path (str): If set, loads model weights from the given path\n",
        "    \"\"\"\n",
        "    model = Resnet50_ft_dag()\n",
        "    if weights_path:\n",
        "        state_dict = torch.load(weights_path)\n",
        "        model.load_state_dict(state_dict)\n",
        "    return model\n",
        "\n",
        "class Flatten(nn.Module): \n",
        "    \"\"\"One layer module that flattens its input.\"\"\"\n",
        "    def __init__(self):\n",
        "        super(Flatten, self).__init__()\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)\n",
        "        return x\n",
        "\n",
        "def pre_process(data_dir):\n",
        "    # 入力画像の前処理をするクラス\n",
        "    # 訓練時と推論時で処理が異なる\n",
        "\n",
        "    \"\"\"\n",
        "        画像の前処理クラス。訓練時、検証時で異なる動作をする。\n",
        "        画像のサイズをリサイズし、色を標準化する。\n",
        "        訓練時はRandomResizedCropとRandomHorizontalFlipでデータオーギュメンテーションする。\n",
        "\n",
        "\n",
        "        Attributes\n",
        "        ----------\n",
        "        resize : int\n",
        "            リサイズ先の画像の大きさ。\n",
        "        mean : (R, G, B)\n",
        "            各色チャネルの平均値。\n",
        "        std : (R, G, B)\n",
        "            各色チャネルの標準偏差。\n",
        "    \"\"\"\n",
        "\n",
        "    data_transforms = {\n",
        "        'train': transforms.Compose([\n",
        "            transforms.RandomResizedCrop(224, scale=(0.75,1.0)),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "        ]),\n",
        "        'val': transforms.Compose([\n",
        "            transforms.Resize(224),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "        ]),\n",
        "    }\n",
        "\n",
        "    data_dir = data_dir\n",
        "    n_samples = len(data_dir)\n",
        "\n",
        "    image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
        "                                              data_transforms[x])\n",
        "                      for x in ['train', 'val']}\n",
        "    dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=20,\n",
        "                                                shuffle=True, num_workers=os.cpu_count(), pin_memory=True)\n",
        "                  for x in ['train', 'val']}\n",
        "    dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
        "    class_names = image_datasets['train'].classes\n",
        "\n",
        "\n",
        "    print(class_names)\n",
        "    k=0\n",
        "    for i in class_names:\n",
        "        print(class_names[k]+\"_train:\"+str(len(os.listdir(path=data_dir + '/train/'+class_names[k]))))\n",
        "        k+=1\n",
        "    k=0\n",
        "    for i in class_names:\n",
        "        print(class_names[k]+\"_val:\"+str(len(os.listdir(path=data_dir + '/val/'+class_names[k]))))\n",
        "        k+=1\n",
        "\n",
        "    print(\"training data set_total：\"+ str(len(image_datasets['train'])))\n",
        "    print(\"validating data set_total：\"+str(len(image_datasets['val'])))\n",
        "    \n",
        "    return image_datasets, dataloaders, dataset_sizes, class_names, device\n",
        "\n",
        "\n",
        "#少数の画像を可視化\n",
        "def imshow(inp, title=None):\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    inp = std * inp + mean\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "    plt.imshow(inp)\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
        "\n",
        "\n",
        "def getBatch(dataloaders):    \n",
        "    # Get a batch of training data\n",
        "    inputs, classes = next(iter(dataloaders['train']))\n",
        "\n",
        "    # Make a grid from batch\n",
        "    out = torchvision.utils.make_grid(inputs)\n",
        "\n",
        "    #imshow(out, title=[class_names[x] for x in classes])\n",
        "    return(inputs, classes)\n",
        "\n",
        "#Defining early stopping class\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "class EarlyStopping:\n",
        "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
        "    def __init__(self, patience=7, verbose=False, delta=0):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            patience (int): How long to wait after last time validation loss improved.\n",
        "                            Default: 7\n",
        "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
        "                            Default: False\n",
        "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
        "                            Default: 0\n",
        "        \"\"\"\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.val_loss_min = np.Inf\n",
        "        self.delta = delta\n",
        "\n",
        "    def __call__(self, val_loss, model):\n",
        "\n",
        "        score = -val_loss\n",
        "\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "            self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, val_loss, model):\n",
        "        '''Saves model when validation loss decrease.'''\n",
        "        if self.verbose:\n",
        "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
        "        torch.save(model.state_dict(), 'checkpoint.pt')\n",
        "        self.val_loss_min = val_loss\n",
        "\n",
        "\n",
        "#Train models\n",
        "def train_model(model, criterion, optimizer, patience, num_epochs):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    # to track the training loss as the model trains\n",
        "    train_loss = []\n",
        "    # to track the validation loss as the model trains\n",
        "    valid_loss = []\n",
        "\n",
        "\n",
        "    # initialize the early_stopping object\n",
        "    early_stopping = EarlyStopping(patience=patience, verbose=True)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device, non_blocking=True)\n",
        "                labels = labels.to(device, non_blocking=True)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase] \n",
        "            \n",
        "            # record train_loss and valid_loss\n",
        "            if phase == 'train':\n",
        "                train_loss.append(epoch_loss)\n",
        "            if phase == 'val':\n",
        "                valid_loss.append(epoch_loss)\n",
        "            #print(train_loss)\n",
        "            #print(valid_loss)\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                phase, epoch_loss, epoch_acc))\n",
        "\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "      \n",
        "      # early_stopping needs the validation loss to check if it has decresed, \n",
        "      # and if it has, it will make a checkpoint of the current model\n",
        "        if phase == 'val':    \n",
        "            early_stopping(epoch_loss, model)\n",
        "                \n",
        "            if early_stopping.early_stop:\n",
        "                print(\"Early stopping\")\n",
        "                break\n",
        "        print()\n",
        "\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model, train_loss, valid_loss\n",
        "\n",
        "\n",
        "#Visualize model\n",
        "def visualize_model(model, num_images=6):\n",
        "    was_training = model.training\n",
        "    model.eval()\n",
        "    images_so_far = 0\n",
        "    fig = plt.figure()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, labels) in enumerate(dataloaders['val']):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            for j in range(inputs.size()[0]):\n",
        "                images_so_far += 1\n",
        "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
        "                ax.axis('off')\n",
        "                ax.set_title('predicted: {}'.format(class_names[preds[j]]))\n",
        "                imshow(inputs.cpu().data[j])\n",
        "\n",
        "                if images_so_far == num_images:\n",
        "                    model.train(mode=was_training)\n",
        "                    return\n",
        "        model.train(mode=was_training)\n",
        "\n",
        "\n",
        "def training(model_ft, criterion, optimizer_ft,  patience=15, num_epochs=50):\n",
        "    model_ft, train_loss, valid_loss = train_model(model_ft, criterion, optimizer_ft,  patience=patience, num_epochs=num_epochs)\n",
        "\n",
        "\n",
        "#対象のパスからラベルを抜き出して表示\n",
        "def getlabel(image_path):\n",
        "      image_name = os.path.basename(image_path)\n",
        "      label = os.path.basename(os.path.dirname(image_path))\n",
        "      return(image_name, label)\n",
        "\n",
        "'''\n",
        "#変形後の画像を表示\n",
        "def image_transform(image_path):\n",
        "\n",
        "    image=Image.open(image_path)\n",
        "\n",
        "    \n",
        "    #変形した画像を表示する\n",
        "    transform = transforms.Compose([\n",
        "            transforms.Resize(256),\n",
        "            transforms.CenterCrop(224)])\n",
        "    image_transformed = transform(image)\n",
        "    plt.imshow(np.array(image_transformed))\n",
        "'''\n",
        "\n",
        "#評価のための画像下処理\n",
        "def image_transform(image_path):    \n",
        "    image=Image.open(image_path)\n",
        "    transform = transforms.Compose([\n",
        "            transforms.Resize(256),\n",
        "            transforms.CenterCrop(224),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "    image_tensor = transform(image)\n",
        "\n",
        "    #バッチサイズの次元を先頭に追加した4Dテンソルに変換\n",
        "    image_tensor.unsqueeze_(0)\n",
        "    #print(image_tensor.size())  # torch.Size([1, 3, 224, 224])\n",
        "    image_tensor = image_tensor.to(device) #model_ftをGPUに載せる\n",
        "\n",
        "    return(image_tensor)\n",
        "\n",
        "#モデルにした処理した画像を投入して予測結果を表示\n",
        "def image_eval(image_tensor, label):\n",
        "    output = model_ft(image_tensor)\n",
        "    #print(output.size())  # torch.Size([1, 1000])\n",
        "    #print(output)\n",
        "\n",
        "    #model_pred:クラス名前、prob:確率、pred:クラス番号\n",
        "    prob, pred = torch.topk(nn.Softmax(dim=1)(output), 1)\n",
        "    model_pred = class_names[pred]\n",
        "    \n",
        "    #甲状腺眼症のprobabilityを計算（classが0なら1から減算、classが1ならそのまま）\n",
        "    prob = abs(1-float(prob)-float(pred))\n",
        " \n",
        "    return model_pred, prob, pred\n",
        "\n",
        "    \"\"\"\n",
        "    #probalilityを計算する\n",
        "    pred_prob = torch.topk(nn.Softmax(dim=1)(output), 1)[0]\n",
        "    pred_class = torch.topk(nn.Softmax(dim=1)(output), 1)[1]\n",
        "    if pred_class == 1:\n",
        "        pred_prob = pred_prob\n",
        "    elif pred_class == 0:\n",
        "        pred_prob = 1- pred_prob\n",
        "    return(model_pred, pred_prob)  #class_nameの番号で出力される\n",
        "    \"\"\"\n",
        "\n",
        "def showImage(image_path):\n",
        "    #画像のインポート\n",
        "    img = cv2.imread(image_path, cv2.IMREAD_UNCHANGED)\n",
        "    #画像のリサイズ\n",
        "    height = img.shape[0]\n",
        "    width = img.shape[1]\n",
        "    resized_img = cv2.resize(img, (int(width*300/height), 300))\n",
        "    cv2_imshow(resized_img)\n",
        "\n",
        "def calculateAccuracy (TP, TN, FP, FN):\n",
        "    accuracy = (TP + TN)/ (TP + TN + FP + FN)\n",
        "    precision  = TP/(FP + TP)\n",
        "    recall = TP/(TP + FN)\n",
        "    specificity = TN/(FP + TN)\n",
        "    f_value = (2*recall*precision)/(recall+precision)\n",
        "    return(accuracy, precision, recall, specificity, f_value)\n",
        "\n",
        "\"\"\"\n",
        "・True positive (TN)\n",
        "・False positive (FP)\n",
        "・True negative (TN)\n",
        "・False negative (FN)\n",
        "Accuracy = (TP + TN)/ (TP + TN + FP + FN)\n",
        "Precision = TP/(FP + TP) ※positive predictive value\n",
        "Recall = TP/(TP + FN)　※sensitivity\n",
        "Specificity = TN/(FP + TN)\n",
        "F_value = (2RecallPrecision)/(Recall+Precision)\n",
        "\"\"\"\n",
        "\n",
        "def evaluation(model_ft, testset_dir):\n",
        "    #評価モードにする\n",
        "    model_ft.eval()\n",
        "\n",
        "    #testデータセット内のファイル名を取得\n",
        "    image_path = glob.glob(testset_dir + \"/*/*\")\n",
        "    #random.shuffle(image_path)  #表示順をランダムにする\n",
        "    print('number of images: ' +str(len(image_path)))\n",
        "\n",
        "\n",
        "    TP, FP, TN, FN, TP, FP, TN, FN = [0,0,0,0,0,0,0,0]\n",
        "    image_name_list = []\n",
        "    label_list = []\n",
        "    model_pred_list = []\n",
        "    hum_pred_list = []\n",
        "\n",
        "    model_pred_class = []\n",
        "    model_pred_prob = []\n",
        "\n",
        "    for i in image_path:\n",
        "          image_name, label = getlabel(i)  #画像の名前とラベルを取得\n",
        "          image_tensor = image_transform(i)  #予測のための画像下処理\n",
        "          model_pred, prob, pred = image_eval(image_tensor, label)  #予測結果を出力   \n",
        "          #print('Image: '+ image_name)\n",
        "          #print('Label: '+ label)\n",
        "          #print('Pred: '+ model_pred)\n",
        "          #showImage(i)  #画像を表示\n",
        "          #print() #空白行を入れる\n",
        "          time.sleep(0.1)\n",
        "\n",
        "          image_name_list.append(image_name)\n",
        "          label_list.append(label)\n",
        "          model_pred_list.append(model_pred)\n",
        "\n",
        "          model_pred_class.append(int(pred))\n",
        "          model_pred_prob.append(float(prob))\n",
        "\n",
        "          if label == class_names[0]:\n",
        "              if model_pred == class_names[0]:\n",
        "                  TN += 1\n",
        "              else:\n",
        "                  FP += 1\n",
        "          elif label == class_names[1]:\n",
        "              if model_pred == class_names[1]:\n",
        "                  TP += 1\n",
        "              else:\n",
        "                  FN += 1     \n",
        "\n",
        "    print(TP, FN, TN, FP)\n",
        "\n",
        "    #Accuracyを計算\n",
        "    accuracy, precision, recall, specificity, f_value = calculateAccuracy (TP, TN, FP, FN)\n",
        "    print('Accuracy: ' + str(accuracy))\n",
        "    print('Precision (positive predictive value): ' + str(precision))\n",
        "    print('Recall (sensitivity): ' + str(recall))\n",
        "    print('Specificity: ' + str(specificity))\n",
        "    print('F_value: ' + str(f_value))\n",
        "\n",
        "    #print(model_pred_class)\n",
        "    #print(model_pred_prob)\n",
        "\n",
        "    return TP,TN,FP,FN, accuracy, precision, recall, specificity, f_value, label_list, model_pred_prob, model_pred_class, image_path\n",
        "\n",
        "\n",
        "def make_csv(roc_label_list):\n",
        "    #csvのdata tableを作成\n",
        "    pd.set_option('display.max_rows', 800)  # 省略なしで表示\n",
        "    #columns1 = [\"EfficientNet_32\", \"EfficientNet_64\", \"EfficientNet_128\", \"EfficientNet_256\", \"EfficientNet_512\", \"EfficientNet_558\"]\n",
        "    roc_label_list.extend([\"avg\", \"std\"])\n",
        "    index1 = [\"TP\",\"TN\",\"FP\",\"FN\",\"Accuracy\",\"Positive predictive value\",\"sensitity\",\"specificity\",\"F-value\",\"roc_auc\"]\n",
        "    df = pd.DataFrame(index=index1, columns=roc_label_list)\n",
        "    return df\n",
        "\n",
        "def write_csv(df, col, TP, TN, FP, FN, accuracy, precision, recall, specificity, f_value,roc_auc):\n",
        "    df.iloc[0:10, col] = TP, TN, FP, FN, accuracy, precision, recall, specificity, f_value,roc_auc \n",
        "    #print(df)\n",
        "\n",
        "    # CSVとして出力\n",
        "    #df2.to_csv(\"/content/drive/My Drive/Grav_bootcamp/Posttrain_model_eval_result.csv\",encoding=\"shift_jis\")\n",
        "    return df\n",
        "\n",
        "def Draw_roc_curve(label_list_list, model_pred_prob_list, sample_num_list, num_curves,class_names):\n",
        "\n",
        "#グラフの外形を作成\n",
        "    fig = plt.figure(figsize=(8.0, 6.0))\n",
        "    lw = 2\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver operating characteristic')\n",
        "    ycolor = [\"r\", \"g\", \"b\", \"c\", \"m\", \"y\", \"k\", \"w\"]      # 各プロットの色\n",
        "    plt.legend(loc=\"lower right\")\n",
        "\n",
        "    k=0\n",
        "    for j in range(num_curves):\n",
        "        y_score = []\n",
        "        y_true = []\n",
        "\n",
        "        for i in label_list_list[k]:\n",
        "            if i == class_names[0]:\n",
        "                  y_true.append(0)\n",
        "            elif i == class_names[1]:\n",
        "                  y_true.append(1)\n",
        "            \n",
        "        #それぞれの画像における陽性の確率についてリストを作成\n",
        "        y_score = model_pred_prob_list[k]\n",
        "\n",
        "        fpr, tpr,thred = roc_curve(y_true, y_score)\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "\n",
        "        plt.plot(fpr, tpr, color=ycolor[k],lw=lw, label= str(roc_label_list[k])+':ROC curve (area = %0.2f)' % roc_auc)\n",
        "            \n",
        "        k+=1\n",
        "\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n",
        "    return fig\n",
        "\n",
        "def calculate_auc(label_list, model_pred_prob, class_names):\n",
        "    y_true, y_score = [], []\n",
        "    for i in label_list:\n",
        "        if i == class_names[0]:\n",
        "              y_true.append(0)\n",
        "        elif i == class_names[1]:\n",
        "              y_true.append(1)\n",
        "            \n",
        "    #それぞれの画像における陽性の確率についてリストを作成\n",
        "    y_score = model_pred_prob\n",
        "\n",
        "    print(y_true)\n",
        "    print(len(y_true))\n",
        "    print(y_score)\n",
        "    print(len(y_score))\n",
        "\n",
        "    fpr, tpr,thred = roc_curve(y_true, y_score)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    print(\"roc_auc: \" +str(roc_auc))\n",
        "    return(roc_auc, y_true, y_score)\n",
        "\n",
        "def calcurate_ave_std(df, fold):\n",
        "    for i in range(5):\n",
        "        df.iloc[i,fold] = df[i,0:5].mean \n",
        "\n",
        "def makefolder(path):\n",
        "    if not os.path.exists(path):  # ディレクトリがなかったら\n",
        "        os.mkdir(path)  # 作成したいフォルダ名を作成\n",
        "\n",
        "def prediction_results_to_df(df, img_path, pred):\n",
        "    for path, pred in zip(img_path, pred):\n",
        "        img_name = os.path.basename(path)\n",
        "        df.loc[df[\"num\"] == img_name, \"prediction\"] = pred\n",
        "\n",
        "def convnet_pretrained():\n",
        "    model_ft = models.resnet50(pretrained=True)\n",
        "    num_ftrs = model_ft.fc.in_features\n",
        "    model_ft.fc = nn.Linear(num_ftrs, 2)\n",
        "\n",
        "    #GPU使用\n",
        "    model_ft = model_ft.to(device)\n",
        "\n",
        "    #損失関数を定義\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Observe that all parameters are being optimized\n",
        "    #https://blog.knjcode.com/adabound-memo/\n",
        "    #https://pypi.org/project/torch-optimizer/\n",
        "    optimizer_ft = optim.AdaBound(\n",
        "        model_ft.parameters(),\n",
        "        lr= 1e-3,\n",
        "        betas= (0.9, 0.999),\n",
        "        final_lr = 0.1,\n",
        "        gamma=1e-3,\n",
        "        eps= 1e-8,\n",
        "        weight_decay=0,\n",
        "        amsbound=False,\n",
        "    )\n",
        "    return (model_ft, criterion, optimizer_ft)\n",
        "\n",
        "def convnet_nonpretrained():\n",
        "    model_ft = models.resnet50(pretrained=False)\n",
        "    num_ftrs = model_ft.fc.in_features\n",
        "    model_ft.fc = nn.Linear(num_ftrs, 2)\n",
        "\n",
        "    #GPU使用\n",
        "    model_ft = model_ft.to(device)\n",
        "\n",
        "    #損失関数を定義\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Observe that all parameters are being optimized\n",
        "    #https://blog.knjcode.com/adabound-memo/\n",
        "    #https://pypi.org/project/torch-optimizer/\n",
        "    optimizer_ft = optim.AdaBound(\n",
        "        model_ft.parameters(),\n",
        "        lr= 1e-3,\n",
        "        betas= (0.9, 0.999),\n",
        "        final_lr = 0.1,\n",
        "        gamma=1e-3,\n",
        "        eps= 1e-8,\n",
        "        weight_decay=0,\n",
        "        amsbound=False,\n",
        "    )\n",
        "    return (model_ft, criterion, optimizer_ft)\n",
        "\n",
        "def convnet_VGGFace():\n",
        "   #Pretrained dataと結びつける\n",
        "    model_ft = Resnet50_ft_dag()\n",
        "    model_ft.load_state_dict(torch.load('/content/drive/MyDrive/Deep_learning/resnet50_ft_dag.pth'))\n",
        "    #最終結合層のリセットと付け替え(全結合層を2つに)\n",
        "    #model_ft.classifier = nn.Conv2d(2048, len(class_names), kernel_size=[1,1], stride=(1,1), bias = False)\n",
        "    model_ft.classifier = nn.Linear(2048, 2)\n",
        "    model_ft.classifier = nn.Sequential(*([Flatten()] + list(model_ft.children())[-1:])) #Flattenを挿入\n",
        "\n",
        "\n",
        "    #GPU使用\n",
        "    model_ft = model_ft.to(device)\n",
        "\n",
        "    #損失関数を定義\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Observe that all parameters are being optimized\n",
        "    #https://blog.knjcode.com/adabound-memo/\n",
        "    #https://pypi.org/project/torch-optimizer/\n",
        "    optimizer_ft = optim.AdaBound(\n",
        "        model_ft.parameters(),\n",
        "        lr= 1e-3,\n",
        "        betas= (0.9, 0.999),\n",
        "        final_lr = 0.1,\n",
        "        gamma=1e-3,\n",
        "        eps= 1e-8,\n",
        "        weight_decay=0,\n",
        "        amsbound=False,\n",
        "    )\n",
        "    return (model_ft, criterion, optimizer_ft)\n",
        "        "
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugZyB_gxU2uX"
      },
      "source": [
        "#まとめて解析\n",
        "# 出力名を記入\n",
        "pretrain_num = 0\n",
        "pretrain = [\"pretrained\", \"nonpretrained\", \"VGGFace\"]\n",
        "out_name = \"ResNet50_\"+pretrain[pretrain_num]+\"_all\"\n",
        "csv_path = dst_path + \"/img_list_\"+out_name+\".csv\"\n",
        "\n",
        "#create data_dir_list\n",
        "data_dir = dst_path\n",
        "fold = split_num\n",
        "print(str(fold)+'-fold cross validation')\n",
        "\n",
        "\n",
        "data_dir_list = [0]*fold\n",
        "\n",
        "for i in range(fold):\n",
        "    data_dir_list[i] = data_dir + '/' + str(i)\n",
        "    print(data_dir_list[i])\n",
        "\n",
        "#create roc_label_list\n",
        "roc_label_list = [0]*fold\n",
        "roc_label_list = list(range(fold))\n",
        "#print(roc_label_list)\n",
        "\n",
        "df = make_csv(roc_label_list)\n",
        "\n",
        "label_list_list, model_pred_prob_list, Y_TRUE, Y_SCORE = [],[],[],[]\n",
        "\n",
        "#print(data_dir_list)\n",
        "#print(roc_label_list)\n",
        "\n",
        "for i, t in enumerate(zip(data_dir_list, roc_label_list)):\n",
        "    image_datasets, dataloaders, dataset_sizes, class_names, device = pre_process(t[0]) #path\n",
        "    inputs, classes = getBatch(dataloaders)\n",
        "\n",
        "    if pretrain_num == 0:\n",
        "        model_ft, criterion, optimizer_ft = convnet_pretrained()\n",
        "    elif pretrain_num == 1:\n",
        "        model_ft, criterion, optimizer_ft = convnet_nonpretrained()\n",
        "    elif pretrain_num == 2:\n",
        "        model_ft, criterion, optimizer_ft = convnet_VGGFace() #VGGFace使用時はこちら\n",
        "\n",
        "    training(model_ft, criterion, optimizer_ft,  patience=30, num_epochs=50)  \n",
        "    torch.save(model_ft.state_dict(), data_dir + '/'+str(out_name)+\"_\"+str(i)+\".pth\")    #ネットワークの保存\n",
        "    TP,TN,FP,FN, accuracy, precision, recall, specificity, f_value, label_list, model_pred_prob, model_pred_class, val_img_path = evaluation(model_ft, data_dir + \"/\" +str(i)+\"/val\")\n",
        "    prediction_results_to_df(df_cross, val_img_path, model_pred_class)\n",
        "    roc_auc, y_true, y_score = calculate_auc(label_list, model_pred_prob, class_names)\n",
        "    Y_TRUE.append(y_true)\n",
        "    Y_SCORE.append(y_score)\n",
        "    df = write_csv(df, i,TP,TN,FP,FN, accuracy, precision, recall, specificity, f_value, roc_auc) #numberをcsvの行として指定\n",
        "\n",
        "    label_list_list.append(label_list)\n",
        "    model_pred_prob_list.append(model_pred_prob)\n",
        "    print(\"\")\n",
        "    print(\"\")\n",
        "\n",
        "#Draw ROC curve\n",
        "fig = Draw_roc_curve(label_list_list, model_pred_prob_list, roc_label_list, len(label_list_list), class_names)\n",
        "\n",
        "pd.set_option('display.max_columns', 100)\n",
        "#それぞれの項目の平均を計算しcsvに追記する\n",
        "df.iloc[0:4,fold], df.iloc[9,fold]   = df.mean(axis=1)[0:4], df.mean(axis=1)[9] \n",
        "df.iloc[0:10,fold+1] = df.std(axis=1)[0:10]\n",
        "TP,TN,FP,FN = df.mean(axis=1)[0:4]\n",
        "df.iloc[4:9,fold] = calculateAccuracy (TP, TN, FP, FN)\n",
        "print(df)\n",
        "\n",
        "# CSVとして出力\n",
        "makefolder(data_dir + \"/crossvalidation_csv\")\n",
        "df.to_csv(data_dir + \"/crossvalidation_csv/\" + out_name + \".csv\",encoding=\"shift_jis\")\n",
        "\n",
        "#ROC_curveを保存\n",
        "makefolder(data_dir + \"/crossvalidation_ROCfigure\")\n",
        "fig.savefig(data_dir + \"/crossvalidation_ROCfigure/\" + out_name +\".png\")\n",
        "\n",
        "\"\"\"\n",
        "#Save ROC data\n",
        "makefolder(data_dir + \"/crossvalidation_ROCdata\")\n",
        "with open(data_dir + \"/crossvalidation_ROCdata/\"+out_name+\".csv\", 'w') as f:\n",
        "    writer = csv.writer(f)\n",
        "    for i, t in enumerate(zip(Y_TRUE, Y_SCORE)):\n",
        "        writer.writerow([t[0],t[1]])\n",
        "\"\"\"\n",
        "\n",
        "#リストCSVを保存\n",
        "df_cross.to_csv(csv_path, encoding='utf_8_sig')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Od7Y2_he021W",
        "outputId": "fbd3be10-70e7-41cf-b25f-7a693237463d"
      },
      "source": [
        "#さらにまとめて解析\n",
        "# 出力名を記入\n",
        "pretrain_num = [0,1,2]\n",
        "pretrain = [\"pretrained\", \"nonpretrained\", \"VGGFace\"]\n",
        "\n",
        "for num in pretrain_num:\n",
        "    out_name = \"ResNet50_\"+pretrain[num]+\"_all\"\n",
        "    csv_path = dst_path + \"/img_list_\"+out_name+\".csv\"\n",
        "\n",
        "    #create data_dir_list\n",
        "    data_dir = dst_path\n",
        "    fold = split_num\n",
        "\n",
        "    print(\"pretrain: \"+str(pretrain[num]))\n",
        "    print(str(fold)+'-fold cross validation')\n",
        "\n",
        "\n",
        "    data_dir_list = [0]*fold\n",
        "\n",
        "    for i in range(fold):\n",
        "        data_dir_list[i] = data_dir + '/' + str(i)\n",
        "        print(data_dir_list[i])\n",
        "\n",
        "    #create roc_label_list\n",
        "    roc_label_list = [0]*fold\n",
        "    roc_label_list = list(range(fold))\n",
        "    #print(roc_label_list)\n",
        "\n",
        "    df = make_csv(roc_label_list)\n",
        "\n",
        "    label_list_list, model_pred_prob_list, Y_TRUE, Y_SCORE = [],[],[],[]\n",
        "\n",
        "    #print(data_dir_list)\n",
        "    #print(roc_label_list)\n",
        "\n",
        "    for i, t in enumerate(zip(data_dir_list, roc_label_list)):\n",
        "        image_datasets, dataloaders, dataset_sizes, class_names, device = pre_process(t[0]) #path\n",
        "        inputs, classes = getBatch(dataloaders)\n",
        "\n",
        "        if pretrain_num == 0:\n",
        "            model_ft, criterion, optimizer_ft = convnet_pretrained()\n",
        "        elif pretrain_num == 1:\n",
        "            model_ft, criterion, optimizer_ft = convnet_nonpretrained()\n",
        "        elif pretrain_num == 2:\n",
        "            model_ft, criterion, optimizer_ft = convnet_VGGFace() #VGGFace使用時はこちら\n",
        "\n",
        "        training(model_ft, criterion, optimizer_ft,  patience=30, num_epochs=50)  \n",
        "        torch.save(model_ft.state_dict(), data_dir + '/'+str(out_name)+\"_\"+str(i)+\".pth\")    #ネットワークの保存\n",
        "        TP,TN,FP,FN, accuracy, precision, recall, specificity, f_value, label_list, model_pred_prob, model_pred_class, val_img_path = evaluation(model_ft, data_dir + \"/\" +str(i)+\"/val\")\n",
        "        prediction_results_to_df(df_cross, val_img_path, model_pred_class)\n",
        "        roc_auc, y_true, y_score = calculate_auc(label_list, model_pred_prob, class_names)\n",
        "        Y_TRUE.append(y_true)\n",
        "        Y_SCORE.append(y_score)\n",
        "        df = write_csv(df, i,TP,TN,FP,FN, accuracy, precision, recall, specificity, f_value, roc_auc) #numberをcsvの行として指定\n",
        "\n",
        "        label_list_list.append(label_list)\n",
        "        model_pred_prob_list.append(model_pred_prob)\n",
        "        print(\"\")\n",
        "        print(\"\")\n",
        "\n",
        "    #Draw ROC curve\n",
        "    fig = Draw_roc_curve(label_list_list, model_pred_prob_list, roc_label_list, len(label_list_list), class_names)\n",
        "\n",
        "    pd.set_option('display.max_columns', 100)\n",
        "    #それぞれの項目の平均を計算しcsvに追記する\n",
        "    df.iloc[0:4,fold], df.iloc[9,fold]   = df.mean(axis=1)[0:4], df.mean(axis=1)[9] \n",
        "    df.iloc[0:10,fold+1] = df.std(axis=1)[0:10]\n",
        "    TP,TN,FP,FN = df.mean(axis=1)[0:4]\n",
        "    df.iloc[4:9,fold] = calculateAccuracy (TP, TN, FP, FN)\n",
        "    print(df)\n",
        "\n",
        "    # CSVとして出力\n",
        "    makefolder(data_dir + \"/crossvalidation_csv\")\n",
        "    df.to_csv(data_dir + \"/crossvalidation_csv/\" + out_name + \".csv\",encoding=\"shift_jis\")\n",
        "\n",
        "    #ROC_curveを保存\n",
        "    makefolder(data_dir + \"/crossvalidation_ROCfigure\")\n",
        "    fig.savefig(data_dir + \"/crossvalidation_ROCfigure/\" + out_name +\".png\")\n",
        "\n",
        "    \"\"\"\n",
        "    #Save ROC data\n",
        "    makefolder(data_dir + \"/crossvalidation_ROCdata\")\n",
        "    with open(data_dir + \"/crossvalidation_ROCdata/\"+out_name+\".csv\", 'w') as f:\n",
        "        writer = csv.writer(f)\n",
        "        for i, t in enumerate(zip(Y_TRUE, Y_SCORE)):\n",
        "            writer.writerow([t[0],t[1]])\n",
        "    \"\"\"\n",
        "\n",
        "    #リストCSVを保存\n",
        "    df_cross.to_csv(csv_path, encoding='utf_8_sig')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5-fold cross validation\n",
            "/content/drive/MyDrive/Deep_learning/Strabismus/Dataset_250px_shuffle_crossvalidation_eso/0\n",
            "/content/drive/MyDrive/Deep_learning/Strabismus/Dataset_250px_shuffle_crossvalidation_eso/1\n",
            "/content/drive/MyDrive/Deep_learning/Strabismus/Dataset_250px_shuffle_crossvalidation_eso/2\n",
            "/content/drive/MyDrive/Deep_learning/Strabismus/Dataset_250px_shuffle_crossvalidation_eso/3\n",
            "/content/drive/MyDrive/Deep_learning/Strabismus/Dataset_250px_shuffle_crossvalidation_eso/4\n",
            "['cont', 'eso']\n",
            "cont_train:292\n",
            "eso_train:238\n",
            "cont_val:74\n",
            "eso_val:60\n",
            "training data set_total：530\n",
            "validating data set_total：134\n",
            "Epoch 0/49\n",
            "----------\n",
            "train Loss: 0.2334 Acc: 0.9057\n",
            "val Loss: 0.1486 Acc: 0.9627\n",
            "Validation loss decreased (inf --> 0.148561).  Saving model ...\n",
            "\n",
            "Epoch 1/49\n",
            "----------\n",
            "train Loss: 0.1720 Acc: 0.9377\n",
            "val Loss: 0.4626 Acc: 0.8134\n",
            "EarlyStopping counter: 1 out of 30\n",
            "\n",
            "Epoch 2/49\n",
            "----------\n",
            "train Loss: 0.1502 Acc: 0.9396\n",
            "val Loss: 0.1524 Acc: 0.9478\n",
            "EarlyStopping counter: 2 out of 30\n",
            "\n",
            "Epoch 3/49\n",
            "----------\n",
            "train Loss: 0.1872 Acc: 0.9170\n",
            "val Loss: 0.1568 Acc: 0.9478\n",
            "EarlyStopping counter: 3 out of 30\n",
            "\n",
            "Epoch 4/49\n",
            "----------\n",
            "train Loss: 0.1857 Acc: 0.9226\n",
            "val Loss: 0.3181 Acc: 0.8731\n",
            "EarlyStopping counter: 4 out of 30\n",
            "\n",
            "Epoch 5/49\n",
            "----------\n",
            "train Loss: 0.1379 Acc: 0.9434\n",
            "val Loss: 0.1783 Acc: 0.9328\n",
            "EarlyStopping counter: 5 out of 30\n",
            "\n",
            "Epoch 6/49\n",
            "----------\n",
            "train Loss: 0.1579 Acc: 0.9340\n",
            "val Loss: 0.0958 Acc: 0.9776\n",
            "Validation loss decreased (0.148561 --> 0.095803).  Saving model ...\n",
            "\n",
            "Epoch 7/49\n",
            "----------\n",
            "train Loss: 0.1389 Acc: 0.9509\n",
            "val Loss: 0.1238 Acc: 0.9552\n",
            "EarlyStopping counter: 1 out of 30\n",
            "\n",
            "Epoch 8/49\n",
            "----------\n",
            "train Loss: 0.1164 Acc: 0.9528\n",
            "val Loss: 0.1004 Acc: 0.9627\n",
            "EarlyStopping counter: 2 out of 30\n",
            "\n",
            "Epoch 9/49\n",
            "----------\n",
            "train Loss: 0.1054 Acc: 0.9623\n",
            "val Loss: 0.2748 Acc: 0.9328\n",
            "EarlyStopping counter: 3 out of 30\n",
            "\n",
            "Epoch 10/49\n",
            "----------\n",
            "train Loss: 0.1508 Acc: 0.9528\n",
            "val Loss: 0.1370 Acc: 0.9627\n",
            "EarlyStopping counter: 4 out of 30\n",
            "\n",
            "Epoch 11/49\n",
            "----------\n",
            "train Loss: 0.1539 Acc: 0.9358\n",
            "val Loss: 0.1675 Acc: 0.9328\n",
            "EarlyStopping counter: 5 out of 30\n",
            "\n",
            "Epoch 12/49\n",
            "----------\n",
            "train Loss: 0.1167 Acc: 0.9528\n",
            "val Loss: 0.1455 Acc: 0.9552\n",
            "EarlyStopping counter: 6 out of 30\n",
            "\n",
            "Epoch 13/49\n",
            "----------\n",
            "train Loss: 0.1231 Acc: 0.9547\n",
            "val Loss: 0.2338 Acc: 0.9254\n",
            "EarlyStopping counter: 7 out of 30\n",
            "\n",
            "Epoch 14/49\n",
            "----------\n",
            "train Loss: 0.1554 Acc: 0.9340\n",
            "val Loss: 0.1950 Acc: 0.9179\n",
            "EarlyStopping counter: 8 out of 30\n",
            "\n",
            "Epoch 15/49\n",
            "----------\n",
            "train Loss: 0.1155 Acc: 0.9660\n",
            "val Loss: 0.2519 Acc: 0.8955\n",
            "EarlyStopping counter: 9 out of 30\n",
            "\n",
            "Epoch 16/49\n",
            "----------\n",
            "train Loss: 0.2854 Acc: 0.8868\n",
            "val Loss: 0.2397 Acc: 0.8731\n",
            "EarlyStopping counter: 10 out of 30\n",
            "\n",
            "Epoch 17/49\n",
            "----------\n",
            "train Loss: 0.2200 Acc: 0.9170\n",
            "val Loss: 0.3063 Acc: 0.8806\n",
            "EarlyStopping counter: 11 out of 30\n",
            "\n",
            "Epoch 18/49\n",
            "----------\n",
            "train Loss: 0.1115 Acc: 0.9528\n",
            "val Loss: 0.1013 Acc: 0.9552\n",
            "EarlyStopping counter: 12 out of 30\n",
            "\n",
            "Epoch 19/49\n",
            "----------\n",
            "train Loss: 0.1067 Acc: 0.9623\n",
            "val Loss: 0.1956 Acc: 0.9254\n",
            "EarlyStopping counter: 13 out of 30\n",
            "\n",
            "Epoch 20/49\n",
            "----------\n",
            "train Loss: 0.1787 Acc: 0.9491\n",
            "val Loss: 0.2618 Acc: 0.8955\n",
            "EarlyStopping counter: 14 out of 30\n",
            "\n",
            "Epoch 21/49\n",
            "----------\n",
            "train Loss: 0.1493 Acc: 0.9415\n",
            "val Loss: 0.1129 Acc: 0.9701\n",
            "EarlyStopping counter: 15 out of 30\n",
            "\n",
            "Epoch 22/49\n",
            "----------\n",
            "train Loss: 0.1054 Acc: 0.9604\n",
            "val Loss: 0.2839 Acc: 0.8955\n",
            "EarlyStopping counter: 16 out of 30\n",
            "\n",
            "Epoch 23/49\n",
            "----------\n",
            "train Loss: 0.1540 Acc: 0.9358\n",
            "val Loss: 0.7074 Acc: 0.7537\n",
            "EarlyStopping counter: 17 out of 30\n",
            "\n",
            "Epoch 24/49\n",
            "----------\n",
            "train Loss: 0.2110 Acc: 0.9264\n",
            "val Loss: 0.1506 Acc: 0.9478\n",
            "EarlyStopping counter: 18 out of 30\n",
            "\n",
            "Epoch 25/49\n",
            "----------\n",
            "train Loss: 0.1268 Acc: 0.9491\n",
            "val Loss: 0.2713 Acc: 0.9030\n",
            "EarlyStopping counter: 19 out of 30\n",
            "\n",
            "Epoch 26/49\n",
            "----------\n",
            "train Loss: 0.0900 Acc: 0.9698\n",
            "val Loss: 0.4448 Acc: 0.8657\n",
            "EarlyStopping counter: 20 out of 30\n",
            "\n",
            "Epoch 27/49\n",
            "----------\n",
            "train Loss: 0.1462 Acc: 0.9472\n",
            "val Loss: 0.1794 Acc: 0.9403\n",
            "EarlyStopping counter: 21 out of 30\n",
            "\n",
            "Epoch 28/49\n",
            "----------\n",
            "train Loss: 0.1005 Acc: 0.9642\n",
            "val Loss: 0.8540 Acc: 0.7313\n",
            "EarlyStopping counter: 22 out of 30\n",
            "\n",
            "Epoch 29/49\n",
            "----------\n",
            "train Loss: 0.0889 Acc: 0.9698\n",
            "val Loss: 0.2509 Acc: 0.9328\n",
            "EarlyStopping counter: 23 out of 30\n",
            "\n",
            "Epoch 30/49\n",
            "----------\n",
            "train Loss: 0.0825 Acc: 0.9679\n",
            "val Loss: 0.1848 Acc: 0.9552\n",
            "EarlyStopping counter: 24 out of 30\n",
            "\n",
            "Epoch 31/49\n",
            "----------\n",
            "train Loss: 0.0940 Acc: 0.9623\n",
            "val Loss: 0.2492 Acc: 0.9179\n",
            "EarlyStopping counter: 25 out of 30\n",
            "\n",
            "Epoch 32/49\n",
            "----------\n",
            "train Loss: 0.0786 Acc: 0.9755\n",
            "val Loss: 0.3898 Acc: 0.8657\n",
            "EarlyStopping counter: 26 out of 30\n",
            "\n",
            "Epoch 33/49\n",
            "----------\n",
            "train Loss: 0.0765 Acc: 0.9755\n",
            "val Loss: 0.3341 Acc: 0.9104\n",
            "EarlyStopping counter: 27 out of 30\n",
            "\n",
            "Epoch 34/49\n",
            "----------\n",
            "train Loss: 0.1166 Acc: 0.9604\n",
            "val Loss: 0.4728 Acc: 0.8657\n",
            "EarlyStopping counter: 28 out of 30\n",
            "\n",
            "Epoch 35/49\n",
            "----------\n",
            "train Loss: 0.1223 Acc: 0.9528\n",
            "val Loss: 0.1868 Acc: 0.9403\n",
            "EarlyStopping counter: 29 out of 30\n",
            "\n",
            "Epoch 36/49\n",
            "----------\n",
            "train Loss: 0.0798 Acc: 0.9623\n",
            "val Loss: 0.1571 Acc: 0.9552\n",
            "EarlyStopping counter: 30 out of 30\n",
            "Early stopping\n",
            "Training complete in 2m 21s\n",
            "Best val Acc: 0.977612\n",
            "number of images: 134\n",
            "55 5 74 0\n",
            "Accuracy: 0.9626865671641791\n",
            "Precision (positive predictive value): 1.0\n",
            "Recall (sensitivity): 0.9166666666666666\n",
            "Specificity: 1.0\n",
            "F_value: 0.9565217391304348\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "134\n",
            "[0.0005956888198852539, 0.0005135536193847656, 0.00021332502365112305, 0.00010716915130615234, 0.06445670127868652, 0.00039702653884887695, 7.641315460205078e-05, 0.031867265701293945, 9.274482727050781e-05, 0.004763007164001465, 0.06948858499526978, 0.01745736598968506, 0.003082275390625, 0.00038552284240722656, 0.007202565670013428, 0.004655659198760986, 0.004308879375457764, 0.056131601333618164, 0.013135731220245361, 0.0008125901222229004, 6.306171417236328e-05, 0.012425720691680908, 0.0015456676483154297, 0.12758570909500122, 0.040521442890167236, 0.049607694149017334, 0.004503726959228516, 0.16027379035949707, 0.0012511014938354492, 0.027381598949432373, 0.012805521488189697, 0.06655663251876831, 0.0005739927291870117, 0.005145430564880371, 0.03353321552276611, 8.654594421386719e-05, 0.0008513927459716797, 0.0054018497467041016, 0.00813978910446167, 0.01805335283279419, 0.002460956573486328, 0.08383691310882568, 0.0017078518867492676, 0.010717511177062988, 0.2467237114906311, 0.0012118220329284668, 0.002291083335876465, 0.00036966800689697266, 0.004311740398406982, 0.016156136989593506, 0.0005322098731994629, 0.0008363723754882812, 0.003906667232513428, 0.027142345905303955, 0.000850677490234375, 0.00833117961883545, 0.009689509868621826, 0.0002484917640686035, 0.0009177923202514648, 0.005816519260406494, 0.000599980354309082, 0.0002942681312561035, 0.001813352108001709, 0.0012824535369873047, 0.0008948445320129395, 7.021427154541016e-05, 0.0005806684494018555, 0.025907933712005615, 0.013603448867797852, 0.033033132553100586, 0.028669536113739014, 0.005264878273010254, 0.00345534086227417, 0.0008445978164672852, 0.8494893312454224, 0.9999942779541016, 0.19289064407348633, 0.8518865704536438, 0.9999064207077026, 0.9809126257896423, 0.5077145099639893, 0.9999572038650513, 0.9999940395355225, 0.9972817897796631, 0.9623528122901917, 0.9986578226089478, 0.6273092031478882, 0.9999948740005493, 0.9999998807907104, 0.9903222918510437, 0.9907010793685913, 0.03549009561538696, 0.9995689988136292, 0.9981387853622437, 0.2763206958770752, 0.9978916049003601, 0.956060528755188, 0.9999816417694092, 0.9994809031486511, 0.729006826877594, 0.9993731379508972, 0.13918852806091309, 0.9996825456619263, 0.9950215816497803, 0.9993003606796265, 0.9964392781257629, 0.9966666102409363, 0.999985933303833, 0.9896323680877686, 0.9693845510482788, 0.9997687935829163, 0.9827837944030762, 0.9999327659606934, 0.2953779101371765, 0.9956629872322083, 0.9941228032112122, 0.9999794960021973, 0.9999110698699951, 0.9998519420623779, 0.9960740804672241, 0.9999985694885254, 0.8392906785011292, 0.9721096158027649, 0.9765987396240234, 0.9999570846557617, 0.983064591884613, 0.9998397827148438, 0.9883282780647278, 0.5786802768707275, 0.941440224647522, 0.9997392296791077, 0.9734941720962524, 0.955141544342041, 0.8357551097869873]\n",
            "134\n",
            "roc_auc: 0.9970720720720722\n",
            "\n",
            "\n",
            "['cont', 'eso']\n",
            "cont_train:293\n",
            "eso_train:238\n",
            "cont_val:73\n",
            "eso_val:60\n",
            "training data set_total：531\n",
            "validating data set_total：133\n",
            "Epoch 0/49\n",
            "----------\n",
            "train Loss: 0.1392 Acc: 0.9435\n",
            "val Loss: 0.0789 Acc: 0.9624\n",
            "Validation loss decreased (inf --> 0.078924).  Saving model ...\n",
            "\n",
            "Epoch 1/49\n",
            "----------\n",
            "train Loss: 0.1672 Acc: 0.9435\n",
            "val Loss: 0.0924 Acc: 0.9624\n",
            "EarlyStopping counter: 1 out of 30\n",
            "\n",
            "Epoch 2/49\n",
            "----------\n",
            "train Loss: 0.1423 Acc: 0.9360\n",
            "val Loss: 0.1145 Acc: 0.9624\n",
            "EarlyStopping counter: 2 out of 30\n",
            "\n",
            "Epoch 3/49\n",
            "----------\n",
            "train Loss: 0.1462 Acc: 0.9492\n",
            "val Loss: 0.0835 Acc: 0.9774\n",
            "EarlyStopping counter: 3 out of 30\n",
            "\n",
            "Epoch 4/49\n",
            "----------\n",
            "train Loss: 0.1046 Acc: 0.9699\n",
            "val Loss: 0.0551 Acc: 0.9774\n",
            "Validation loss decreased (0.078924 --> 0.055109).  Saving model ...\n",
            "\n",
            "Epoch 5/49\n",
            "----------\n",
            "train Loss: 0.1486 Acc: 0.9397\n",
            "val Loss: 0.3546 Acc: 0.8571\n",
            "EarlyStopping counter: 1 out of 30\n",
            "\n",
            "Epoch 6/49\n",
            "----------\n",
            "train Loss: 0.1504 Acc: 0.9454\n",
            "val Loss: 0.1283 Acc: 0.9398\n",
            "EarlyStopping counter: 2 out of 30\n",
            "\n",
            "Epoch 7/49\n",
            "----------\n",
            "train Loss: 0.1271 Acc: 0.9454\n",
            "val Loss: 0.5591 Acc: 0.8421\n",
            "EarlyStopping counter: 3 out of 30\n",
            "\n",
            "Epoch 8/49\n",
            "----------\n",
            "train Loss: 0.2562 Acc: 0.9058\n",
            "val Loss: 0.1292 Acc: 0.9474\n",
            "EarlyStopping counter: 4 out of 30\n",
            "\n",
            "Epoch 9/49\n",
            "----------\n",
            "train Loss: 0.1466 Acc: 0.9360\n",
            "val Loss: 0.1978 Acc: 0.9323\n",
            "EarlyStopping counter: 5 out of 30\n",
            "\n",
            "Epoch 10/49\n",
            "----------\n",
            "train Loss: 0.1412 Acc: 0.9435\n",
            "val Loss: 0.1624 Acc: 0.9549\n",
            "EarlyStopping counter: 6 out of 30\n",
            "\n",
            "Epoch 11/49\n",
            "----------\n",
            "train Loss: 0.2224 Acc: 0.9171\n",
            "val Loss: 0.2012 Acc: 0.9173\n",
            "EarlyStopping counter: 7 out of 30\n",
            "\n",
            "Epoch 12/49\n",
            "----------\n",
            "train Loss: 0.1989 Acc: 0.9190\n",
            "val Loss: 0.1326 Acc: 0.9624\n",
            "EarlyStopping counter: 8 out of 30\n",
            "\n",
            "Epoch 13/49\n",
            "----------\n",
            "train Loss: 0.1219 Acc: 0.9510\n",
            "val Loss: 0.1025 Acc: 0.9549\n",
            "EarlyStopping counter: 9 out of 30\n",
            "\n",
            "Epoch 14/49\n",
            "----------\n",
            "train Loss: 0.1215 Acc: 0.9586\n",
            "val Loss: 0.1056 Acc: 0.9398\n",
            "EarlyStopping counter: 10 out of 30\n",
            "\n",
            "Epoch 15/49\n",
            "----------\n",
            "train Loss: 0.1074 Acc: 0.9567\n",
            "val Loss: 0.1389 Acc: 0.9624\n",
            "EarlyStopping counter: 11 out of 30\n",
            "\n",
            "Epoch 16/49\n",
            "----------\n",
            "train Loss: 0.1744 Acc: 0.9416\n",
            "val Loss: 0.1531 Acc: 0.9549\n",
            "EarlyStopping counter: 12 out of 30\n",
            "\n",
            "Epoch 17/49\n",
            "----------\n",
            "train Loss: 0.0821 Acc: 0.9736\n",
            "val Loss: 0.1631 Acc: 0.9398\n",
            "EarlyStopping counter: 13 out of 30\n",
            "\n",
            "Epoch 18/49\n",
            "----------\n",
            "train Loss: 0.0892 Acc: 0.9605\n",
            "val Loss: 0.0620 Acc: 0.9774\n",
            "EarlyStopping counter: 14 out of 30\n",
            "\n",
            "Epoch 19/49\n",
            "----------\n",
            "train Loss: 0.0542 Acc: 0.9831\n",
            "val Loss: 0.5350 Acc: 0.8797\n",
            "EarlyStopping counter: 15 out of 30\n",
            "\n",
            "Epoch 20/49\n",
            "----------\n",
            "train Loss: 0.1057 Acc: 0.9642\n",
            "val Loss: 0.5782 Acc: 0.8421\n",
            "EarlyStopping counter: 16 out of 30\n",
            "\n",
            "Epoch 21/49\n",
            "----------\n",
            "train Loss: 0.2294 Acc: 0.9153\n",
            "val Loss: 0.1564 Acc: 0.9474\n",
            "EarlyStopping counter: 17 out of 30\n",
            "\n",
            "Epoch 22/49\n",
            "----------\n",
            "train Loss: 0.1537 Acc: 0.9416\n",
            "val Loss: 0.1875 Acc: 0.9323\n",
            "EarlyStopping counter: 18 out of 30\n",
            "\n",
            "Epoch 23/49\n",
            "----------\n",
            "train Loss: 0.1301 Acc: 0.9492\n",
            "val Loss: 0.3207 Acc: 0.8496\n",
            "EarlyStopping counter: 19 out of 30\n",
            "\n",
            "Epoch 24/49\n",
            "----------\n",
            "train Loss: 0.1296 Acc: 0.9492\n",
            "val Loss: 0.1029 Acc: 0.9549\n",
            "EarlyStopping counter: 20 out of 30\n",
            "\n",
            "Epoch 25/49\n",
            "----------\n",
            "train Loss: 0.1336 Acc: 0.9548\n",
            "val Loss: 0.2360 Acc: 0.9248\n",
            "EarlyStopping counter: 21 out of 30\n",
            "\n",
            "Epoch 26/49\n",
            "----------\n",
            "train Loss: 0.0848 Acc: 0.9642\n",
            "val Loss: 0.2046 Acc: 0.9549\n",
            "EarlyStopping counter: 22 out of 30\n",
            "\n",
            "Epoch 27/49\n",
            "----------\n",
            "train Loss: 0.0837 Acc: 0.9680\n",
            "val Loss: 0.1265 Acc: 0.9398\n",
            "EarlyStopping counter: 23 out of 30\n",
            "\n",
            "Epoch 28/49\n",
            "----------\n",
            "train Loss: 0.0940 Acc: 0.9605\n",
            "val Loss: 0.1703 Acc: 0.9398\n",
            "EarlyStopping counter: 24 out of 30\n",
            "\n",
            "Epoch 29/49\n",
            "----------\n",
            "train Loss: 0.1266 Acc: 0.9548\n",
            "val Loss: 0.1919 Acc: 0.9248\n",
            "EarlyStopping counter: 25 out of 30\n",
            "\n",
            "Epoch 30/49\n",
            "----------\n",
            "train Loss: 0.0760 Acc: 0.9774\n",
            "val Loss: 0.1677 Acc: 0.9323\n",
            "EarlyStopping counter: 26 out of 30\n",
            "\n",
            "Epoch 31/49\n",
            "----------\n",
            "train Loss: 0.1291 Acc: 0.9586\n",
            "val Loss: 0.1574 Acc: 0.9248\n",
            "EarlyStopping counter: 27 out of 30\n",
            "\n",
            "Epoch 32/49\n",
            "----------\n",
            "train Loss: 0.1059 Acc: 0.9623\n",
            "val Loss: 0.1556 Acc: 0.9474\n",
            "EarlyStopping counter: 28 out of 30\n",
            "\n",
            "Epoch 33/49\n",
            "----------\n",
            "train Loss: 0.1445 Acc: 0.9360\n",
            "val Loss: 0.2331 Acc: 0.8797\n",
            "EarlyStopping counter: 29 out of 30\n",
            "\n",
            "Epoch 34/49\n",
            "----------\n",
            "train Loss: 0.1448 Acc: 0.9454\n",
            "val Loss: 0.4217 Acc: 0.8647\n",
            "EarlyStopping counter: 30 out of 30\n",
            "Early stopping\n",
            "Training complete in 2m 14s\n",
            "Best val Acc: 0.977444\n",
            "number of images: 133\n",
            "57 3 68 5\n",
            "Accuracy: 0.9398496240601504\n",
            "Precision (positive predictive value): 0.9193548387096774\n",
            "Recall (sensitivity): 0.95\n",
            "Specificity: 0.9315068493150684\n",
            "F_value: 0.9344262295081968\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "133\n",
            "[0.006621003150939941, 0.03331571817398071, 0.04889380931854248, 0.2833539843559265, 0.14312142133712769, 0.02017146348953247, 0.006526529788970947, 0.026690185070037842, 0.05203604698181152, 0.053369998931884766, 0.03671693801879883, 0.008647680282592773, 0.7144037485122681, 0.046978771686553955, 0.40230733156204224, 0.012285947799682617, 0.22609561681747437, 0.009954750537872314, 0.0044367313385009766, 0.00681459903717041, 0.051555335521698, 0.04826396703720093, 0.050946056842803955, 0.025014221668243408, 0.026848793029785156, 0.18152445554733276, 0.09959191083908081, 0.024509549140930176, 0.025941073894500732, 0.022351205348968506, 0.07964354753494263, 0.03724318742752075, 0.04671269655227661, 0.03233146667480469, 0.05145227909088135, 0.00840151309967041, 0.032051920890808105, 0.1698666214942932, 0.026576578617095947, 0.006841838359832764, 0.013882100582122803, 0.23865073919296265, 0.11977052688598633, 0.030189573764801025, 0.10330456495285034, 0.03663516044616699, 0.1311834454536438, 0.02182084321975708, 0.018386006355285645, 0.3761882781982422, 0.5056869983673096, 0.22501957416534424, 0.21243435144424438, 0.005774199962615967, 0.028335511684417725, 0.10406243801116943, 0.14103984832763672, 0.015561878681182861, 0.01820164918899536, 0.013893365859985352, 0.22070449590682983, 0.013679802417755127, 0.005833745002746582, 0.6416909098625183, 0.04337131977081299, 0.07362949848175049, 0.07719898223876953, 0.41921496391296387, 0.010644912719726562, 0.03478693962097168, 0.6291109919548035, 0.5570988059043884, 0.01797384023666382, 0.9546845555305481, 0.9999243021011353, 0.8703113198280334, 0.999942421913147, 0.999977707862854, 0.9993539452552795, 0.9999980926513672, 0.9743485450744629, 0.47647857666015625, 0.9996793270111084, 0.9923937320709229, 0.9954203963279724, 0.9862619042396545, 0.9996657371520996, 0.9959158301353455, 0.3468133211135864, 0.9998959302902222, 0.9835078716278076, 0.9997718930244446, 0.9892742037773132, 0.9968446493148804, 0.9992468357086182, 0.9970676302909851, 0.9999986886978149, 0.9991315007209778, 0.9999892711639404, 0.6677480936050415, 0.9988850951194763, 0.5745691061019897, 0.9867317080497742, 0.9999932050704956, 0.9949374198913574, 0.9718819856643677, 0.9999164342880249, 0.9919430017471313, 0.9999955892562866, 0.9762769341468811, 0.9978799819946289, 0.4694923162460327, 0.9877712726593018, 0.9931001663208008, 0.9888432025909424, 0.9461086392402649, 0.9951609969139099, 0.9975574016571045, 0.9999475479125977, 0.998964786529541, 0.9929581880569458, 0.9996622800827026, 0.9920137524604797, 0.9453786015510559, 0.9999234676361084, 0.9977389574050903, 0.9999985694885254, 0.9917218089103699, 0.756870687007904, 0.9999974966049194, 0.9881133437156677, 0.9912554025650024, 0.9953069090843201]\n",
            "133\n",
            "roc_auc: 0.9949771689497717\n",
            "\n",
            "\n",
            "['cont', 'eso']\n",
            "cont_train:293\n",
            "eso_train:238\n",
            "cont_val:73\n",
            "eso_val:60\n",
            "training data set_total：531\n",
            "validating data set_total：133\n",
            "Epoch 0/49\n",
            "----------\n",
            "train Loss: 0.1602 Acc: 0.9284\n",
            "val Loss: 0.6759 Acc: 0.7519\n",
            "Validation loss decreased (inf --> 0.675925).  Saving model ...\n",
            "\n",
            "Epoch 1/49\n",
            "----------\n",
            "train Loss: 0.1318 Acc: 0.9548\n",
            "val Loss: 0.1459 Acc: 0.9398\n",
            "Validation loss decreased (0.675925 --> 0.145889).  Saving model ...\n",
            "\n",
            "Epoch 2/49\n",
            "----------\n",
            "train Loss: 0.1092 Acc: 0.9586\n",
            "val Loss: 0.1199 Acc: 0.9549\n",
            "Validation loss decreased (0.145889 --> 0.119929).  Saving model ...\n",
            "\n",
            "Epoch 3/49\n",
            "----------\n",
            "train Loss: 0.1214 Acc: 0.9510\n",
            "val Loss: 0.1829 Acc: 0.9248\n",
            "EarlyStopping counter: 1 out of 30\n",
            "\n",
            "Epoch 4/49\n",
            "----------\n",
            "train Loss: 0.1142 Acc: 0.9510\n",
            "val Loss: 0.1414 Acc: 0.9398\n",
            "EarlyStopping counter: 2 out of 30\n",
            "\n",
            "Epoch 5/49\n",
            "----------\n",
            "train Loss: 0.0738 Acc: 0.9661\n",
            "val Loss: 0.1716 Acc: 0.9549\n",
            "EarlyStopping counter: 3 out of 30\n",
            "\n",
            "Epoch 6/49\n",
            "----------\n",
            "train Loss: 0.0978 Acc: 0.9718\n",
            "val Loss: 0.0975 Acc: 0.9624\n",
            "Validation loss decreased (0.119929 --> 0.097472).  Saving model ...\n",
            "\n",
            "Epoch 7/49\n",
            "----------\n",
            "train Loss: 0.1170 Acc: 0.9548\n",
            "val Loss: 0.2121 Acc: 0.9323\n",
            "EarlyStopping counter: 1 out of 30\n",
            "\n",
            "Epoch 8/49\n",
            "----------\n",
            "train Loss: 0.0896 Acc: 0.9586\n",
            "val Loss: 0.0919 Acc: 0.9699\n",
            "Validation loss decreased (0.097472 --> 0.091914).  Saving model ...\n",
            "\n",
            "Epoch 9/49\n",
            "----------\n",
            "train Loss: 0.0613 Acc: 0.9755\n",
            "val Loss: 0.0645 Acc: 0.9850\n",
            "Validation loss decreased (0.091914 --> 0.064535).  Saving model ...\n",
            "\n",
            "Epoch 10/49\n",
            "----------\n",
            "train Loss: 0.0913 Acc: 0.9661\n",
            "val Loss: 0.0706 Acc: 0.9624\n",
            "EarlyStopping counter: 1 out of 30\n",
            "\n",
            "Epoch 11/49\n",
            "----------\n",
            "train Loss: 0.0949 Acc: 0.9642\n",
            "val Loss: 0.2498 Acc: 0.9323\n",
            "EarlyStopping counter: 2 out of 30\n",
            "\n",
            "Epoch 12/49\n",
            "----------\n",
            "train Loss: 0.0861 Acc: 0.9680\n",
            "val Loss: 0.0873 Acc: 0.9624\n",
            "EarlyStopping counter: 3 out of 30\n",
            "\n",
            "Epoch 13/49\n",
            "----------\n",
            "train Loss: 0.0890 Acc: 0.9680\n",
            "val Loss: 0.9442 Acc: 0.8045\n",
            "EarlyStopping counter: 4 out of 30\n",
            "\n",
            "Epoch 14/49\n",
            "----------\n",
            "train Loss: 0.1414 Acc: 0.9548\n",
            "val Loss: 0.2041 Acc: 0.9098\n",
            "EarlyStopping counter: 5 out of 30\n",
            "\n",
            "Epoch 15/49\n",
            "----------\n",
            "train Loss: 0.0711 Acc: 0.9661\n",
            "val Loss: 0.0673 Acc: 0.9699\n",
            "EarlyStopping counter: 6 out of 30\n",
            "\n",
            "Epoch 16/49\n",
            "----------\n",
            "train Loss: 0.0838 Acc: 0.9623\n",
            "val Loss: 0.2085 Acc: 0.9023\n",
            "EarlyStopping counter: 7 out of 30\n",
            "\n",
            "Epoch 17/49\n",
            "----------\n",
            "train Loss: 0.0861 Acc: 0.9642\n",
            "val Loss: 0.1194 Acc: 0.9624\n",
            "EarlyStopping counter: 8 out of 30\n",
            "\n",
            "Epoch 18/49\n",
            "----------\n",
            "train Loss: 0.0864 Acc: 0.9812\n",
            "val Loss: 0.3214 Acc: 0.8722\n",
            "EarlyStopping counter: 9 out of 30\n",
            "\n",
            "Epoch 19/49\n",
            "----------\n",
            "train Loss: 0.0726 Acc: 0.9699\n",
            "val Loss: 0.1460 Acc: 0.9398\n",
            "EarlyStopping counter: 10 out of 30\n",
            "\n",
            "Epoch 20/49\n",
            "----------\n",
            "train Loss: 0.0356 Acc: 0.9868\n",
            "val Loss: 0.2054 Acc: 0.9323\n",
            "EarlyStopping counter: 11 out of 30\n",
            "\n",
            "Epoch 21/49\n",
            "----------\n",
            "train Loss: 0.0588 Acc: 0.9755\n",
            "val Loss: 0.3178 Acc: 0.9098\n",
            "EarlyStopping counter: 12 out of 30\n",
            "\n",
            "Epoch 22/49\n",
            "----------\n",
            "train Loss: 0.0890 Acc: 0.9642\n",
            "val Loss: 0.1108 Acc: 0.9549\n",
            "EarlyStopping counter: 13 out of 30\n",
            "\n",
            "Epoch 23/49\n",
            "----------\n",
            "train Loss: 0.0937 Acc: 0.9661\n",
            "val Loss: 0.2241 Acc: 0.9248\n",
            "EarlyStopping counter: 14 out of 30\n",
            "\n",
            "Epoch 24/49\n",
            "----------\n",
            "train Loss: 0.0824 Acc: 0.9661\n",
            "val Loss: 0.3945 Acc: 0.8872\n",
            "EarlyStopping counter: 15 out of 30\n",
            "\n",
            "Epoch 25/49\n",
            "----------\n",
            "train Loss: 0.1213 Acc: 0.9567\n",
            "val Loss: 0.2940 Acc: 0.9173\n",
            "EarlyStopping counter: 16 out of 30\n",
            "\n",
            "Epoch 26/49\n",
            "----------\n",
            "train Loss: 0.1499 Acc: 0.9379\n",
            "val Loss: 0.1799 Acc: 0.9323\n",
            "EarlyStopping counter: 17 out of 30\n",
            "\n",
            "Epoch 27/49\n",
            "----------\n",
            "train Loss: 0.0898 Acc: 0.9680\n",
            "val Loss: 0.2438 Acc: 0.8947\n",
            "EarlyStopping counter: 18 out of 30\n",
            "\n",
            "Epoch 28/49\n",
            "----------\n",
            "train Loss: 0.0612 Acc: 0.9755\n",
            "val Loss: 0.2512 Acc: 0.9173\n",
            "EarlyStopping counter: 19 out of 30\n",
            "\n",
            "Epoch 29/49\n",
            "----------\n",
            "train Loss: 0.0683 Acc: 0.9736\n",
            "val Loss: 0.2098 Acc: 0.9398\n",
            "EarlyStopping counter: 20 out of 30\n",
            "\n",
            "Epoch 30/49\n",
            "----------\n",
            "train Loss: 0.0618 Acc: 0.9831\n",
            "val Loss: 0.1571 Acc: 0.9248\n",
            "EarlyStopping counter: 21 out of 30\n",
            "\n",
            "Epoch 31/49\n",
            "----------\n",
            "train Loss: 0.0491 Acc: 0.9887\n",
            "val Loss: 0.0991 Acc: 0.9624\n",
            "EarlyStopping counter: 22 out of 30\n",
            "\n",
            "Epoch 32/49\n",
            "----------\n",
            "train Loss: 0.0665 Acc: 0.9793\n",
            "val Loss: 0.1800 Acc: 0.9474\n",
            "EarlyStopping counter: 23 out of 30\n",
            "\n",
            "Epoch 33/49\n",
            "----------\n",
            "train Loss: 0.0408 Acc: 0.9868\n",
            "val Loss: 0.2711 Acc: 0.9173\n",
            "EarlyStopping counter: 24 out of 30\n",
            "\n",
            "Epoch 34/49\n",
            "----------\n",
            "train Loss: 0.0816 Acc: 0.9699\n",
            "val Loss: 0.3077 Acc: 0.9098\n",
            "EarlyStopping counter: 25 out of 30\n",
            "\n",
            "Epoch 35/49\n",
            "----------\n",
            "train Loss: 0.0616 Acc: 0.9774\n",
            "val Loss: 0.2043 Acc: 0.9323\n",
            "EarlyStopping counter: 26 out of 30\n",
            "\n",
            "Epoch 36/49\n",
            "----------\n",
            "train Loss: 0.1335 Acc: 0.9586\n",
            "val Loss: 0.2979 Acc: 0.8722\n",
            "EarlyStopping counter: 27 out of 30\n",
            "\n",
            "Epoch 37/49\n",
            "----------\n",
            "train Loss: 0.0753 Acc: 0.9699\n",
            "val Loss: 0.1096 Acc: 0.9699\n",
            "EarlyStopping counter: 28 out of 30\n",
            "\n",
            "Epoch 38/49\n",
            "----------\n",
            "train Loss: 0.0742 Acc: 0.9699\n",
            "val Loss: 0.1531 Acc: 0.9398\n",
            "EarlyStopping counter: 29 out of 30\n",
            "\n",
            "Epoch 39/49\n",
            "----------\n",
            "train Loss: 0.0551 Acc: 0.9774\n",
            "val Loss: 0.1565 Acc: 0.9474\n",
            "EarlyStopping counter: 30 out of 30\n",
            "Early stopping\n",
            "Training complete in 2m 34s\n",
            "Best val Acc: 0.984962\n",
            "number of images: 133\n",
            "59 1 72 1\n",
            "Accuracy: 0.9849624060150376\n",
            "Precision (positive predictive value): 0.9833333333333333\n",
            "Recall (sensitivity): 0.9833333333333333\n",
            "Specificity: 0.9863013698630136\n",
            "F_value: 0.9833333333333333\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "133\n",
            "[0.0030251741409301758, 0.00047135353088378906, 0.0016394257545471191, 0.00023549795150756836, 0.0011140704154968262, 0.006234407424926758, 0.00015115737915039062, 0.00028818845748901367, 0.9871217608451843, 0.004055798053741455, 0.0019896626472473145, 0.02372986078262329, 0.1448184847831726, 0.0011910200119018555, 0.0016391873359680176, 0.0877874493598938, 0.00645977258682251, 0.0011333227157592773, 9.465217590332031e-05, 0.03233206272125244, 0.008159399032592773, 0.0558968186378479, 0.021286964416503906, 0.0002695918083190918, 0.028815269470214844, 0.002657949924468994, 0.0007417798042297363, 0.06895822286605835, 0.0008910298347473145, 0.011855781078338623, 0.00023943185806274414, 0.003021836280822754, 0.0002697110176086426, 3.063678741455078e-05, 0.0005731582641601562, 0.004107117652893066, 8.106231689453125e-05, 0.045241355895996094, 8.797645568847656e-05, 0.00012993812561035156, 0.22241926193237305, 0.3530343770980835, 0.00015044212341308594, 6.258487701416016e-05, 0.008038580417633057, 0.12381476163864136, 0.0022463202476501465, 0.06896257400512695, 0.16239947080612183, 0.0021744370460510254, 0.0084916353225708, 0.0006177425384521484, 0.04871708154678345, 0.006669461727142334, 0.00043708086013793945, 4.506111145019531e-05, 0.012482106685638428, 0.0007925629615783691, 0.00021058320999145508, 0.0004532933235168457, 0.008277714252471924, 0.04875415563583374, 0.0014729499816894531, 0.01761925220489502, 0.007468044757843018, 0.0037082433700561523, 0.00021570920944213867, 0.0011456012725830078, 0.0048487186431884766, 4.887580871582031e-05, 0.0002225041389465332, 0.002556443214416504, 0.0026875734329223633, 0.9999979734420776, 0.9999978542327881, 0.9999994039535522, 0.999994158744812, 0.9988290667533875, 0.9925064444541931, 0.9993780851364136, 0.9980732202529907, 0.9999960660934448, 0.9999926090240479, 0.9999710321426392, 0.9992374181747437, 0.5609615445137024, 0.9999974966049194, 0.9999912977218628, 0.9999966621398926, 0.9999994039535522, 0.9998841285705566, 0.9987155199050903, 0.9995225667953491, 0.08385765552520752, 0.9915747046470642, 0.9998617172241211, 0.9999998807907104, 0.9999996423721313, 0.8792659640312195, 1.0, 0.9999768733978271, 0.9736812710762024, 0.9924615025520325, 0.9999991655349731, 1.0, 0.7807040214538574, 0.9999943971633911, 0.998988926410675, 0.9998822212219238, 0.9999673366546631, 0.9999996423721313, 0.9999138116836548, 0.9999935626983643, 0.9999964237213135, 0.9996689558029175, 0.9980660080909729, 0.9999129772186279, 0.9838323593139648, 0.6718447804450989, 0.9860084652900696, 0.9999998807907104, 0.9989405274391174, 0.9999915361404419, 0.9999293088912964, 1.0, 0.9996665716171265, 1.0, 0.9999825954437256, 0.999997615814209, 0.9999370574951172, 0.9999613761901855, 0.999930739402771, 0.9999268054962158]\n",
            "133\n",
            "roc_auc: 0.9968036529680365\n",
            "\n",
            "\n",
            "['cont', 'eso']\n",
            "cont_train:293\n",
            "eso_train:239\n",
            "cont_val:73\n",
            "eso_val:59\n",
            "training data set_total：532\n",
            "validating data set_total：132\n",
            "Epoch 0/49\n",
            "----------\n",
            "train Loss: 0.0660 Acc: 0.9756\n",
            "val Loss: 0.2851 Acc: 0.9015\n",
            "Validation loss decreased (inf --> 0.285136).  Saving model ...\n",
            "\n",
            "Epoch 1/49\n",
            "----------\n",
            "train Loss: 0.0996 Acc: 0.9680\n",
            "val Loss: 0.0901 Acc: 0.9697\n",
            "Validation loss decreased (0.285136 --> 0.090105).  Saving model ...\n",
            "\n",
            "Epoch 2/49\n",
            "----------\n",
            "train Loss: 0.1706 Acc: 0.9323\n",
            "val Loss: 0.1509 Acc: 0.9318\n",
            "EarlyStopping counter: 1 out of 30\n",
            "\n",
            "Epoch 3/49\n",
            "----------\n",
            "train Loss: 0.1357 Acc: 0.9492\n",
            "val Loss: 0.3167 Acc: 0.9242\n",
            "EarlyStopping counter: 2 out of 30\n",
            "\n",
            "Epoch 4/49\n",
            "----------\n",
            "train Loss: 0.1622 Acc: 0.9530\n",
            "val Loss: 0.1971 Acc: 0.9318\n",
            "EarlyStopping counter: 3 out of 30\n",
            "\n",
            "Epoch 5/49\n",
            "----------\n",
            "train Loss: 0.0924 Acc: 0.9662\n",
            "val Loss: 0.1004 Acc: 0.9545\n",
            "EarlyStopping counter: 4 out of 30\n",
            "\n",
            "Epoch 6/49\n",
            "----------\n",
            "train Loss: 0.0498 Acc: 0.9868\n",
            "val Loss: 0.1514 Acc: 0.9394\n",
            "EarlyStopping counter: 5 out of 30\n",
            "\n",
            "Epoch 7/49\n",
            "----------\n",
            "train Loss: 0.1089 Acc: 0.9586\n",
            "val Loss: 0.1385 Acc: 0.9470\n",
            "EarlyStopping counter: 6 out of 30\n",
            "\n",
            "Epoch 8/49\n",
            "----------\n",
            "train Loss: 0.1513 Acc: 0.9492\n",
            "val Loss: 0.0861 Acc: 0.9621\n",
            "Validation loss decreased (0.090105 --> 0.086112).  Saving model ...\n",
            "\n",
            "Epoch 9/49\n",
            "----------\n",
            "train Loss: 0.1216 Acc: 0.9624\n",
            "val Loss: 0.0831 Acc: 0.9773\n",
            "Validation loss decreased (0.086112 --> 0.083051).  Saving model ...\n",
            "\n",
            "Epoch 10/49\n",
            "----------\n",
            "train Loss: 0.0584 Acc: 0.9831\n",
            "val Loss: 0.1380 Acc: 0.9242\n",
            "EarlyStopping counter: 1 out of 30\n",
            "\n",
            "Epoch 11/49\n",
            "----------\n",
            "train Loss: 0.0828 Acc: 0.9812\n",
            "val Loss: 0.1314 Acc: 0.9470\n",
            "EarlyStopping counter: 2 out of 30\n",
            "\n",
            "Epoch 12/49\n",
            "----------\n",
            "train Loss: 0.1132 Acc: 0.9662\n",
            "val Loss: 0.4957 Acc: 0.8485\n",
            "EarlyStopping counter: 3 out of 30\n",
            "\n",
            "Epoch 13/49\n",
            "----------\n",
            "train Loss: 0.0657 Acc: 0.9756\n",
            "val Loss: 0.2097 Acc: 0.9242\n",
            "EarlyStopping counter: 4 out of 30\n",
            "\n",
            "Epoch 14/49\n",
            "----------\n",
            "train Loss: 0.0960 Acc: 0.9680\n",
            "val Loss: 0.1628 Acc: 0.9167\n",
            "EarlyStopping counter: 5 out of 30\n",
            "\n",
            "Epoch 15/49\n",
            "----------\n",
            "train Loss: 0.0641 Acc: 0.9774\n",
            "val Loss: 0.0665 Acc: 0.9697\n",
            "Validation loss decreased (0.083051 --> 0.066548).  Saving model ...\n",
            "\n",
            "Epoch 16/49\n",
            "----------\n",
            "train Loss: 0.0788 Acc: 0.9756\n",
            "val Loss: 0.0891 Acc: 0.9621\n",
            "EarlyStopping counter: 1 out of 30\n",
            "\n",
            "Epoch 17/49\n",
            "----------\n",
            "train Loss: 0.0635 Acc: 0.9793\n",
            "val Loss: 0.2670 Acc: 0.9091\n",
            "EarlyStopping counter: 2 out of 30\n",
            "\n",
            "Epoch 18/49\n",
            "----------\n",
            "train Loss: 0.1163 Acc: 0.9680\n",
            "val Loss: 0.3255 Acc: 0.8864\n",
            "EarlyStopping counter: 3 out of 30\n",
            "\n",
            "Epoch 19/49\n",
            "----------\n",
            "train Loss: 0.0807 Acc: 0.9737\n",
            "val Loss: 0.0856 Acc: 0.9545\n",
            "EarlyStopping counter: 4 out of 30\n",
            "\n",
            "Epoch 20/49\n",
            "----------\n",
            "train Loss: 0.0627 Acc: 0.9718\n",
            "val Loss: 0.1916 Acc: 0.9242\n",
            "EarlyStopping counter: 5 out of 30\n",
            "\n",
            "Epoch 21/49\n",
            "----------\n",
            "train Loss: 0.0487 Acc: 0.9887\n",
            "val Loss: 1.6177 Acc: 0.7273\n",
            "EarlyStopping counter: 6 out of 30\n",
            "\n",
            "Epoch 22/49\n",
            "----------\n",
            "train Loss: 0.0869 Acc: 0.9718\n",
            "val Loss: 0.1683 Acc: 0.9545\n",
            "EarlyStopping counter: 7 out of 30\n",
            "\n",
            "Epoch 23/49\n",
            "----------\n",
            "train Loss: 0.0778 Acc: 0.9737\n",
            "val Loss: 0.1295 Acc: 0.9470\n",
            "EarlyStopping counter: 8 out of 30\n",
            "\n",
            "Epoch 24/49\n",
            "----------\n",
            "train Loss: 0.0848 Acc: 0.9756\n",
            "val Loss: 0.2211 Acc: 0.9394\n",
            "EarlyStopping counter: 9 out of 30\n",
            "\n",
            "Epoch 25/49\n",
            "----------\n",
            "train Loss: 0.0687 Acc: 0.9737\n",
            "val Loss: 0.2269 Acc: 0.9091\n",
            "EarlyStopping counter: 10 out of 30\n",
            "\n",
            "Epoch 26/49\n",
            "----------\n",
            "train Loss: 0.0963 Acc: 0.9699\n",
            "val Loss: 0.1132 Acc: 0.9545\n",
            "EarlyStopping counter: 11 out of 30\n",
            "\n",
            "Epoch 27/49\n",
            "----------\n",
            "train Loss: 0.0616 Acc: 0.9737\n",
            "val Loss: 0.1601 Acc: 0.9394\n",
            "EarlyStopping counter: 12 out of 30\n",
            "\n",
            "Epoch 28/49\n",
            "----------\n",
            "train Loss: 0.0777 Acc: 0.9699\n",
            "val Loss: 0.1525 Acc: 0.9621\n",
            "EarlyStopping counter: 13 out of 30\n",
            "\n",
            "Epoch 29/49\n",
            "----------\n",
            "train Loss: 0.0501 Acc: 0.9793\n",
            "val Loss: 0.1571 Acc: 0.9394\n",
            "EarlyStopping counter: 14 out of 30\n",
            "\n",
            "Epoch 30/49\n",
            "----------\n",
            "train Loss: 0.0672 Acc: 0.9699\n",
            "val Loss: 0.1556 Acc: 0.9545\n",
            "EarlyStopping counter: 15 out of 30\n",
            "\n",
            "Epoch 31/49\n",
            "----------\n",
            "train Loss: 0.0707 Acc: 0.9737\n",
            "val Loss: 0.9024 Acc: 0.8258\n",
            "EarlyStopping counter: 16 out of 30\n",
            "\n",
            "Epoch 32/49\n",
            "----------\n",
            "train Loss: 0.2197 Acc: 0.9323\n",
            "val Loss: 0.8996 Acc: 0.6894\n",
            "EarlyStopping counter: 17 out of 30\n",
            "\n",
            "Epoch 33/49\n",
            "----------\n",
            "train Loss: 0.1953 Acc: 0.9267\n",
            "val Loss: 0.2585 Acc: 0.9091\n",
            "EarlyStopping counter: 18 out of 30\n",
            "\n",
            "Epoch 34/49\n",
            "----------\n",
            "train Loss: 0.0762 Acc: 0.9699\n",
            "val Loss: 0.2092 Acc: 0.9167\n",
            "EarlyStopping counter: 19 out of 30\n",
            "\n",
            "Epoch 35/49\n",
            "----------\n",
            "train Loss: 0.0788 Acc: 0.9718\n",
            "val Loss: 0.2470 Acc: 0.9167\n",
            "EarlyStopping counter: 20 out of 30\n",
            "\n",
            "Epoch 36/49\n",
            "----------\n",
            "train Loss: 0.0475 Acc: 0.9812\n",
            "val Loss: 0.2492 Acc: 0.9242\n",
            "EarlyStopping counter: 21 out of 30\n",
            "\n",
            "Epoch 37/49\n",
            "----------\n",
            "train Loss: 0.1300 Acc: 0.9530\n",
            "val Loss: 0.2149 Acc: 0.9318\n",
            "EarlyStopping counter: 22 out of 30\n",
            "\n",
            "Epoch 38/49\n",
            "----------\n",
            "train Loss: 0.0361 Acc: 0.9887\n",
            "val Loss: 0.2186 Acc: 0.9394\n",
            "EarlyStopping counter: 23 out of 30\n",
            "\n",
            "Epoch 39/49\n",
            "----------\n",
            "train Loss: 0.0902 Acc: 0.9624\n",
            "val Loss: 0.3378 Acc: 0.9091\n",
            "EarlyStopping counter: 24 out of 30\n",
            "\n",
            "Epoch 40/49\n",
            "----------\n",
            "train Loss: 0.0569 Acc: 0.9737\n",
            "val Loss: 0.2190 Acc: 0.9167\n",
            "EarlyStopping counter: 25 out of 30\n",
            "\n",
            "Epoch 41/49\n",
            "----------\n",
            "train Loss: 0.1010 Acc: 0.9643\n",
            "val Loss: 0.2186 Acc: 0.9242\n",
            "EarlyStopping counter: 26 out of 30\n",
            "\n",
            "Epoch 42/49\n",
            "----------\n",
            "train Loss: 0.0525 Acc: 0.9756\n",
            "val Loss: 0.1804 Acc: 0.9470\n",
            "EarlyStopping counter: 27 out of 30\n",
            "\n",
            "Epoch 43/49\n",
            "----------\n",
            "train Loss: 0.0401 Acc: 0.9868\n",
            "val Loss: 0.1649 Acc: 0.9470\n",
            "EarlyStopping counter: 28 out of 30\n",
            "\n",
            "Epoch 44/49\n",
            "----------\n",
            "train Loss: 0.0423 Acc: 0.9868\n",
            "val Loss: 0.2159 Acc: 0.9545\n",
            "EarlyStopping counter: 29 out of 30\n",
            "\n",
            "Epoch 45/49\n",
            "----------\n",
            "train Loss: 0.1028 Acc: 0.9680\n",
            "val Loss: 0.2585 Acc: 0.9091\n",
            "EarlyStopping counter: 30 out of 30\n",
            "Early stopping\n",
            "Training complete in 2m 57s\n",
            "Best val Acc: 0.977273\n",
            "number of images: 132\n",
            "56 3 72 1\n",
            "Accuracy: 0.9696969696969697\n",
            "Precision (positive predictive value): 0.9824561403508771\n",
            "Recall (sensitivity): 0.9491525423728814\n",
            "Specificity: 0.9863013698630136\n",
            "F_value: 0.9655172413793103\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "132\n",
            "[0.07417649030685425, 0.0195656418800354, 0.009293138980865479, 0.21408611536026, 0.02432018518447876, 0.014615833759307861, 0.3237014412879944, 0.07689285278320312, 0.01753908395767212, 0.013257503509521484, 0.015275955200195312, 0.04075843095779419, 0.008727848529815674, 0.017651736736297607, 0.01414412260055542, 0.020393669605255127, 0.007609069347381592, 0.1085711121559143, 0.03274178504943848, 0.05219841003417969, 0.02824103832244873, 0.016586661338806152, 0.005151987075805664, 0.015036046504974365, 0.21232974529266357, 0.04348790645599365, 0.01603531837463379, 0.022984862327575684, 0.02557814121246338, 0.007084012031555176, 0.01568305492401123, 0.019550442695617676, 0.06546050310134888, 0.17906808853149414, 0.004513084888458252, 0.011021554470062256, 0.3961753249168396, 0.18047267198562622, 0.0041558146476745605, 0.006749212741851807, 0.5760191082954407, 0.009396851062774658, 0.01274651288986206, 0.01425480842590332, 0.026494324207305908, 0.006939530372619629, 0.002706468105316162, 0.005217015743255615, 0.044407427310943604, 0.00880199670791626, 0.006974220275878906, 0.3162005543708801, 0.0077475905418396, 0.019397616386413574, 0.02778315544128418, 0.11445176601409912, 0.0039855241775512695, 0.024502098560333252, 0.07089215517044067, 0.06639498472213745, 0.002939760684967041, 0.03283274173736572, 0.009389221668243408, 0.07814544439315796, 0.024491548538208008, 0.010697782039642334, 0.007320284843444824, 0.00786590576171875, 0.0045258402824401855, 0.0029098987579345703, 0.010526955127716064, 0.01019960641860962, 0.010509192943572998, 0.9930700659751892, 0.9997195601463318, 0.9969561100006104, 0.9962155222892761, 0.9991193413734436, 0.9984985589981079, 0.9999927282333374, 0.9999629259109497, 0.9992081522941589, 0.9995982050895691, 0.9999948740005493, 0.9986769556999207, 0.8496906161308289, 0.9614238739013672, 0.9998860359191895, 0.9496835470199585, 0.999782383441925, 0.15427672863006592, 0.999984622001648, 0.9967833757400513, 0.9546689987182617, 0.9999995231628418, 0.9999855756759644, 0.999924898147583, 0.9999998807907104, 0.9999016523361206, 0.9999216794967651, 0.9131474494934082, 0.9983843564987183, 0.9981545805931091, 0.9999806880950928, 0.9999432563781738, 0.9791128635406494, 0.9999881982803345, 0.4266088008880615, 0.9927918910980225, 0.7083329558372498, 0.9979771971702576, 0.9996470212936401, 0.9989069700241089, 0.9797114729881287, 0.9999926090240479, 0.8125112056732178, 0.9999017715454102, 0.999508261680603, 0.9997500777244568, 0.9999747276306152, 0.9997860789299011, 0.9997392296791077, 0.9999918937683105, 0.9643900394439697, 0.9984057545661926, 0.9900221228599548, 0.08715581893920898, 0.9999150037765503, 0.9998819828033447, 0.9524924755096436, 0.9893276691436768, 0.9994074106216431]\n",
            "132\n",
            "roc_auc: 0.9955885767355468\n",
            "\n",
            "\n",
            "['cont', 'eso']\n",
            "cont_train:293\n",
            "eso_train:239\n",
            "cont_val:73\n",
            "eso_val:59\n",
            "training data set_total：532\n",
            "validating data set_total：132\n",
            "Epoch 0/49\n",
            "----------\n",
            "train Loss: 0.1183 Acc: 0.9549\n",
            "val Loss: 0.0717 Acc: 0.9773\n",
            "Validation loss decreased (inf --> 0.071736).  Saving model ...\n",
            "\n",
            "Epoch 1/49\n",
            "----------\n",
            "train Loss: 0.0923 Acc: 0.9662\n",
            "val Loss: 0.0747 Acc: 0.9848\n",
            "EarlyStopping counter: 1 out of 30\n",
            "\n",
            "Epoch 2/49\n",
            "----------\n",
            "train Loss: 0.0763 Acc: 0.9699\n",
            "val Loss: 0.0939 Acc: 0.9697\n",
            "EarlyStopping counter: 2 out of 30\n",
            "\n",
            "Epoch 3/49\n",
            "----------\n",
            "train Loss: 0.1149 Acc: 0.9530\n",
            "val Loss: 0.1110 Acc: 0.9621\n",
            "EarlyStopping counter: 3 out of 30\n",
            "\n",
            "Epoch 4/49\n",
            "----------\n",
            "train Loss: 0.0888 Acc: 0.9756\n",
            "val Loss: 0.5177 Acc: 0.8636\n",
            "EarlyStopping counter: 4 out of 30\n",
            "\n",
            "Epoch 5/49\n",
            "----------\n",
            "train Loss: 0.0583 Acc: 0.9756\n",
            "val Loss: 0.1590 Acc: 0.9318\n",
            "EarlyStopping counter: 5 out of 30\n",
            "\n",
            "Epoch 6/49\n",
            "----------\n",
            "train Loss: 0.0917 Acc: 0.9662\n",
            "val Loss: 1.2118 Acc: 0.7424\n",
            "EarlyStopping counter: 6 out of 30\n",
            "\n",
            "Epoch 7/49\n",
            "----------\n",
            "train Loss: 0.0706 Acc: 0.9643\n",
            "val Loss: 0.2023 Acc: 0.9167\n",
            "EarlyStopping counter: 7 out of 30\n",
            "\n",
            "Epoch 8/49\n",
            "----------\n",
            "train Loss: 0.0703 Acc: 0.9718\n",
            "val Loss: 0.1637 Acc: 0.9242\n",
            "EarlyStopping counter: 8 out of 30\n",
            "\n",
            "Epoch 9/49\n",
            "----------\n",
            "train Loss: 0.0611 Acc: 0.9737\n",
            "val Loss: 0.1458 Acc: 0.9394\n",
            "EarlyStopping counter: 9 out of 30\n",
            "\n",
            "Epoch 10/49\n",
            "----------\n",
            "train Loss: 0.0736 Acc: 0.9680\n",
            "val Loss: 0.1474 Acc: 0.9545\n",
            "EarlyStopping counter: 10 out of 30\n",
            "\n",
            "Epoch 11/49\n",
            "----------\n",
            "train Loss: 0.0526 Acc: 0.9774\n",
            "val Loss: 0.1755 Acc: 0.9318\n",
            "EarlyStopping counter: 11 out of 30\n",
            "\n",
            "Epoch 12/49\n",
            "----------\n",
            "train Loss: 0.0416 Acc: 0.9812\n",
            "val Loss: 0.0921 Acc: 0.9697\n",
            "EarlyStopping counter: 12 out of 30\n",
            "\n",
            "Epoch 13/49\n",
            "----------\n",
            "train Loss: 0.0855 Acc: 0.9737\n",
            "val Loss: 0.1753 Acc: 0.9394\n",
            "EarlyStopping counter: 13 out of 30\n",
            "\n",
            "Epoch 14/49\n",
            "----------\n",
            "train Loss: 0.0607 Acc: 0.9793\n",
            "val Loss: 0.4231 Acc: 0.8864\n",
            "EarlyStopping counter: 14 out of 30\n",
            "\n",
            "Epoch 15/49\n",
            "----------\n",
            "train Loss: 0.0664 Acc: 0.9774\n",
            "val Loss: 0.1288 Acc: 0.9394\n",
            "EarlyStopping counter: 15 out of 30\n",
            "\n",
            "Epoch 16/49\n",
            "----------\n",
            "train Loss: 0.0661 Acc: 0.9718\n",
            "val Loss: 0.1342 Acc: 0.9697\n",
            "EarlyStopping counter: 16 out of 30\n",
            "\n",
            "Epoch 17/49\n",
            "----------\n",
            "train Loss: 0.0406 Acc: 0.9850\n",
            "val Loss: 0.1869 Acc: 0.9394\n",
            "EarlyStopping counter: 17 out of 30\n",
            "\n",
            "Epoch 18/49\n",
            "----------\n",
            "train Loss: 0.0412 Acc: 0.9812\n",
            "val Loss: 0.1643 Acc: 0.9697\n",
            "EarlyStopping counter: 18 out of 30\n",
            "\n",
            "Epoch 19/49\n",
            "----------\n",
            "train Loss: 0.0223 Acc: 0.9925\n",
            "val Loss: 0.1472 Acc: 0.9621\n",
            "EarlyStopping counter: 19 out of 30\n",
            "\n",
            "Epoch 20/49\n",
            "----------\n",
            "train Loss: 0.0240 Acc: 0.9906\n",
            "val Loss: 0.1983 Acc: 0.9394\n",
            "EarlyStopping counter: 20 out of 30\n",
            "\n",
            "Epoch 21/49\n",
            "----------\n",
            "train Loss: 0.0599 Acc: 0.9812\n",
            "val Loss: 0.4515 Acc: 0.8864\n",
            "EarlyStopping counter: 21 out of 30\n",
            "\n",
            "Epoch 22/49\n",
            "----------\n",
            "train Loss: 0.0850 Acc: 0.9699\n",
            "val Loss: 0.1162 Acc: 0.9470\n",
            "EarlyStopping counter: 22 out of 30\n",
            "\n",
            "Epoch 23/49\n",
            "----------\n",
            "train Loss: 0.0380 Acc: 0.9868\n",
            "val Loss: 0.1154 Acc: 0.9621\n",
            "EarlyStopping counter: 23 out of 30\n",
            "\n",
            "Epoch 24/49\n",
            "----------\n",
            "train Loss: 0.0307 Acc: 0.9887\n",
            "val Loss: 0.1694 Acc: 0.9318\n",
            "EarlyStopping counter: 24 out of 30\n",
            "\n",
            "Epoch 25/49\n",
            "----------\n",
            "train Loss: 0.0643 Acc: 0.9774\n",
            "val Loss: 0.2111 Acc: 0.9318\n",
            "EarlyStopping counter: 25 out of 30\n",
            "\n",
            "Epoch 26/49\n",
            "----------\n",
            "train Loss: 0.0995 Acc: 0.9643\n",
            "val Loss: 0.2296 Acc: 0.9167\n",
            "EarlyStopping counter: 26 out of 30\n",
            "\n",
            "Epoch 27/49\n",
            "----------\n",
            "train Loss: 0.1551 Acc: 0.9568\n",
            "val Loss: 0.1371 Acc: 0.9394\n",
            "EarlyStopping counter: 27 out of 30\n",
            "\n",
            "Epoch 28/49\n",
            "----------\n",
            "train Loss: 0.0804 Acc: 0.9756\n",
            "val Loss: 0.1626 Acc: 0.9242\n",
            "EarlyStopping counter: 28 out of 30\n",
            "\n",
            "Epoch 29/49\n",
            "----------\n",
            "train Loss: 0.0408 Acc: 0.9868\n",
            "val Loss: 0.2045 Acc: 0.9242\n",
            "EarlyStopping counter: 29 out of 30\n",
            "\n",
            "Epoch 30/49\n",
            "----------\n",
            "train Loss: 0.0235 Acc: 0.9906\n",
            "val Loss: 0.0827 Acc: 0.9697\n",
            "EarlyStopping counter: 30 out of 30\n",
            "Early stopping\n",
            "Training complete in 1m 59s\n",
            "Best val Acc: 0.984848\n",
            "number of images: 132\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No handles with labels found to put in legend.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "59 0 68 5\n",
            "Accuracy: 0.9621212121212122\n",
            "Precision (positive predictive value): 0.921875\n",
            "Recall (sensitivity): 1.0\n",
            "Specificity: 0.9315068493150684\n",
            "F_value: 0.959349593495935\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "132\n",
            "[0.0028108954429626465, 0.0014216899871826172, 0.027501940727233887, 0.002213120460510254, 0.1777815818786621, 0.0032238364219665527, 0.704860270023346, 0.0027998685836791992, 0.00977545976638794, 0.01396709680557251, 0.026867330074310303, 0.0007377266883850098, 0.23748278617858887, 0.16364264488220215, 0.012580335140228271, 0.0016961097717285156, 0.000110626220703125, 0.2921047806739807, 0.0015494823455810547, 0.047697365283966064, 0.0009765625, 0.13828283548355103, 0.006789982318878174, 0.0021533966064453125, 0.36259591579437256, 0.011465132236480713, 0.008072733879089355, 0.0031297802925109863, 0.002609431743621826, 0.0011796355247497559, 0.00293809175491333, 0.009748339653015137, 0.33276480436325073, 0.26032954454421997, 0.0011765360832214355, 0.0008093714714050293, 0.005026578903198242, 0.0102042555809021, 0.005686521530151367, 0.00663912296295166, 0.00012063980102539062, 0.004401564598083496, 0.0001100301742553711, 0.8635386824607849, 0.022591769695281982, 0.011734247207641602, 0.00205153226852417, 0.011989176273345947, 0.7128539681434631, 0.14066457748413086, 0.9129394292831421, 0.007064521312713623, 0.009002923965454102, 0.0036697983741760254, 0.17547714710235596, 0.004049897193908691, 0.002843618392944336, 0.00037360191345214844, 0.028991222381591797, 0.7777509093284607, 0.0014902949333190918, 0.05268251895904541, 0.3332185745239258, 0.006090998649597168, 0.0009014606475830078, 0.0017511844635009766, 0.005441546440124512, 0.004382967948913574, 0.015751898288726807, 0.25748229026794434, 0.1005907654762268, 0.11325222253799438, 0.002702057361602783, 0.9206490516662598, 0.9947644472122192, 0.977627694606781, 0.999991774559021, 0.9991899132728577, 0.9960887432098389, 0.9999798536300659, 0.9944638609886169, 0.9999685287475586, 0.9993960857391357, 0.9934872388839722, 0.99969482421875, 0.9997301697731018, 0.9987012147903442, 0.9952709078788757, 0.9984546899795532, 0.9955400824546814, 0.9999988079071045, 0.9925859570503235, 0.9999970197677612, 0.9998602867126465, 0.9984025359153748, 0.8973017930984497, 0.999951958656311, 0.9998986721038818, 0.9902899861335754, 0.9988332390785217, 0.9980778694152832, 0.9994930028915405, 0.9959979057312012, 0.9997298121452332, 0.9992291927337646, 0.999993085861206, 0.9999101161956787, 0.9968459010124207, 0.9999715089797974, 0.9998729228973389, 0.9962676167488098, 0.9972177743911743, 0.9953058362007141, 0.999953031539917, 0.9997851252555847, 0.9997983574867249, 0.999916672706604, 0.9998440742492676, 0.999967098236084, 0.9833341240882874, 0.9919336438179016, 0.9999697208404541, 0.9996032118797302, 0.9977794289588928, 0.9873149394989014, 0.999387264251709, 0.998817503452301, 0.999420166015625, 0.9925398230552673, 0.9561476111412048, 0.999613344669342, 0.9999972581863403]\n",
            "132\n",
            "roc_auc: 0.9997678198281866\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                  0         1         2         3         4  \\\n",
            "TP                               55        57        59        56        59   \n",
            "TN                               74        68        72        72        68   \n",
            "FP                                0         5         1         1         5   \n",
            "FN                                5         3         1         3         0   \n",
            "Accuracy                   0.962687   0.93985  0.984962  0.969697  0.962121   \n",
            "Positive predictive value         1  0.919355  0.983333  0.982456  0.921875   \n",
            "sensitity                  0.916667      0.95  0.983333  0.949153         1   \n",
            "specificity                       1  0.931507  0.986301  0.986301  0.931507   \n",
            "F-value                    0.956522  0.934426  0.983333  0.965517   0.95935   \n",
            "roc_auc                    0.997072  0.994977  0.996804  0.995589  0.999768   \n",
            "\n",
            "                                avg         std  \n",
            "TP                             57.2         1.6  \n",
            "TN                             70.8         2.4  \n",
            "FP                              2.4     2.15407  \n",
            "FN                              2.4     1.74356  \n",
            "Accuracy                   0.959367    0.016281  \n",
            "Positive predictive value  0.954189    0.037896  \n",
            "sensitity                  0.955274   0.0325567  \n",
            "specificity                0.962695   0.0329907  \n",
            "F-value                    0.954731   0.0176159  \n",
            "roc_auc                    0.996842  0.00165309  \n",
            "5-fold cross validation\n",
            "/content/drive/MyDrive/Deep_learning/Strabismus/Dataset_250px_shuffle_crossvalidation_eso/0\n",
            "/content/drive/MyDrive/Deep_learning/Strabismus/Dataset_250px_shuffle_crossvalidation_eso/1\n",
            "/content/drive/MyDrive/Deep_learning/Strabismus/Dataset_250px_shuffle_crossvalidation_eso/2\n",
            "/content/drive/MyDrive/Deep_learning/Strabismus/Dataset_250px_shuffle_crossvalidation_eso/3\n",
            "/content/drive/MyDrive/Deep_learning/Strabismus/Dataset_250px_shuffle_crossvalidation_eso/4\n",
            "['cont', 'eso']\n",
            "cont_train:292\n",
            "eso_train:238\n",
            "cont_val:74\n",
            "eso_val:60\n",
            "training data set_total：530\n",
            "validating data set_total：134\n",
            "Epoch 0/49\n",
            "----------\n",
            "train Loss: 0.0780 Acc: 0.9717\n",
            "val Loss: 0.0455 Acc: 0.9851\n",
            "Validation loss decreased (inf --> 0.045516).  Saving model ...\n",
            "\n",
            "Epoch 1/49\n",
            "----------\n",
            "train Loss: 0.0964 Acc: 0.9660\n",
            "val Loss: 0.0780 Acc: 0.9627\n",
            "EarlyStopping counter: 1 out of 30\n",
            "\n",
            "Epoch 2/49\n",
            "----------\n",
            "train Loss: 0.1116 Acc: 0.9566\n",
            "val Loss: 0.1481 Acc: 0.9478\n",
            "EarlyStopping counter: 2 out of 30\n",
            "\n",
            "Epoch 3/49\n",
            "----------\n",
            "train Loss: 0.0867 Acc: 0.9604\n",
            "val Loss: 0.0410 Acc: 0.9925\n",
            "Validation loss decreased (0.045516 --> 0.040984).  Saving model ...\n",
            "\n",
            "Epoch 4/49\n",
            "----------\n",
            "train Loss: 0.0494 Acc: 0.9830\n",
            "val Loss: 0.4537 Acc: 0.9030\n",
            "EarlyStopping counter: 1 out of 30\n",
            "\n",
            "Epoch 5/49\n",
            "----------\n",
            "train Loss: 0.0770 Acc: 0.9736\n",
            "val Loss: 0.1367 Acc: 0.9552\n",
            "EarlyStopping counter: 2 out of 30\n",
            "\n",
            "Epoch 6/49\n",
            "----------\n",
            "train Loss: 0.0805 Acc: 0.9679\n",
            "val Loss: 0.0536 Acc: 0.9701\n",
            "EarlyStopping counter: 3 out of 30\n",
            "\n",
            "Epoch 7/49\n",
            "----------\n",
            "train Loss: 0.0581 Acc: 0.9736\n",
            "val Loss: 0.0697 Acc: 0.9701\n",
            "EarlyStopping counter: 4 out of 30\n",
            "\n",
            "Epoch 8/49\n",
            "----------\n",
            "train Loss: 0.0632 Acc: 0.9811\n",
            "val Loss: 0.1666 Acc: 0.9552\n",
            "EarlyStopping counter: 5 out of 30\n",
            "\n",
            "Epoch 9/49\n",
            "----------\n",
            "train Loss: 0.0978 Acc: 0.9566\n",
            "val Loss: 0.0745 Acc: 0.9701\n",
            "EarlyStopping counter: 6 out of 30\n",
            "\n",
            "Epoch 10/49\n",
            "----------\n",
            "train Loss: 0.1165 Acc: 0.9604\n",
            "val Loss: 0.1203 Acc: 0.9701\n",
            "EarlyStopping counter: 7 out of 30\n",
            "\n",
            "Epoch 11/49\n",
            "----------\n",
            "train Loss: 0.0977 Acc: 0.9623\n",
            "val Loss: 0.0999 Acc: 0.9627\n",
            "EarlyStopping counter: 8 out of 30\n",
            "\n",
            "Epoch 12/49\n",
            "----------\n",
            "train Loss: 0.1775 Acc: 0.9302\n",
            "val Loss: 0.1853 Acc: 0.9179\n",
            "EarlyStopping counter: 9 out of 30\n",
            "\n",
            "Epoch 13/49\n",
            "----------\n",
            "train Loss: 0.0604 Acc: 0.9811\n",
            "val Loss: 0.0787 Acc: 0.9701\n",
            "EarlyStopping counter: 10 out of 30\n",
            "\n",
            "Epoch 14/49\n",
            "----------\n",
            "train Loss: 0.0571 Acc: 0.9830\n",
            "val Loss: 0.1712 Acc: 0.9478\n",
            "EarlyStopping counter: 11 out of 30\n",
            "\n",
            "Epoch 15/49\n",
            "----------\n",
            "train Loss: 0.0715 Acc: 0.9679\n",
            "val Loss: 0.1343 Acc: 0.9701\n",
            "EarlyStopping counter: 12 out of 30\n",
            "\n",
            "Epoch 16/49\n",
            "----------\n",
            "train Loss: 0.0664 Acc: 0.9698\n",
            "val Loss: 0.1145 Acc: 0.9701\n",
            "EarlyStopping counter: 13 out of 30\n",
            "\n",
            "Epoch 17/49\n",
            "----------\n",
            "train Loss: 0.0874 Acc: 0.9755\n",
            "val Loss: 0.2688 Acc: 0.9030\n",
            "EarlyStopping counter: 14 out of 30\n",
            "\n",
            "Epoch 18/49\n",
            "----------\n",
            "train Loss: 0.0542 Acc: 0.9792\n",
            "val Loss: 0.1407 Acc: 0.9627\n",
            "EarlyStopping counter: 15 out of 30\n",
            "\n",
            "Epoch 19/49\n",
            "----------\n",
            "train Loss: 0.0296 Acc: 0.9925\n",
            "val Loss: 0.1217 Acc: 0.9627\n",
            "EarlyStopping counter: 16 out of 30\n",
            "\n",
            "Epoch 20/49\n",
            "----------\n",
            "train Loss: 0.0428 Acc: 0.9811\n",
            "val Loss: 0.1554 Acc: 0.9627\n",
            "EarlyStopping counter: 17 out of 30\n",
            "\n",
            "Epoch 21/49\n",
            "----------\n",
            "train Loss: 0.1415 Acc: 0.9585\n",
            "val Loss: 0.1909 Acc: 0.9478\n",
            "EarlyStopping counter: 18 out of 30\n",
            "\n",
            "Epoch 22/49\n",
            "----------\n",
            "train Loss: 0.1094 Acc: 0.9547\n",
            "val Loss: 0.1296 Acc: 0.9328\n",
            "EarlyStopping counter: 19 out of 30\n",
            "\n",
            "Epoch 23/49\n",
            "----------\n",
            "train Loss: 0.1061 Acc: 0.9509\n",
            "val Loss: 0.1986 Acc: 0.9328\n",
            "EarlyStopping counter: 20 out of 30\n",
            "\n",
            "Epoch 24/49\n",
            "----------\n",
            "train Loss: 0.0829 Acc: 0.9717\n",
            "val Loss: 0.1548 Acc: 0.9552\n",
            "EarlyStopping counter: 21 out of 30\n",
            "\n",
            "Epoch 25/49\n",
            "----------\n",
            "train Loss: 0.0487 Acc: 0.9849\n",
            "val Loss: 0.1977 Acc: 0.9552\n",
            "EarlyStopping counter: 22 out of 30\n",
            "\n",
            "Epoch 26/49\n",
            "----------\n",
            "train Loss: 0.0355 Acc: 0.9868\n",
            "val Loss: 0.1277 Acc: 0.9552\n",
            "EarlyStopping counter: 23 out of 30\n",
            "\n",
            "Epoch 27/49\n",
            "----------\n",
            "train Loss: 0.0458 Acc: 0.9811\n",
            "val Loss: 0.1793 Acc: 0.9478\n",
            "EarlyStopping counter: 24 out of 30\n",
            "\n",
            "Epoch 28/49\n",
            "----------\n",
            "train Loss: 0.0581 Acc: 0.9717\n",
            "val Loss: 0.1510 Acc: 0.9552\n",
            "EarlyStopping counter: 25 out of 30\n",
            "\n",
            "Epoch 29/49\n",
            "----------\n",
            "train Loss: 0.0460 Acc: 0.9868\n",
            "val Loss: 0.1159 Acc: 0.9701\n",
            "EarlyStopping counter: 26 out of 30\n",
            "\n",
            "Epoch 30/49\n",
            "----------\n",
            "train Loss: 0.0339 Acc: 0.9849\n",
            "val Loss: 0.1067 Acc: 0.9701\n",
            "EarlyStopping counter: 27 out of 30\n",
            "\n",
            "Epoch 31/49\n",
            "----------\n",
            "train Loss: 0.0589 Acc: 0.9830\n",
            "val Loss: 0.1126 Acc: 0.9701\n",
            "EarlyStopping counter: 28 out of 30\n",
            "\n",
            "Epoch 32/49\n",
            "----------\n",
            "train Loss: 0.0299 Acc: 0.9906\n",
            "val Loss: 0.1056 Acc: 0.9478\n",
            "EarlyStopping counter: 29 out of 30\n",
            "\n",
            "Epoch 33/49\n",
            "----------\n",
            "train Loss: 0.0433 Acc: 0.9811\n",
            "val Loss: 0.1400 Acc: 0.9552\n",
            "EarlyStopping counter: 30 out of 30\n",
            "Early stopping\n",
            "Training complete in 2m 10s\n",
            "Best val Acc: 0.992537\n",
            "number of images: 134\n",
            "60 0 73 1\n",
            "Accuracy: 0.9925373134328358\n",
            "Precision (positive predictive value): 0.9836065573770492\n",
            "Recall (sensitivity): 1.0\n",
            "Specificity: 0.9864864864864865\n",
            "F_value: 0.9917355371900827\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "134\n",
            "[0.0005077123641967773, 0.0023425817489624023, 3.8743019104003906e-05, 0.00047278404235839844, 0.025224149227142334, 0.0003637075424194336, 0.0006648898124694824, 0.00538557767868042, 0.00030362606048583984, 0.003838658332824707, 0.03361696004867554, 0.005265355110168457, 0.0011010169982910156, 0.0005574822425842285, 0.007972419261932373, 0.006641685962677002, 0.0012679696083068848, 0.011210978031158447, 0.0012428760528564453, 0.006154894828796387, 6.830692291259766e-05, 0.0022949576377868652, 0.00255739688873291, 0.006738007068634033, 0.571678638458252, 0.01250767707824707, 0.0026041269302368164, 0.0627855658531189, 0.002699434757232666, 0.014341652393341064, 0.008178174495697021, 0.005699872970581055, 0.001071155071258545, 0.002564370632171631, 0.02497231960296631, 7.2479248046875e-05, 3.886222839355469e-05, 0.02866750955581665, 0.00047969818115234375, 0.012790560722351074, 0.0017456412315368652, 0.017018258571624756, 0.008350133895874023, 0.000964045524597168, 0.12996333837509155, 0.0007550716400146484, 0.003089010715484619, 7.975101470947266e-05, 0.00024944543838500977, 0.0767335295677185, 0.004192829132080078, 0.0003336668014526367, 0.0002726912498474121, 0.004981875419616699, 0.0004013180732727051, 0.0025705695152282715, 0.01527494192123413, 0.0005080699920654297, 0.00031638145446777344, 0.010439515113830566, 2.944469451904297e-05, 2.658367156982422e-05, 0.00037741661071777344, 0.003581523895263672, 0.0007160305976867676, 2.7418136596679688e-05, 0.002117455005645752, 0.1844119429588318, 0.01150578260421753, 0.0014105439186096191, 0.018526971340179443, 0.0028209686279296875, 0.0014064908027648926, 0.00041109323501586914, 0.9934485554695129, 0.9999996423721313, 0.8667889833450317, 0.9956837892532349, 0.9965916872024536, 0.9975535273551941, 0.9600251913070679, 0.9999867677688599, 0.9999991655349731, 0.994968593120575, 0.9981398582458496, 0.9999518394470215, 0.9892849326133728, 0.9999978542327881, 1.0, 0.996222972869873, 0.999630331993103, 0.9551762342453003, 0.9996933937072754, 0.9999698400497437, 0.927824079990387, 0.9955543875694275, 0.9993492960929871, 0.9999476671218872, 0.9998160004615784, 0.9797057509422302, 0.9996681213378906, 0.7490251660346985, 0.999950647354126, 0.9999176263809204, 0.998634397983551, 0.9999258518218994, 0.9934203028678894, 0.999992847442627, 0.9867668747901917, 0.9960111379623413, 0.9999998807907104, 0.99982750415802, 0.9999995231628418, 0.9740411639213562, 0.9716089963912964, 0.9999551773071289, 0.9999998807907104, 0.9999979734420776, 0.9999433755874634, 0.9999984502792358, 0.9999971389770508, 0.9467158913612366, 0.9984676241874695, 0.9992695450782776, 0.9999995231628418, 0.9990267753601074, 0.9998672008514404, 0.9997981190681458, 0.9649235010147095, 0.9999908208847046, 0.9993371367454529, 0.954346239566803, 0.9927547574043274, 0.9981435537338257]\n",
            "134\n",
            "roc_auc: 1.0\n",
            "\n",
            "\n",
            "['cont', 'eso']\n",
            "cont_train:293\n",
            "eso_train:238\n",
            "cont_val:73\n",
            "eso_val:60\n",
            "training data set_total：531\n",
            "validating data set_total：133\n",
            "Epoch 0/49\n",
            "----------\n",
            "train Loss: 0.0476 Acc: 0.9906\n",
            "val Loss: 0.0058 Acc: 1.0000\n",
            "Validation loss decreased (inf --> 0.005847).  Saving model ...\n",
            "\n",
            "Epoch 1/49\n",
            "----------\n",
            "train Loss: 0.0528 Acc: 0.9774\n",
            "val Loss: 0.0594 Acc: 0.9925\n",
            "EarlyStopping counter: 1 out of 30\n",
            "\n",
            "Epoch 2/49\n",
            "----------\n",
            "train Loss: 0.1050 Acc: 0.9586\n",
            "val Loss: 0.0980 Acc: 0.9474\n",
            "EarlyStopping counter: 2 out of 30\n",
            "\n",
            "Epoch 3/49\n",
            "----------\n",
            "train Loss: 0.0829 Acc: 0.9755\n",
            "val Loss: 0.0651 Acc: 0.9624\n",
            "EarlyStopping counter: 3 out of 30\n",
            "\n",
            "Epoch 4/49\n",
            "----------\n",
            "train Loss: 0.0875 Acc: 0.9642\n",
            "val Loss: 0.0771 Acc: 0.9549\n",
            "EarlyStopping counter: 4 out of 30\n",
            "\n",
            "Epoch 5/49\n",
            "----------\n",
            "train Loss: 0.0645 Acc: 0.9793\n",
            "val Loss: 0.1145 Acc: 0.9549\n",
            "EarlyStopping counter: 5 out of 30\n",
            "\n",
            "Epoch 6/49\n",
            "----------\n",
            "train Loss: 0.1063 Acc: 0.9623\n",
            "val Loss: 0.1820 Acc: 0.9398\n",
            "EarlyStopping counter: 6 out of 30\n",
            "\n",
            "Epoch 7/49\n",
            "----------\n",
            "train Loss: 0.0848 Acc: 0.9699\n",
            "val Loss: 0.1275 Acc: 0.9624\n",
            "EarlyStopping counter: 7 out of 30\n",
            "\n",
            "Epoch 8/49\n",
            "----------\n",
            "train Loss: 0.1111 Acc: 0.9642\n",
            "val Loss: 0.0870 Acc: 0.9624\n",
            "EarlyStopping counter: 8 out of 30\n",
            "\n",
            "Epoch 9/49\n",
            "----------\n",
            "train Loss: 0.0449 Acc: 0.9831\n",
            "val Loss: 0.0788 Acc: 0.9549\n",
            "EarlyStopping counter: 9 out of 30\n",
            "\n",
            "Epoch 10/49\n",
            "----------\n",
            "train Loss: 0.0467 Acc: 0.9755\n",
            "val Loss: 0.0456 Acc: 0.9850\n",
            "EarlyStopping counter: 10 out of 30\n",
            "\n",
            "Epoch 11/49\n",
            "----------\n",
            "train Loss: 0.0505 Acc: 0.9849\n",
            "val Loss: 0.1629 Acc: 0.9323\n",
            "EarlyStopping counter: 11 out of 30\n",
            "\n",
            "Epoch 12/49\n",
            "----------\n",
            "train Loss: 0.1173 Acc: 0.9642\n",
            "val Loss: 0.1423 Acc: 0.9624\n",
            "EarlyStopping counter: 12 out of 30\n",
            "\n",
            "Epoch 13/49\n",
            "----------\n",
            "train Loss: 0.0923 Acc: 0.9661\n",
            "val Loss: 0.0738 Acc: 0.9774\n",
            "EarlyStopping counter: 13 out of 30\n",
            "\n",
            "Epoch 14/49\n",
            "----------\n",
            "train Loss: 0.0730 Acc: 0.9699\n",
            "val Loss: 0.1009 Acc: 0.9774\n",
            "EarlyStopping counter: 14 out of 30\n",
            "\n",
            "Epoch 15/49\n",
            "----------\n",
            "train Loss: 0.0887 Acc: 0.9661\n",
            "val Loss: 0.1024 Acc: 0.9624\n",
            "EarlyStopping counter: 15 out of 30\n",
            "\n",
            "Epoch 16/49\n",
            "----------\n",
            "train Loss: 0.0405 Acc: 0.9868\n",
            "val Loss: 0.0928 Acc: 0.9624\n",
            "EarlyStopping counter: 16 out of 30\n",
            "\n",
            "Epoch 17/49\n",
            "----------\n",
            "train Loss: 0.0762 Acc: 0.9661\n",
            "val Loss: 0.1065 Acc: 0.9549\n",
            "EarlyStopping counter: 17 out of 30\n",
            "\n",
            "Epoch 18/49\n",
            "----------\n",
            "train Loss: 0.0523 Acc: 0.9812\n",
            "val Loss: 0.0286 Acc: 0.9925\n",
            "EarlyStopping counter: 18 out of 30\n",
            "\n",
            "Epoch 19/49\n",
            "----------\n",
            "train Loss: 0.0278 Acc: 0.9906\n",
            "val Loss: 0.1023 Acc: 0.9699\n",
            "EarlyStopping counter: 19 out of 30\n",
            "\n",
            "Epoch 20/49\n",
            "----------\n",
            "train Loss: 0.0894 Acc: 0.9718\n",
            "val Loss: 0.0922 Acc: 0.9774\n",
            "EarlyStopping counter: 20 out of 30\n",
            "\n",
            "Epoch 21/49\n",
            "----------\n",
            "train Loss: 0.0351 Acc: 0.9906\n",
            "val Loss: 0.0798 Acc: 0.9624\n",
            "EarlyStopping counter: 21 out of 30\n",
            "\n",
            "Epoch 22/49\n",
            "----------\n",
            "train Loss: 0.0515 Acc: 0.9736\n",
            "val Loss: 0.1096 Acc: 0.9549\n",
            "EarlyStopping counter: 22 out of 30\n",
            "\n",
            "Epoch 23/49\n",
            "----------\n",
            "train Loss: 0.0562 Acc: 0.9755\n",
            "val Loss: 0.1530 Acc: 0.9624\n",
            "EarlyStopping counter: 23 out of 30\n",
            "\n",
            "Epoch 24/49\n",
            "----------\n",
            "train Loss: 0.0800 Acc: 0.9699\n",
            "val Loss: 0.0689 Acc: 0.9699\n",
            "EarlyStopping counter: 24 out of 30\n",
            "\n",
            "Epoch 25/49\n",
            "----------\n",
            "train Loss: 0.0593 Acc: 0.9699\n",
            "val Loss: 0.1173 Acc: 0.9624\n",
            "EarlyStopping counter: 25 out of 30\n",
            "\n",
            "Epoch 26/49\n",
            "----------\n",
            "train Loss: 0.0412 Acc: 0.9831\n",
            "val Loss: 0.1716 Acc: 0.9549\n",
            "EarlyStopping counter: 26 out of 30\n",
            "\n",
            "Epoch 27/49\n",
            "----------\n",
            "train Loss: 0.0627 Acc: 0.9755\n",
            "val Loss: 0.0551 Acc: 0.9699\n",
            "EarlyStopping counter: 27 out of 30\n",
            "\n",
            "Epoch 28/49\n",
            "----------\n",
            "train Loss: 0.0508 Acc: 0.9849\n",
            "val Loss: 0.2746 Acc: 0.9398\n",
            "EarlyStopping counter: 28 out of 30\n",
            "\n",
            "Epoch 29/49\n",
            "----------\n",
            "train Loss: 0.0430 Acc: 0.9812\n",
            "val Loss: 0.1531 Acc: 0.9398\n",
            "EarlyStopping counter: 29 out of 30\n",
            "\n",
            "Epoch 30/49\n",
            "----------\n",
            "train Loss: 0.0379 Acc: 0.9849\n",
            "val Loss: 0.0911 Acc: 0.9699\n",
            "EarlyStopping counter: 30 out of 30\n",
            "Early stopping\n",
            "Training complete in 1m 59s\n",
            "Best val Acc: 1.000000\n",
            "number of images: 133\n",
            "59 1 73 0\n",
            "Accuracy: 0.9924812030075187\n",
            "Precision (positive predictive value): 1.0\n",
            "Recall (sensitivity): 0.9833333333333333\n",
            "Specificity: 1.0\n",
            "F_value: 0.9915966386554621\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "133\n",
            "[7.176399230957031e-05, 0.0004805326461791992, 0.003076612949371338, 0.003537476062774658, 0.05441629886627197, 0.0049430131912231445, 0.0010411739349365234, 0.02249884605407715, 0.0013658404350280762, 0.0018445849418640137, 0.0013228058815002441, 0.00037658214569091797, 0.05415952205657959, 0.000988602638244629, 0.0075604915618896484, 0.0025715231895446777, 0.0017473101615905762, 0.008333861827850342, 0.0052741169929504395, 0.00048720836639404297, 0.0026913881301879883, 0.005618393421173096, 0.02841508388519287, 0.0005803108215332031, 0.0008603334426879883, 0.0027671456336975098, 0.0012272000312805176, 0.0008523464202880859, 0.0005432963371276855, 0.0003771781921386719, 0.055709660053253174, 0.015821874141693115, 0.005880832672119141, 0.005200505256652832, 0.0002568364143371582, 0.001012265682220459, 0.0005360245704650879, 0.11375635862350464, 0.07128912210464478, 0.0016120672225952148, 0.0005620121955871582, 0.018970370292663574, 0.021007001399993896, 0.02264493703842163, 0.00119781494140625, 0.001350700855255127, 0.0036298036575317383, 0.0030696988105773926, 0.0026630759239196777, 0.05124121904373169, 0.00728154182434082, 0.010695457458496094, 0.006081938743591309, 0.00017303228378295898, 0.00011754035949707031, 0.0014047026634216309, 0.01328188180923462, 0.03061443567276001, 0.0007005929946899414, 0.0004901885986328125, 0.0029802918434143066, 0.0038015246391296387, 0.0004482865333557129, 0.0022516846656799316, 0.0015696883201599121, 0.004506707191467285, 0.03790760040283203, 0.038086533546447754, 0.00043839216232299805, 0.00016486644744873047, 0.012199997901916504, 0.005376338958740234, 0.0008624792098999023, 0.9889340996742249, 0.9999995231628418, 0.999932050704956, 0.9999685287475586, 0.9999129772186279, 0.9996044039726257, 0.9999915361404419, 0.9993476271629333, 0.1933944821357727, 0.999997615814209, 0.9999765157699585, 0.9999998807907104, 0.9998924732208252, 1.0, 0.999160647392273, 0.9881911277770996, 0.9999979734420776, 0.9986336827278137, 0.9999920129776001, 0.9999977350234985, 0.9999505281448364, 1.0, 0.9961085915565491, 1.0, 0.9999673366546631, 0.9999994039535522, 0.999941349029541, 0.9999974966049194, 0.9997116923332214, 0.9992954730987549, 0.9998900890350342, 0.9981014132499695, 0.9990094900131226, 0.9999823570251465, 0.9999862909317017, 0.9999995231628418, 0.9992594122886658, 0.9999792575836182, 0.9981414079666138, 0.9999990463256836, 1.0, 0.9999940395355225, 0.9885014295578003, 0.9998587369918823, 0.999927282333374, 0.9999994039535522, 0.9999998807907104, 0.9983856678009033, 1.0, 0.9999865293502808, 0.9999576807022095, 0.9999856948852539, 0.9999934434890747, 0.9999988079071045, 0.9986635446548462, 0.9529318809509277, 0.9999974966049194, 0.9986398816108704, 0.9999723434448242, 0.9998250603675842]\n",
            "133\n",
            "roc_auc: 1.0\n",
            "\n",
            "\n",
            "['cont', 'eso']\n",
            "cont_train:293\n",
            "eso_train:238\n",
            "cont_val:73\n",
            "eso_val:60\n",
            "training data set_total：531\n",
            "validating data set_total：133\n",
            "Epoch 0/49\n",
            "----------\n",
            "train Loss: 0.0599 Acc: 0.9793\n",
            "val Loss: 0.1346 Acc: 0.9474\n",
            "Validation loss decreased (inf --> 0.134608).  Saving model ...\n",
            "\n",
            "Epoch 1/49\n",
            "----------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blaWE7qw6GjP"
      },
      "source": [
        "#**作ったフォルダの削除**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ats9BT0d6OAP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "132815e6-74a1-4990-ba35-e696ae88903a"
      },
      "source": [
        "dst_path = \"/content/drive/MyDrive/Deep_learning/Strabismus/Dataset_250px_crossvalidation_eso\"\n",
        "directory = dst_path\n",
        "try:\n",
        "    shutil.rmtree(directory)\n",
        "except FileNotFoundError:\n",
        "    print(\"file not found\")\n",
        "    pass"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "file not found\n"
          ]
        }
      ]
    }
  ]
}