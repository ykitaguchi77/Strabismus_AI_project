{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled80.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOsFmAiY+AuMf7H2HAvCcTB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ykitaguchi77/Strabismus_AI_project/blob/main/5-fold%20crossvalidation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h5CVPFZ3z0ON"
      },
      "source": [
        "#**Strabismus 5-fold crossvalidation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-ropSQkzzmq"
      },
      "source": [
        "\"\"\"\n",
        "CSVを作成し、ファイル名-正解-予測を記載\n",
        "\n",
        "データを5分割（division1~5)\n",
        "set1: 1がtest、2~5がtrain\n",
        "set2: 2がtest、1、3~5がtrain\n",
        "set3:\n",
        "set4: \n",
        "set5: 5がtest、1~4がtrain\n",
        "それぞれのdivisionに、exoとcontのフォルダを置いておく\n",
        "\n",
        "各セットについてトレーニング→CSVに予測の結果を記載していく\n",
        "全てのデータが揃ったら、正解-予測のデータから、正解率、感度、特異度、ROC curveの計算を行う\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dyW4AJj14_og"
      },
      "source": [
        "#**Split dataset for Crossvalidation**\n",
        "trainセットを５分割、うち1つをvalセット、残りの合計をtestセットに分割"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "PnyR-OC25V0Q",
        "outputId": "a3ee292d-134a-471e-9b49-21adecd9da9c"
      },
      "source": [
        "import random\n",
        "import glob\n",
        "import os\n",
        "import shutil\n",
        "import numpy as np\n",
        "import time\n",
        "import pandas as pd\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "'''\n",
        "-----orig_data-----grav\n",
        "                |--cont\n",
        "↓\n",
        "↓\n",
        "\n",
        "-----dst_data[0]------dst_train[0]----grav\n",
        "  |                |               |-- cont\n",
        "  |                |--dst_val[0]------grav\n",
        "  |                                |--cont\n",
        "  |\n",
        "  |--dst_data[1]------dst_train[1]----grav\n",
        "  |                |               |-- cont\n",
        "  |                |--dst_val[1]------grav\n",
        "  |                                |--cont\n",
        "  ...\n",
        "  |--dst_data[1]------dst_train[9]----grav\n",
        "                   |               |-- cont\n",
        "                   |--dst_val[9]------grav\n",
        "                                   |--cont\n",
        "'''"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n-----orig_data-----grav\\n                |--cont\\n↓\\n↓\\n\\n-----dst_data[0]------dst_train[0]----grav\\n  |                |               |-- cont\\n  |                |--dst_val[0]------grav\\n  |                                |--cont\\n  |\\n  |--dst_data[1]------dst_train[1]----grav\\n  |                |               |-- cont\\n  |                |--dst_val[1]------grav\\n  |                                |--cont\\n  ...\\n  |--dst_data[1]------dst_train[9]----grav\\n                   |               |-- cont\\n                   |--dst_val[9]------grav\\n                                   |--cont\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-XraZlu5a5d"
      },
      "source": [
        "def get_path(orig_path, dst_path, split_num):\n",
        "    classes = os.listdir(orig_path) #クラス名を取得\n",
        "    #データの分割数を設定\n",
        "    data_list = [0]*len(classes)\n",
        "    k=0\n",
        "    for i in classes:\n",
        "        data_list[k] = glob.glob(orig_path+'/'+i+'/*')\n",
        "        k+=1\n",
        "    split_length = int(len(data_list)/split_num)\n",
        "    return data_list, classes, split_length\n",
        "\n",
        "def makefolder(orig_path, dst_path, classes):\n",
        "    #フォルダを作成\n",
        "    if os.path.exists(dst_path):\n",
        "        shutil.rmtree(dst_path)\n",
        "        print(\"Existing dataset deleted.\")\n",
        "    elif not os.path.exists(dst_path):  # ディレクトリがなかったら\n",
        "        os.mkdir(dst_path)  # 作成したいフォルダ名を作成\n",
        "        for i in range(split_num):\n",
        "            os.mkdir(dst_path+'/'+str(i))\n",
        "            os.mkdir(dst_path+'/'+str(i)+'/train')\n",
        "            os.mkdir(dst_path+'/'+str(i)+'/val')\n",
        "            for j in classes:\n",
        "                os.mkdir(dst_path+'/'+str(i)+'/train/'+j)\n",
        "                os.mkdir(dst_path+'/'+str(i)+'/val/'+j)\n",
        "\n",
        "def split_data_list(data_list, split_num):\n",
        "    split_data, dst_data, dst_train, dst_val, dst_test = [0]*split_num, [0]*split_num, [0]*split_num, [0]*split_num, [0]*split_num\n",
        "\n",
        "    #データの分割\n",
        "    data_list = random.shuffle(data_list)  #data_listをシャッフルする場合にはこれを入れる\n",
        "    split_data = list(np.array_split(data_list, split_num))\n",
        "\n",
        "    #データセット全体と分割したデータの差分を取り、dst_dataに格納\n",
        "\n",
        "    dst_data = [0] * split_num\n",
        "    for i in range(split_num):\n",
        "        dst_data[i] = [x for x in data_list if x not in split_data[i]]\n",
        "\n",
        "    #トレーニングセット、バリデーションセット、テストセットのリスト作成\n",
        "    for i in range(split_num):\n",
        "        dst_train[i] = dst_data[i]\n",
        "        dst_val[i] = split_data[i]  #テストセット\n",
        "    \n",
        "    return dst_train, dst_val\n",
        "\n",
        "def copy_to_folders(split_num, class_name, dst_train, dst_val, dst_path):\n",
        "    k=0\n",
        "    for i in range(split_num):\n",
        "        dst_path_train = dst_path +'/'+str(i)+'/train/'+class_name\n",
        "        dst_path_val = dst_path +'/'+str(i)+'/val/'+class_name\n",
        "        for p in dst_train[k]:  # 選択したファイルを目的フォルダにコピー\n",
        "            shutil.copy(p, dst_path_train)\n",
        "            #print(p)\n",
        "            print(dst_path_train)\n",
        "\n",
        "        for p in dst_val[k]:  # 選択したファイルを目的フォルダにコピー\n",
        "            shutil.copy(p, dst_path_val)\n",
        "            #print(p)    \n",
        "            print(dst_path_val)\n",
        "\n",
        "        k+=1    "
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmDnaPiLHxm4"
      },
      "source": [
        "#パスの設定\n",
        "orig_path = \"/content/drive/MyDrive/Deep_learning/Strabismus/Dataset_250px_20211111\"\n",
        "dst_path = \"/content/drive/MyDrive/Deep_learning/Strabismus/Dataset_250px_crossvalidation_exo\"  # フォルダ名\n",
        "csv_path = dst_path + \"/img_list.csv\""
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JIxM04cGIfQo",
        "outputId": "e10e2ec8-968e-4965-8be6-329ea2498e33"
      },
      "source": [
        "#Dataの分割の設定\n",
        "split_num = 5  #データをいくつに分割するかを記載\n",
        "data_list, classes, split_length = get_path(orig_path, dst_path, split_num)\n",
        "print(classes)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['cont', 'eso', 'exo']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HnfDmSsjI8yX"
      },
      "source": [
        "#作成するデータのクラスを設定し直す\n",
        "#疾患群を後ろにする\n",
        "classes = ['cont', 'exo']"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHp4Whs25lbn"
      },
      "source": [
        "#5-foldデータセットの作成\n",
        "#作成済みの場合には省略\n",
        "makefolder(orig_path, dst_path, classes)\n",
        "print(classes)\n",
        "k=0\n",
        "for i in range(len(classes)):\n",
        "    dst_train, dst_val = split_data_list(data_list[k], split_num)\n",
        "    print(classes[k])\n",
        "    copy_to_folders(split_num, classes[k], dst_train, dst_val, dst_path)\n",
        "    k+=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1SlzcdphHIA7"
      },
      "source": [
        "#**Make CSV file**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFwa0-VP-fR5"
      },
      "source": [
        "classes = os.listdir(dst_path+\"/0/val/\")\n",
        "split_num = 5\n",
        "img_num = len(glob.glob(dst_path+\"/*/val/*/*\"))\n",
        "#print(glob.glob(dst_path+\"/*/val/*/*\"))\n",
        "#print(img_num)\n",
        "\n",
        "#Make CSV file\n",
        "cols = [\"num\", \"division\", \"class\", \"prediction\"]\n",
        "df_cross = pd.DataFrame(index=list(range(img_num)), columns=cols)\n",
        "\n",
        "t=0\n",
        "for i in range(split_num):\n",
        "    for j in classes:\n",
        "        #print(str(i) + \", \"+str(j))\n",
        "        img_list = os.listdir(dst_path+\"/\"+str(i)+\"/val/\"+str(j))\n",
        "        #print(img_list)\n",
        "        for k in img_list:\n",
        "            df_cross.iloc[t,0]=str(k)\n",
        "            df_cross.iloc[t,1]=str(i)\n",
        "            df_cross.iloc[t,2]=str(j)\n",
        "            t+=1\n",
        "df_cross"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXnQMFDKL7gF"
      },
      "source": [
        "#CSV fileを保存\n",
        "csv = df_cross.to_csv(csv_path, encoding='utf_8_sig')"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cRZtvJGoHZIp"
      },
      "source": [
        "#**Training & evaluation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZCjIXc4ULq1",
        "outputId": "05368739-379b-401c-f0a2-4b0eb519677b"
      },
      "source": [
        "from __future__ import print_function, division\n",
        "!pip install torch_optimizer\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch_optimizer as optim\n",
        "import torch.utils.data as data\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "import math\n",
        "import shutil\n",
        "\n",
        "import glob\n",
        "import os.path as osp\n",
        "import random\n",
        "import json\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "%matplotlib inline\n",
        "\n",
        "import pandas as pd\n",
        "import csv\n",
        "\n",
        "#サポートパッチのインポート\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "\n",
        "plt.ion()   # interactive mode\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "!pip install efficientnet_pytorch\n",
        "from efficientnet_pytorch import EfficientNet \n",
        "\n",
        "import numpy as np\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch_optimizer in /usr/local/lib/python3.7/dist-packages (0.3.0)\n",
            "Requirement already satisfied: pytorch-ranger>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from torch_optimizer) (0.1.1)\n",
            "Requirement already satisfied: torch>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from torch_optimizer) (1.10.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.5.0->torch_optimizer) (3.10.0.2)\n",
            "Requirement already satisfied: efficientnet_pytorch in /usr/local/lib/python3.7/dist-packages (0.7.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from efficientnet_pytorch) (1.10.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->efficientnet_pytorch) (3.10.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YiozE-KzUZPp"
      },
      "source": [
        "#Module群\n",
        "\n",
        "#Define ResNet5-VGGFace\n",
        "class Resnet50_ft_dag(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Resnet50_ft_dag, self).__init__()\n",
        "        self.meta = {'mean': [131.0912, 103.8827, 91.4953],\n",
        "                     'std': [1, 1, 1],\n",
        "                     'imageSize': [224, 224, 3]}\n",
        "        self.conv1_7x7_s2 = nn.Conv2d(3, 64, kernel_size=[7, 7], stride=(2, 2), padding=(3, 3), bias=False)\n",
        "        self.conv1_7x7_s2_bn = nn.BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv1_relu_7x7_s2 = nn.ReLU()\n",
        "        self.pool1_3x3_s2 = nn.MaxPool2d(kernel_size=[3, 3], stride=[2, 2], padding=(0, 0), dilation=1, ceil_mode=True)\n",
        "        self.conv2_1_1x1_reduce = nn.Conv2d(64, 64, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv2_1_1x1_reduce_bn = nn.BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv2_1_1x1_reduce_relu = nn.ReLU()\n",
        "        self.conv2_1_3x3 = nn.Conv2d(64, 64, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
        "        self.conv2_1_3x3_bn = nn.BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv2_1_3x3_relu = nn.ReLU()\n",
        "        self.conv2_1_1x1_increase = nn.Conv2d(64, 256, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv2_1_1x1_increase_bn = nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv2_1_1x1_proj = nn.Conv2d(64, 256, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv2_1_1x1_proj_bn = nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv2_1_relu = nn.ReLU()\n",
        "        self.conv2_2_1x1_reduce = nn.Conv2d(256, 64, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv2_2_1x1_reduce_bn = nn.BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv2_2_1x1_reduce_relu = nn.ReLU()\n",
        "        self.conv2_2_3x3 = nn.Conv2d(64, 64, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
        "        self.conv2_2_3x3_bn = nn.BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv2_2_3x3_relu = nn.ReLU()\n",
        "        self.conv2_2_1x1_increase = nn.Conv2d(64, 256, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv2_2_1x1_increase_bn = nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv2_2_relu = nn.ReLU()\n",
        "        self.conv2_3_1x1_reduce = nn.Conv2d(256, 64, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv2_3_1x1_reduce_bn = nn.BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv2_3_1x1_reduce_relu = nn.ReLU()\n",
        "        self.conv2_3_3x3 = nn.Conv2d(64, 64, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
        "        self.conv2_3_3x3_bn = nn.BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv2_3_3x3_relu = nn.ReLU()\n",
        "        self.conv2_3_1x1_increase = nn.Conv2d(64, 256, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv2_3_1x1_increase_bn = nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv2_3_relu = nn.ReLU()\n",
        "        self.conv3_1_1x1_reduce = nn.Conv2d(256, 128, kernel_size=[1, 1], stride=(2, 2), bias=False)\n",
        "        self.conv3_1_1x1_reduce_bn = nn.BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv3_1_1x1_reduce_relu = nn.ReLU()\n",
        "        self.conv3_1_3x3 = nn.Conv2d(128, 128, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
        "        self.conv3_1_3x3_bn = nn.BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv3_1_3x3_relu = nn.ReLU()\n",
        "        self.conv3_1_1x1_increase = nn.Conv2d(128, 512, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv3_1_1x1_increase_bn = nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv3_1_1x1_proj = nn.Conv2d(256, 512, kernel_size=[1, 1], stride=(2, 2), bias=False)\n",
        "        self.conv3_1_1x1_proj_bn = nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv3_1_relu = nn.ReLU()\n",
        "        self.conv3_2_1x1_reduce = nn.Conv2d(512, 128, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv3_2_1x1_reduce_bn = nn.BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv3_2_1x1_reduce_relu = nn.ReLU()\n",
        "        self.conv3_2_3x3 = nn.Conv2d(128, 128, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
        "        self.conv3_2_3x3_bn = nn.BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv3_2_3x3_relu = nn.ReLU()\n",
        "        self.conv3_2_1x1_increase = nn.Conv2d(128, 512, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv3_2_1x1_increase_bn = nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv3_2_relu = nn.ReLU()\n",
        "        self.conv3_3_1x1_reduce = nn.Conv2d(512, 128, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv3_3_1x1_reduce_bn = nn.BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv3_3_1x1_reduce_relu = nn.ReLU()\n",
        "        self.conv3_3_3x3 = nn.Conv2d(128, 128, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
        "        self.conv3_3_3x3_bn = nn.BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv3_3_3x3_relu = nn.ReLU()\n",
        "        self.conv3_3_1x1_increase = nn.Conv2d(128, 512, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv3_3_1x1_increase_bn = nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv3_3_relu = nn.ReLU()\n",
        "        self.conv3_4_1x1_reduce = nn.Conv2d(512, 128, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv3_4_1x1_reduce_bn = nn.BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv3_4_1x1_reduce_relu = nn.ReLU()\n",
        "        self.conv3_4_3x3 = nn.Conv2d(128, 128, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
        "        self.conv3_4_3x3_bn = nn.BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv3_4_3x3_relu = nn.ReLU()\n",
        "        self.conv3_4_1x1_increase = nn.Conv2d(128, 512, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv3_4_1x1_increase_bn = nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv3_4_relu = nn.ReLU()\n",
        "        self.conv4_1_1x1_reduce = nn.Conv2d(512, 256, kernel_size=[1, 1], stride=(2, 2), bias=False)\n",
        "        self.conv4_1_1x1_reduce_bn = nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv4_1_1x1_reduce_relu = nn.ReLU()\n",
        "        self.conv4_1_3x3 = nn.Conv2d(256, 256, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
        "        self.conv4_1_3x3_bn = nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv4_1_3x3_relu = nn.ReLU()\n",
        "        self.conv4_1_1x1_increase = nn.Conv2d(256, 1024, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv4_1_1x1_increase_bn = nn.BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv4_1_1x1_proj = nn.Conv2d(512, 1024, kernel_size=[1, 1], stride=(2, 2), bias=False)\n",
        "        self.conv4_1_1x1_proj_bn = nn.BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv4_1_relu = nn.ReLU()\n",
        "        self.conv4_2_1x1_reduce = nn.Conv2d(1024, 256, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv4_2_1x1_reduce_bn = nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv4_2_1x1_reduce_relu = nn.ReLU()\n",
        "        self.conv4_2_3x3 = nn.Conv2d(256, 256, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
        "        self.conv4_2_3x3_bn = nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv4_2_3x3_relu = nn.ReLU()\n",
        "        self.conv4_2_1x1_increase = nn.Conv2d(256, 1024, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv4_2_1x1_increase_bn = nn.BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv4_2_relu = nn.ReLU()\n",
        "        self.conv4_3_1x1_reduce = nn.Conv2d(1024, 256, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv4_3_1x1_reduce_bn = nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv4_3_1x1_reduce_relu = nn.ReLU()\n",
        "        self.conv4_3_3x3 = nn.Conv2d(256, 256, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
        "        self.conv4_3_3x3_bn = nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv4_3_3x3_relu = nn.ReLU()\n",
        "        self.conv4_3_1x1_increase = nn.Conv2d(256, 1024, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv4_3_1x1_increase_bn = nn.BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv4_3_relu = nn.ReLU()\n",
        "        self.conv4_4_1x1_reduce = nn.Conv2d(1024, 256, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv4_4_1x1_reduce_bn = nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv4_4_1x1_reduce_relu = nn.ReLU()\n",
        "        self.conv4_4_3x3 = nn.Conv2d(256, 256, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
        "        self.conv4_4_3x3_bn = nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv4_4_3x3_relu = nn.ReLU()\n",
        "        self.conv4_4_1x1_increase = nn.Conv2d(256, 1024, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv4_4_1x1_increase_bn = nn.BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv4_4_relu = nn.ReLU()\n",
        "        self.conv4_5_1x1_reduce = nn.Conv2d(1024, 256, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv4_5_1x1_reduce_bn = nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv4_5_1x1_reduce_relu = nn.ReLU()\n",
        "        self.conv4_5_3x3 = nn.Conv2d(256, 256, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
        "        self.conv4_5_3x3_bn = nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv4_5_3x3_relu = nn.ReLU()\n",
        "        self.conv4_5_1x1_increase = nn.Conv2d(256, 1024, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv4_5_1x1_increase_bn = nn.BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv4_5_relu = nn.ReLU()\n",
        "        self.conv4_6_1x1_reduce = nn.Conv2d(1024, 256, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv4_6_1x1_reduce_bn = nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv4_6_1x1_reduce_relu = nn.ReLU()\n",
        "        self.conv4_6_3x3 = nn.Conv2d(256, 256, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
        "        self.conv4_6_3x3_bn = nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv4_6_3x3_relu = nn.ReLU()\n",
        "        self.conv4_6_1x1_increase = nn.Conv2d(256, 1024, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv4_6_1x1_increase_bn = nn.BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv4_6_relu = nn.ReLU()\n",
        "        self.conv5_1_1x1_reduce = nn.Conv2d(1024, 512, kernel_size=[1, 1], stride=(2, 2), bias=False)\n",
        "        self.conv5_1_1x1_reduce_bn = nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv5_1_1x1_reduce_relu = nn.ReLU()\n",
        "        self.conv5_1_3x3 = nn.Conv2d(512, 512, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
        "        self.conv5_1_3x3_bn = nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv5_1_3x3_relu = nn.ReLU()\n",
        "        self.conv5_1_1x1_increase = nn.Conv2d(512, 2048, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv5_1_1x1_increase_bn = nn.BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv5_1_1x1_proj = nn.Conv2d(1024, 2048, kernel_size=[1, 1], stride=(2, 2), bias=False)\n",
        "        self.conv5_1_1x1_proj_bn = nn.BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv5_1_relu = nn.ReLU()\n",
        "        self.conv5_2_1x1_reduce = nn.Conv2d(2048, 512, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv5_2_1x1_reduce_bn = nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv5_2_1x1_reduce_relu = nn.ReLU()\n",
        "        self.conv5_2_3x3 = nn.Conv2d(512, 512, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
        "        self.conv5_2_3x3_bn = nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv5_2_3x3_relu = nn.ReLU()\n",
        "        self.conv5_2_1x1_increase = nn.Conv2d(512, 2048, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv5_2_1x1_increase_bn = nn.BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv5_2_relu = nn.ReLU()\n",
        "        self.conv5_3_1x1_reduce = nn.Conv2d(2048, 512, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv5_3_1x1_reduce_bn = nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv5_3_1x1_reduce_relu = nn.ReLU()\n",
        "        self.conv5_3_3x3 = nn.Conv2d(512, 512, kernel_size=[3, 3], stride=(1, 1), padding=(1, 1), bias=False)\n",
        "        self.conv5_3_3x3_bn = nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv5_3_3x3_relu = nn.ReLU()\n",
        "        self.conv5_3_1x1_increase = nn.Conv2d(512, 2048, kernel_size=[1, 1], stride=(1, 1), bias=False)\n",
        "        self.conv5_3_1x1_increase_bn = nn.BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "        self.conv5_3_relu = nn.ReLU()\n",
        "        self.pool5_7x7_s1 = nn.AvgPool2d(kernel_size=[7, 7], stride=[1, 1], padding=0)\n",
        "        self.classifier = nn.Conv2d(2048, 8631, kernel_size=[1, 1], stride=(1, 1))\n",
        "\n",
        "    def forward(self, data):\n",
        "        conv1_7x7_s2 = self.conv1_7x7_s2(data)\n",
        "        conv1_7x7_s2_bn = self.conv1_7x7_s2_bn(conv1_7x7_s2)\n",
        "        conv1_7x7_s2_bnxx = self.conv1_relu_7x7_s2(conv1_7x7_s2_bn)\n",
        "        pool1_3x3_s2 = self.pool1_3x3_s2(conv1_7x7_s2_bnxx)\n",
        "        conv2_1_1x1_reduce = self.conv2_1_1x1_reduce(pool1_3x3_s2)\n",
        "        conv2_1_1x1_reduce_bn = self.conv2_1_1x1_reduce_bn(conv2_1_1x1_reduce)\n",
        "        conv2_1_1x1_reduce_bnxx = self.conv2_1_1x1_reduce_relu(conv2_1_1x1_reduce_bn)\n",
        "        conv2_1_3x3 = self.conv2_1_3x3(conv2_1_1x1_reduce_bnxx)\n",
        "        conv2_1_3x3_bn = self.conv2_1_3x3_bn(conv2_1_3x3)\n",
        "        conv2_1_3x3_bnxx = self.conv2_1_3x3_relu(conv2_1_3x3_bn)\n",
        "        conv2_1_1x1_increase = self.conv2_1_1x1_increase(conv2_1_3x3_bnxx)\n",
        "        conv2_1_1x1_increase_bn = self.conv2_1_1x1_increase_bn(conv2_1_1x1_increase)\n",
        "        conv2_1_1x1_proj = self.conv2_1_1x1_proj(pool1_3x3_s2)\n",
        "        conv2_1_1x1_proj_bn = self.conv2_1_1x1_proj_bn(conv2_1_1x1_proj)\n",
        "        conv2_1 = torch.add(conv2_1_1x1_proj_bn, 1, conv2_1_1x1_increase_bn)\n",
        "        conv2_1x = self.conv2_1_relu(conv2_1)\n",
        "        conv2_2_1x1_reduce = self.conv2_2_1x1_reduce(conv2_1x)\n",
        "        conv2_2_1x1_reduce_bn = self.conv2_2_1x1_reduce_bn(conv2_2_1x1_reduce)\n",
        "        conv2_2_1x1_reduce_bnxx = self.conv2_2_1x1_reduce_relu(conv2_2_1x1_reduce_bn)\n",
        "        conv2_2_3x3 = self.conv2_2_3x3(conv2_2_1x1_reduce_bnxx)\n",
        "        conv2_2_3x3_bn = self.conv2_2_3x3_bn(conv2_2_3x3)\n",
        "        conv2_2_3x3_bnxx = self.conv2_2_3x3_relu(conv2_2_3x3_bn)\n",
        "        conv2_2_1x1_increase = self.conv2_2_1x1_increase(conv2_2_3x3_bnxx)\n",
        "        conv2_2_1x1_increase_bn = self.conv2_2_1x1_increase_bn(conv2_2_1x1_increase)\n",
        "        conv2_2 = torch.add(conv2_1x, 1, conv2_2_1x1_increase_bn)\n",
        "        conv2_2x = self.conv2_2_relu(conv2_2)\n",
        "        conv2_3_1x1_reduce = self.conv2_3_1x1_reduce(conv2_2x)\n",
        "        conv2_3_1x1_reduce_bn = self.conv2_3_1x1_reduce_bn(conv2_3_1x1_reduce)\n",
        "        conv2_3_1x1_reduce_bnxx = self.conv2_3_1x1_reduce_relu(conv2_3_1x1_reduce_bn)\n",
        "        conv2_3_3x3 = self.conv2_3_3x3(conv2_3_1x1_reduce_bnxx)\n",
        "        conv2_3_3x3_bn = self.conv2_3_3x3_bn(conv2_3_3x3)\n",
        "        conv2_3_3x3_bnxx = self.conv2_3_3x3_relu(conv2_3_3x3_bn)\n",
        "        conv2_3_1x1_increase = self.conv2_3_1x1_increase(conv2_3_3x3_bnxx)\n",
        "        conv2_3_1x1_increase_bn = self.conv2_3_1x1_increase_bn(conv2_3_1x1_increase)\n",
        "        conv2_3 = torch.add(conv2_2x, 1, conv2_3_1x1_increase_bn)\n",
        "        conv2_3x = self.conv2_3_relu(conv2_3)\n",
        "        conv3_1_1x1_reduce = self.conv3_1_1x1_reduce(conv2_3x)\n",
        "        conv3_1_1x1_reduce_bn = self.conv3_1_1x1_reduce_bn(conv3_1_1x1_reduce)\n",
        "        conv3_1_1x1_reduce_bnxx = self.conv3_1_1x1_reduce_relu(conv3_1_1x1_reduce_bn)\n",
        "        conv3_1_3x3 = self.conv3_1_3x3(conv3_1_1x1_reduce_bnxx)\n",
        "        conv3_1_3x3_bn = self.conv3_1_3x3_bn(conv3_1_3x3)\n",
        "        conv3_1_3x3_bnxx = self.conv3_1_3x3_relu(conv3_1_3x3_bn)\n",
        "        conv3_1_1x1_increase = self.conv3_1_1x1_increase(conv3_1_3x3_bnxx)\n",
        "        conv3_1_1x1_increase_bn = self.conv3_1_1x1_increase_bn(conv3_1_1x1_increase)\n",
        "        conv3_1_1x1_proj = self.conv3_1_1x1_proj(conv2_3x)\n",
        "        conv3_1_1x1_proj_bn = self.conv3_1_1x1_proj_bn(conv3_1_1x1_proj)\n",
        "        conv3_1 = torch.add(conv3_1_1x1_proj_bn, 1, conv3_1_1x1_increase_bn)\n",
        "        conv3_1x = self.conv3_1_relu(conv3_1)\n",
        "        conv3_2_1x1_reduce = self.conv3_2_1x1_reduce(conv3_1x)\n",
        "        conv3_2_1x1_reduce_bn = self.conv3_2_1x1_reduce_bn(conv3_2_1x1_reduce)\n",
        "        conv3_2_1x1_reduce_bnxx = self.conv3_2_1x1_reduce_relu(conv3_2_1x1_reduce_bn)\n",
        "        conv3_2_3x3 = self.conv3_2_3x3(conv3_2_1x1_reduce_bnxx)\n",
        "        conv3_2_3x3_bn = self.conv3_2_3x3_bn(conv3_2_3x3)\n",
        "        conv3_2_3x3_bnxx = self.conv3_2_3x3_relu(conv3_2_3x3_bn)\n",
        "        conv3_2_1x1_increase = self.conv3_2_1x1_increase(conv3_2_3x3_bnxx)\n",
        "        conv3_2_1x1_increase_bn = self.conv3_2_1x1_increase_bn(conv3_2_1x1_increase)\n",
        "        conv3_2 = torch.add(conv3_1x, 1, conv3_2_1x1_increase_bn)\n",
        "        conv3_2x = self.conv3_2_relu(conv3_2)\n",
        "        conv3_3_1x1_reduce = self.conv3_3_1x1_reduce(conv3_2x)\n",
        "        conv3_3_1x1_reduce_bn = self.conv3_3_1x1_reduce_bn(conv3_3_1x1_reduce)\n",
        "        conv3_3_1x1_reduce_bnxx = self.conv3_3_1x1_reduce_relu(conv3_3_1x1_reduce_bn)\n",
        "        conv3_3_3x3 = self.conv3_3_3x3(conv3_3_1x1_reduce_bnxx)\n",
        "        conv3_3_3x3_bn = self.conv3_3_3x3_bn(conv3_3_3x3)\n",
        "        conv3_3_3x3_bnxx = self.conv3_3_3x3_relu(conv3_3_3x3_bn)\n",
        "        conv3_3_1x1_increase = self.conv3_3_1x1_increase(conv3_3_3x3_bnxx)\n",
        "        conv3_3_1x1_increase_bn = self.conv3_3_1x1_increase_bn(conv3_3_1x1_increase)\n",
        "        conv3_3 = torch.add(conv3_2x, 1, conv3_3_1x1_increase_bn)\n",
        "        conv3_3x = self.conv3_3_relu(conv3_3)\n",
        "        conv3_4_1x1_reduce = self.conv3_4_1x1_reduce(conv3_3x)\n",
        "        conv3_4_1x1_reduce_bn = self.conv3_4_1x1_reduce_bn(conv3_4_1x1_reduce)\n",
        "        conv3_4_1x1_reduce_bnxx = self.conv3_4_1x1_reduce_relu(conv3_4_1x1_reduce_bn)\n",
        "        conv3_4_3x3 = self.conv3_4_3x3(conv3_4_1x1_reduce_bnxx)\n",
        "        conv3_4_3x3_bn = self.conv3_4_3x3_bn(conv3_4_3x3)\n",
        "        conv3_4_3x3_bnxx = self.conv3_4_3x3_relu(conv3_4_3x3_bn)\n",
        "        conv3_4_1x1_increase = self.conv3_4_1x1_increase(conv3_4_3x3_bnxx)\n",
        "        conv3_4_1x1_increase_bn = self.conv3_4_1x1_increase_bn(conv3_4_1x1_increase)\n",
        "        conv3_4 = torch.add(conv3_3x, 1, conv3_4_1x1_increase_bn)\n",
        "        conv3_4x = self.conv3_4_relu(conv3_4)\n",
        "        conv4_1_1x1_reduce = self.conv4_1_1x1_reduce(conv3_4x)\n",
        "        conv4_1_1x1_reduce_bn = self.conv4_1_1x1_reduce_bn(conv4_1_1x1_reduce)\n",
        "        conv4_1_1x1_reduce_bnxx = self.conv4_1_1x1_reduce_relu(conv4_1_1x1_reduce_bn)\n",
        "        conv4_1_3x3 = self.conv4_1_3x3(conv4_1_1x1_reduce_bnxx)\n",
        "        conv4_1_3x3_bn = self.conv4_1_3x3_bn(conv4_1_3x3)\n",
        "        conv4_1_3x3_bnxx = self.conv4_1_3x3_relu(conv4_1_3x3_bn)\n",
        "        conv4_1_1x1_increase = self.conv4_1_1x1_increase(conv4_1_3x3_bnxx)\n",
        "        conv4_1_1x1_increase_bn = self.conv4_1_1x1_increase_bn(conv4_1_1x1_increase)\n",
        "        conv4_1_1x1_proj = self.conv4_1_1x1_proj(conv3_4x)\n",
        "        conv4_1_1x1_proj_bn = self.conv4_1_1x1_proj_bn(conv4_1_1x1_proj)\n",
        "        conv4_1 = torch.add(conv4_1_1x1_proj_bn, 1, conv4_1_1x1_increase_bn)\n",
        "        conv4_1x = self.conv4_1_relu(conv4_1)\n",
        "        conv4_2_1x1_reduce = self.conv4_2_1x1_reduce(conv4_1x)\n",
        "        conv4_2_1x1_reduce_bn = self.conv4_2_1x1_reduce_bn(conv4_2_1x1_reduce)\n",
        "        conv4_2_1x1_reduce_bnxx = self.conv4_2_1x1_reduce_relu(conv4_2_1x1_reduce_bn)\n",
        "        conv4_2_3x3 = self.conv4_2_3x3(conv4_2_1x1_reduce_bnxx)\n",
        "        conv4_2_3x3_bn = self.conv4_2_3x3_bn(conv4_2_3x3)\n",
        "        conv4_2_3x3_bnxx = self.conv4_2_3x3_relu(conv4_2_3x3_bn)\n",
        "        conv4_2_1x1_increase = self.conv4_2_1x1_increase(conv4_2_3x3_bnxx)\n",
        "        conv4_2_1x1_increase_bn = self.conv4_2_1x1_increase_bn(conv4_2_1x1_increase)\n",
        "        conv4_2 = torch.add(conv4_1x, 1, conv4_2_1x1_increase_bn)\n",
        "        conv4_2x = self.conv4_2_relu(conv4_2)\n",
        "        conv4_3_1x1_reduce = self.conv4_3_1x1_reduce(conv4_2x)\n",
        "        conv4_3_1x1_reduce_bn = self.conv4_3_1x1_reduce_bn(conv4_3_1x1_reduce)\n",
        "        conv4_3_1x1_reduce_bnxx = self.conv4_3_1x1_reduce_relu(conv4_3_1x1_reduce_bn)\n",
        "        conv4_3_3x3 = self.conv4_3_3x3(conv4_3_1x1_reduce_bnxx)\n",
        "        conv4_3_3x3_bn = self.conv4_3_3x3_bn(conv4_3_3x3)\n",
        "        conv4_3_3x3_bnxx = self.conv4_3_3x3_relu(conv4_3_3x3_bn)\n",
        "        conv4_3_1x1_increase = self.conv4_3_1x1_increase(conv4_3_3x3_bnxx)\n",
        "        conv4_3_1x1_increase_bn = self.conv4_3_1x1_increase_bn(conv4_3_1x1_increase)\n",
        "        conv4_3 = torch.add(conv4_2x, 1, conv4_3_1x1_increase_bn)\n",
        "        conv4_3x = self.conv4_3_relu(conv4_3)\n",
        "        conv4_4_1x1_reduce = self.conv4_4_1x1_reduce(conv4_3x)\n",
        "        conv4_4_1x1_reduce_bn = self.conv4_4_1x1_reduce_bn(conv4_4_1x1_reduce)\n",
        "        conv4_4_1x1_reduce_bnxx = self.conv4_4_1x1_reduce_relu(conv4_4_1x1_reduce_bn)\n",
        "        conv4_4_3x3 = self.conv4_4_3x3(conv4_4_1x1_reduce_bnxx)\n",
        "        conv4_4_3x3_bn = self.conv4_4_3x3_bn(conv4_4_3x3)\n",
        "        conv4_4_3x3_bnxx = self.conv4_4_3x3_relu(conv4_4_3x3_bn)\n",
        "        conv4_4_1x1_increase = self.conv4_4_1x1_increase(conv4_4_3x3_bnxx)\n",
        "        conv4_4_1x1_increase_bn = self.conv4_4_1x1_increase_bn(conv4_4_1x1_increase)\n",
        "        conv4_4 = torch.add(conv4_3x, 1, conv4_4_1x1_increase_bn)\n",
        "        conv4_4x = self.conv4_4_relu(conv4_4)\n",
        "        conv4_5_1x1_reduce = self.conv4_5_1x1_reduce(conv4_4x)\n",
        "        conv4_5_1x1_reduce_bn = self.conv4_5_1x1_reduce_bn(conv4_5_1x1_reduce)\n",
        "        conv4_5_1x1_reduce_bnxx = self.conv4_5_1x1_reduce_relu(conv4_5_1x1_reduce_bn)\n",
        "        conv4_5_3x3 = self.conv4_5_3x3(conv4_5_1x1_reduce_bnxx)\n",
        "        conv4_5_3x3_bn = self.conv4_5_3x3_bn(conv4_5_3x3)\n",
        "        conv4_5_3x3_bnxx = self.conv4_5_3x3_relu(conv4_5_3x3_bn)\n",
        "        conv4_5_1x1_increase = self.conv4_5_1x1_increase(conv4_5_3x3_bnxx)\n",
        "        conv4_5_1x1_increase_bn = self.conv4_5_1x1_increase_bn(conv4_5_1x1_increase)\n",
        "        conv4_5 = torch.add(conv4_4x, 1, conv4_5_1x1_increase_bn)\n",
        "        conv4_5x = self.conv4_5_relu(conv4_5)\n",
        "        conv4_6_1x1_reduce = self.conv4_6_1x1_reduce(conv4_5x)\n",
        "        conv4_6_1x1_reduce_bn = self.conv4_6_1x1_reduce_bn(conv4_6_1x1_reduce)\n",
        "        conv4_6_1x1_reduce_bnxx = self.conv4_6_1x1_reduce_relu(conv4_6_1x1_reduce_bn)\n",
        "        conv4_6_3x3 = self.conv4_6_3x3(conv4_6_1x1_reduce_bnxx)\n",
        "        conv4_6_3x3_bn = self.conv4_6_3x3_bn(conv4_6_3x3)\n",
        "        conv4_6_3x3_bnxx = self.conv4_6_3x3_relu(conv4_6_3x3_bn)\n",
        "        conv4_6_1x1_increase = self.conv4_6_1x1_increase(conv4_6_3x3_bnxx)\n",
        "        conv4_6_1x1_increase_bn = self.conv4_6_1x1_increase_bn(conv4_6_1x1_increase)\n",
        "        conv4_6 = torch.add(conv4_5x, 1, conv4_6_1x1_increase_bn)\n",
        "        conv4_6x = self.conv4_6_relu(conv4_6)\n",
        "        conv5_1_1x1_reduce = self.conv5_1_1x1_reduce(conv4_6x)\n",
        "        conv5_1_1x1_reduce_bn = self.conv5_1_1x1_reduce_bn(conv5_1_1x1_reduce)\n",
        "        conv5_1_1x1_reduce_bnxx = self.conv5_1_1x1_reduce_relu(conv5_1_1x1_reduce_bn)\n",
        "        conv5_1_3x3 = self.conv5_1_3x3(conv5_1_1x1_reduce_bnxx)\n",
        "        conv5_1_3x3_bn = self.conv5_1_3x3_bn(conv5_1_3x3)\n",
        "        conv5_1_3x3_bnxx = self.conv5_1_3x3_relu(conv5_1_3x3_bn)\n",
        "        conv5_1_1x1_increase = self.conv5_1_1x1_increase(conv5_1_3x3_bnxx)\n",
        "        conv5_1_1x1_increase_bn = self.conv5_1_1x1_increase_bn(conv5_1_1x1_increase)\n",
        "        conv5_1_1x1_proj = self.conv5_1_1x1_proj(conv4_6x)\n",
        "        conv5_1_1x1_proj_bn = self.conv5_1_1x1_proj_bn(conv5_1_1x1_proj)\n",
        "        conv5_1 = torch.add(conv5_1_1x1_proj_bn, 1, conv5_1_1x1_increase_bn)\n",
        "        conv5_1x = self.conv5_1_relu(conv5_1)\n",
        "        conv5_2_1x1_reduce = self.conv5_2_1x1_reduce(conv5_1x)\n",
        "        conv5_2_1x1_reduce_bn = self.conv5_2_1x1_reduce_bn(conv5_2_1x1_reduce)\n",
        "        conv5_2_1x1_reduce_bnxx = self.conv5_2_1x1_reduce_relu(conv5_2_1x1_reduce_bn)\n",
        "        conv5_2_3x3 = self.conv5_2_3x3(conv5_2_1x1_reduce_bnxx)\n",
        "        conv5_2_3x3_bn = self.conv5_2_3x3_bn(conv5_2_3x3)\n",
        "        conv5_2_3x3_bnxx = self.conv5_2_3x3_relu(conv5_2_3x3_bn)\n",
        "        conv5_2_1x1_increase = self.conv5_2_1x1_increase(conv5_2_3x3_bnxx)\n",
        "        conv5_2_1x1_increase_bn = self.conv5_2_1x1_increase_bn(conv5_2_1x1_increase)\n",
        "        conv5_2 = torch.add(conv5_1x, 1, conv5_2_1x1_increase_bn)\n",
        "        conv5_2x = self.conv5_2_relu(conv5_2)\n",
        "        conv5_3_1x1_reduce = self.conv5_3_1x1_reduce(conv5_2x)\n",
        "        conv5_3_1x1_reduce_bn = self.conv5_3_1x1_reduce_bn(conv5_3_1x1_reduce)\n",
        "        conv5_3_1x1_reduce_bnxx = self.conv5_3_1x1_reduce_relu(conv5_3_1x1_reduce_bn)\n",
        "        conv5_3_3x3 = self.conv5_3_3x3(conv5_3_1x1_reduce_bnxx)\n",
        "        conv5_3_3x3_bn = self.conv5_3_3x3_bn(conv5_3_3x3)\n",
        "        conv5_3_3x3_bnxx = self.conv5_3_3x3_relu(conv5_3_3x3_bn)\n",
        "        conv5_3_1x1_increase = self.conv5_3_1x1_increase(conv5_3_3x3_bnxx)\n",
        "        conv5_3_1x1_increase_bn = self.conv5_3_1x1_increase_bn(conv5_3_1x1_increase)\n",
        "        conv5_3 = torch.add(conv5_2x, 1, conv5_3_1x1_increase_bn)\n",
        "        conv5_3x = self.conv5_3_relu(conv5_3)\n",
        "        pool5_7x7_s1 = self.pool5_7x7_s1(conv5_3x)\n",
        "        classifier_preflatten = self.classifier(pool5_7x7_s1)\n",
        "        classifier = classifier_preflatten.view(classifier_preflatten.size(0), -1)\n",
        "        #return classifier, pool5_7x7_s1 　出力を変更しておかないと次元が合わないと言われる\n",
        "        return classifier\n",
        "\n",
        "def resnet50_ft_dag(weights_path=None, **kwargs):\n",
        "    \"\"\"\n",
        "    load imported model instance\n",
        "\n",
        "    Args:\n",
        "        weights_path (str): If set, loads model weights from the given path\n",
        "    \"\"\"\n",
        "    model = Resnet50_ft_dag()\n",
        "    if weights_path:\n",
        "        state_dict = torch.load(weights_path)\n",
        "        model.load_state_dict(state_dict)\n",
        "    return model\n",
        "\n",
        "class Flatten(nn.Module): \n",
        "    \"\"\"One layer module that flattens its input.\"\"\"\n",
        "    def __init__(self):\n",
        "        super(Flatten, self).__init__()\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)\n",
        "        return x\n",
        "\n",
        "def pre_process(data_dir):\n",
        "    # 入力画像の前処理をするクラス\n",
        "    # 訓練時と推論時で処理が異なる\n",
        "\n",
        "    \"\"\"\n",
        "        画像の前処理クラス。訓練時、検証時で異なる動作をする。\n",
        "        画像のサイズをリサイズし、色を標準化する。\n",
        "        訓練時はRandomResizedCropとRandomHorizontalFlipでデータオーギュメンテーションする。\n",
        "\n",
        "\n",
        "        Attributes\n",
        "        ----------\n",
        "        resize : int\n",
        "            リサイズ先の画像の大きさ。\n",
        "        mean : (R, G, B)\n",
        "            各色チャネルの平均値。\n",
        "        std : (R, G, B)\n",
        "            各色チャネルの標準偏差。\n",
        "    \"\"\"\n",
        "\n",
        "    data_transforms = {\n",
        "        'train': transforms.Compose([\n",
        "            transforms.RandomResizedCrop(224, scale=(0.75,1.0)),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "        ]),\n",
        "        'val': transforms.Compose([\n",
        "            transforms.Resize(224),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "        ]),\n",
        "    }\n",
        "\n",
        "    data_dir = data_dir\n",
        "    n_samples = len(data_dir)\n",
        "\n",
        "    image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
        "                                              data_transforms[x])\n",
        "                      for x in ['train', 'val']}\n",
        "    dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=20,\n",
        "                                                shuffle=True, num_workers=os.cpu_count(), pin_memory=True)\n",
        "                  for x in ['train', 'val']}\n",
        "    dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
        "    class_names = image_datasets['train'].classes\n",
        "\n",
        "\n",
        "    print(class_names)\n",
        "    k=0\n",
        "    for i in class_names:\n",
        "        print(class_names[k]+\"_train:\"+str(len(os.listdir(path=data_dir + '/train/'+class_names[k]))))\n",
        "        k+=1\n",
        "    k=0\n",
        "    for i in class_names:\n",
        "        print(class_names[k]+\"_val:\"+str(len(os.listdir(path=data_dir + '/val/'+class_names[k]))))\n",
        "        k+=1\n",
        "\n",
        "    print(\"training data set_total：\"+ str(len(image_datasets['train'])))\n",
        "    print(\"validating data set_total：\"+str(len(image_datasets['val'])))\n",
        "    \n",
        "    return image_datasets, dataloaders, dataset_sizes, class_names, device\n",
        "\n",
        "\n",
        "#少数の画像を可視化\n",
        "def imshow(inp, title=None):\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    inp = std * inp + mean\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "    plt.imshow(inp)\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
        "\n",
        "\n",
        "def getBatch(dataloaders):    \n",
        "    # Get a batch of training data\n",
        "    inputs, classes = next(iter(dataloaders['train']))\n",
        "\n",
        "    # Make a grid from batch\n",
        "    out = torchvision.utils.make_grid(inputs)\n",
        "\n",
        "    #imshow(out, title=[class_names[x] for x in classes])\n",
        "    return(inputs, classes)\n",
        "\n",
        "#Defining early stopping class\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "class EarlyStopping:\n",
        "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
        "    def __init__(self, patience=7, verbose=False, delta=0):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            patience (int): How long to wait after last time validation loss improved.\n",
        "                            Default: 7\n",
        "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
        "                            Default: False\n",
        "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
        "                            Default: 0\n",
        "        \"\"\"\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.val_loss_min = np.Inf\n",
        "        self.delta = delta\n",
        "\n",
        "    def __call__(self, val_loss, model):\n",
        "\n",
        "        score = -val_loss\n",
        "\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "            self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, val_loss, model):\n",
        "        '''Saves model when validation loss decrease.'''\n",
        "        if self.verbose:\n",
        "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
        "        torch.save(model.state_dict(), 'checkpoint.pt')\n",
        "        self.val_loss_min = val_loss\n",
        "\n",
        "\n",
        "#Train models\n",
        "def train_model(model, criterion, optimizer, patience, num_epochs):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    # to track the training loss as the model trains\n",
        "    train_loss = []\n",
        "    # to track the validation loss as the model trains\n",
        "    valid_loss = []\n",
        "\n",
        "\n",
        "    # initialize the early_stopping object\n",
        "    early_stopping = EarlyStopping(patience=patience, verbose=True)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device, non_blocking=True)\n",
        "                labels = labels.to(device, non_blocking=True)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase] \n",
        "            \n",
        "            # record train_loss and valid_loss\n",
        "            if phase == 'train':\n",
        "                train_loss.append(epoch_loss)\n",
        "            if phase == 'val':\n",
        "                valid_loss.append(epoch_loss)\n",
        "            #print(train_loss)\n",
        "            #print(valid_loss)\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                phase, epoch_loss, epoch_acc))\n",
        "\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "      \n",
        "      # early_stopping needs the validation loss to check if it has decresed, \n",
        "      # and if it has, it will make a checkpoint of the current model\n",
        "        if phase == 'val':    \n",
        "            early_stopping(epoch_loss, model)\n",
        "                \n",
        "            if early_stopping.early_stop:\n",
        "                print(\"Early stopping\")\n",
        "                break\n",
        "        print()\n",
        "\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model, train_loss, valid_loss\n",
        "\n",
        "\n",
        "#Visualize model\n",
        "def visualize_model(model, num_images=6):\n",
        "    was_training = model.training\n",
        "    model.eval()\n",
        "    images_so_far = 0\n",
        "    fig = plt.figure()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, labels) in enumerate(dataloaders['val']):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            for j in range(inputs.size()[0]):\n",
        "                images_so_far += 1\n",
        "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
        "                ax.axis('off')\n",
        "                ax.set_title('predicted: {}'.format(class_names[preds[j]]))\n",
        "                imshow(inputs.cpu().data[j])\n",
        "\n",
        "                if images_so_far == num_images:\n",
        "                    model.train(mode=was_training)\n",
        "                    return\n",
        "        model.train(mode=was_training)\n",
        "\n",
        "\n",
        "def training(model_ft, criterion, optimizer_ft,  patience=15, num_epochs=50):\n",
        "    model_ft, train_loss, valid_loss = train_model(model_ft, criterion, optimizer_ft,  patience=patience, num_epochs=num_epochs)\n",
        "\n",
        "\n",
        "#対象のパスからラベルを抜き出して表示\n",
        "def getlabel(image_path):\n",
        "      image_name = os.path.basename(image_path)\n",
        "      label = os.path.basename(os.path.dirname(image_path))\n",
        "      return(image_name, label)\n",
        "\n",
        "'''\n",
        "#変形後の画像を表示\n",
        "def image_transform(image_path):\n",
        "\n",
        "    image=Image.open(image_path)\n",
        "\n",
        "    \n",
        "    #変形した画像を表示する\n",
        "    transform = transforms.Compose([\n",
        "            transforms.Resize(256),\n",
        "            transforms.CenterCrop(224)])\n",
        "    image_transformed = transform(image)\n",
        "    plt.imshow(np.array(image_transformed))\n",
        "'''\n",
        "\n",
        "#評価のための画像下処理\n",
        "def image_transform(image_path):    \n",
        "    image=Image.open(image_path)\n",
        "    transform = transforms.Compose([\n",
        "            transforms.Resize(256),\n",
        "            transforms.CenterCrop(224),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "    image_tensor = transform(image)\n",
        "\n",
        "    #バッチサイズの次元を先頭に追加した4Dテンソルに変換\n",
        "    image_tensor.unsqueeze_(0)\n",
        "    #print(image_tensor.size())  # torch.Size([1, 3, 224, 224])\n",
        "    image_tensor = image_tensor.to(device) #model_ftをGPUに載せる\n",
        "\n",
        "    return(image_tensor)\n",
        "\n",
        "#モデルにした処理した画像を投入して予測結果を表示\n",
        "def image_eval(image_tensor, label):\n",
        "    output = model_ft(image_tensor)\n",
        "    #print(output.size())  # torch.Size([1, 1000])\n",
        "    #print(output)\n",
        "\n",
        "    #model_pred:クラス名前、prob:確率、pred:クラス番号\n",
        "    prob, pred = torch.topk(nn.Softmax(dim=1)(output), 1)\n",
        "    model_pred = class_names[pred]\n",
        "    \n",
        "    #甲状腺眼症のprobabilityを計算（classが0なら1から減算、classが1ならそのまま）\n",
        "    prob = abs(1-float(prob)-float(pred))\n",
        " \n",
        "    return model_pred, prob, pred\n",
        "\n",
        "    \"\"\"\n",
        "    #probalilityを計算する\n",
        "    pred_prob = torch.topk(nn.Softmax(dim=1)(output), 1)[0]\n",
        "    pred_class = torch.topk(nn.Softmax(dim=1)(output), 1)[1]\n",
        "    if pred_class == 1:\n",
        "        pred_prob = pred_prob\n",
        "    elif pred_class == 0:\n",
        "        pred_prob = 1- pred_prob\n",
        "    return(model_pred, pred_prob)  #class_nameの番号で出力される\n",
        "    \"\"\"\n",
        "\n",
        "def showImage(image_path):\n",
        "    #画像のインポート\n",
        "    img = cv2.imread(image_path, cv2.IMREAD_UNCHANGED)\n",
        "    #画像のリサイズ\n",
        "    height = img.shape[0]\n",
        "    width = img.shape[1]\n",
        "    resized_img = cv2.resize(img, (int(width*300/height), 300))\n",
        "    cv2_imshow(resized_img)\n",
        "\n",
        "def calculateAccuracy (TP, TN, FP, FN):\n",
        "    accuracy = (TP + TN)/ (TP + TN + FP + FN)\n",
        "    precision  = TP/(FP + TP)\n",
        "    recall = TP/(TP + FN)\n",
        "    specificity = TN/(FP + TN)\n",
        "    f_value = (2*recall*precision)/(recall+precision)\n",
        "    return(accuracy, precision, recall, specificity, f_value)\n",
        "\n",
        "\"\"\"\n",
        "・True positive (TN)\n",
        "・False positive (FP)\n",
        "・True negative (TN)\n",
        "・False negative (FN)\n",
        "Accuracy = (TP + TN)/ (TP + TN + FP + FN)\n",
        "Precision = TP/(FP + TP) ※positive predictive value\n",
        "Recall = TP/(TP + FN)　※sensitivity\n",
        "Specificity = TN/(FP + TN)\n",
        "F_value = (2RecallPrecision)/(Recall+Precision)\n",
        "\"\"\"\n",
        "\n",
        "def evaluation(model_ft, testset_dir):\n",
        "    #評価モードにする\n",
        "    model_ft.eval()\n",
        "\n",
        "    #testデータセット内のファイル名を取得\n",
        "    image_path = glob.glob(testset_dir + \"/*/*\")\n",
        "    #random.shuffle(image_path)  #表示順をランダムにする\n",
        "    print('number of images: ' +str(len(image_path)))\n",
        "\n",
        "\n",
        "    TP, FP, TN, FN, TP, FP, TN, FN = [0,0,0,0,0,0,0,0]\n",
        "    image_name_list = []\n",
        "    label_list = []\n",
        "    model_pred_list = []\n",
        "    hum_pred_list = []\n",
        "\n",
        "    model_pred_class = []\n",
        "    model_pred_prob = []\n",
        "\n",
        "    for i in image_path:\n",
        "          image_name, label = getlabel(i)  #画像の名前とラベルを取得\n",
        "          image_tensor = image_transform(i)  #予測のための画像下処理\n",
        "          model_pred, prob, pred = image_eval(image_tensor, label)  #予測結果を出力   \n",
        "          #print('Image: '+ image_name)\n",
        "          #print('Label: '+ label)\n",
        "          #print('Pred: '+ model_pred)\n",
        "          #showImage(i)  #画像を表示\n",
        "          #print() #空白行を入れる\n",
        "          time.sleep(0.1)\n",
        "\n",
        "          image_name_list.append(image_name)\n",
        "          label_list.append(label)\n",
        "          model_pred_list.append(model_pred)\n",
        "\n",
        "          model_pred_class.append(int(pred))\n",
        "          model_pred_prob.append(float(prob))\n",
        "\n",
        "          if label == class_names[0]:\n",
        "              if model_pred == class_names[0]:\n",
        "                  TN += 1\n",
        "              else:\n",
        "                  FP += 1\n",
        "          elif label == class_names[1]:\n",
        "              if model_pred == class_names[1]:\n",
        "                  TP += 1\n",
        "              else:\n",
        "                  FN += 1     \n",
        "\n",
        "    print(TP, FN, TN, FP)\n",
        "\n",
        "    #Accuracyを計算\n",
        "    accuracy, precision, recall, specificity, f_value = calculateAccuracy (TP, TN, FP, FN)\n",
        "    print('Accuracy: ' + str(accuracy))\n",
        "    print('Precision (positive predictive value): ' + str(precision))\n",
        "    print('Recall (sensitivity): ' + str(recall))\n",
        "    print('Specificity: ' + str(specificity))\n",
        "    print('F_value: ' + str(f_value))\n",
        "\n",
        "    #print(model_pred_class)\n",
        "    #print(model_pred_prob)\n",
        "\n",
        "    return TP,TN,FP,FN, accuracy, precision, recall, specificity, f_value, label_list, model_pred_prob, model_pred_class, image_path\n",
        "\n",
        "\n",
        "def make_csv(roc_label_list):\n",
        "    #csvのdata tableを作成\n",
        "    pd.set_option('display.max_rows', 800)  # 省略なしで表示\n",
        "    #columns1 = [\"EfficientNet_32\", \"EfficientNet_64\", \"EfficientNet_128\", \"EfficientNet_256\", \"EfficientNet_512\", \"EfficientNet_558\"]\n",
        "    roc_label_list.extend([\"avg\", \"std\"])\n",
        "    index1 = [\"TP\",\"TN\",\"FP\",\"FN\",\"Accuracy\",\"Positive predictive value\",\"sensitity\",\"specificity\",\"F-value\",\"roc_auc\"]\n",
        "    df = pd.DataFrame(index=index1, columns=roc_label_list)\n",
        "    return df\n",
        "\n",
        "def write_csv(df, col, TP, TN, FP, FN, accuracy, precision, recall, specificity, f_value,roc_auc):\n",
        "    df.iloc[0:10, col] = TP, TN, FP, FN, accuracy, precision, recall, specificity, f_value,roc_auc \n",
        "    #print(df)\n",
        "\n",
        "    # CSVとして出力\n",
        "    #df2.to_csv(\"/content/drive/My Drive/Grav_bootcamp/Posttrain_model_eval_result.csv\",encoding=\"shift_jis\")\n",
        "    return df\n",
        "\n",
        "def Draw_roc_curve(label_list_list, model_pred_prob_list, sample_num_list, num_curves,class_names):\n",
        "\n",
        "#グラフの外形を作成\n",
        "    fig = plt.figure(figsize=(8.0, 6.0))\n",
        "    lw = 2\n",
        "    plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('Receiver operating characteristic')\n",
        "    ycolor = [\"r\", \"g\", \"b\", \"c\", \"m\", \"y\", \"k\", \"w\"]      # 各プロットの色\n",
        "    plt.legend(loc=\"lower right\")\n",
        "\n",
        "    k=0\n",
        "    for j in range(num_curves):\n",
        "        y_score = []\n",
        "        y_true = []\n",
        "\n",
        "        for i in label_list_list[k]:\n",
        "            if i == class_names[0]:\n",
        "                  y_true.append(0)\n",
        "            elif i == class_names[1]:\n",
        "                  y_true.append(1)\n",
        "            \n",
        "        #それぞれの画像における陽性の確率についてリストを作成\n",
        "        y_score = model_pred_prob_list[k]\n",
        "\n",
        "        fpr, tpr,thred = roc_curve(y_true, y_score)\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "\n",
        "        plt.plot(fpr, tpr, color=ycolor[k],lw=lw, label= str(roc_label_list[k])+':ROC curve (area = %0.2f)' % roc_auc)\n",
        "            \n",
        "        k+=1\n",
        "\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.show()\n",
        "    return fig\n",
        "\n",
        "def calculate_auc(label_list, model_pred_prob, class_names):\n",
        "    y_true, y_score = [], []\n",
        "    for i in label_list:\n",
        "        if i == class_names[0]:\n",
        "              y_true.append(0)\n",
        "        elif i == class_names[1]:\n",
        "              y_true.append(1)\n",
        "            \n",
        "    #それぞれの画像における陽性の確率についてリストを作成\n",
        "    y_score = model_pred_prob\n",
        "\n",
        "    print(y_true)\n",
        "    print(len(y_true))\n",
        "    print(y_score)\n",
        "    print(len(y_score))\n",
        "\n",
        "    fpr, tpr,thred = roc_curve(y_true, y_score)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    print(\"roc_auc: \" +str(roc_auc))\n",
        "    return(roc_auc, y_true, y_score)\n",
        "\n",
        "def calcurate_ave_std(df, fold):\n",
        "    for i in range(5):\n",
        "        df.iloc[i,fold] = df[i,0:5].mean \n",
        "\n",
        "def makefolder(path):\n",
        "    if not os.path.exists(path):  # ディレクトリがなかったら\n",
        "        os.mkdir(path)  # 作成したいフォルダ名を作成\n",
        "\n",
        "def prediction_results_to_df(df, img_path, pred):\n",
        "    for path, pred in zip(img_path, pred):\n",
        "        img_name = os.path.basename(path)\n",
        "        df.loc[df[\"num\"] == img_name, \"prediction\"] = pred\n",
        "\n",
        "def convnet():\n",
        "    model_ft = models.resnet50(pretrained=True)\n",
        "    num_ftrs = model_ft.fc.in_features\n",
        "    model_ft.fc = nn.Linear(num_ftrs, 2)\n",
        "\n",
        "    #GPU使用\n",
        "    model_ft = model_ft.to(device)\n",
        "\n",
        "    #損失関数を定義\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Observe that all parameters are being optimized\n",
        "    #https://blog.knjcode.com/adabound-memo/\n",
        "    #https://pypi.org/project/torch-optimizer/\n",
        "    optimizer_ft = optim.AdaBound(\n",
        "        model_ft.parameters(),\n",
        "        lr= 1e-3,\n",
        "        betas= (0.9, 0.999),\n",
        "        final_lr = 0.1,\n",
        "        gamma=1e-3,\n",
        "        eps= 1e-8,\n",
        "        weight_decay=0,\n",
        "        amsbound=False,\n",
        "    )\n",
        "    return (model_ft, criterion, optimizer_ft)\n",
        "\n",
        "def convnet_VGGFace():\n",
        "   #Pretrained dataと結びつける\n",
        "    model_ft = Resnet50_ft_dag()\n",
        "    model_ft.load_state_dict(torch.load('/content/drive/MyDrive/Deep_learning/resnet50_ft_dag.pth'))\n",
        "    #最終結合層のリセットと付け替え(全結合層を2つに)\n",
        "    #model_ft.classifier = nn.Conv2d(2048, len(class_names), kernel_size=[1,1], stride=(1,1), bias = False)\n",
        "    model_ft.classifier = nn.Linear(2048, 2)\n",
        "    model_ft.classifier = nn.Sequential(*([Flatten()] + list(model_ft.children())[-1:])) #Flattenを挿入\n",
        "\n",
        "\n",
        "    #GPU使用\n",
        "    model_ft = model_ft.to(device)\n",
        "\n",
        "    #損失関数を定義\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Observe that all parameters are being optimized\n",
        "    #https://blog.knjcode.com/adabound-memo/\n",
        "    #https://pypi.org/project/torch-optimizer/\n",
        "    optimizer_ft = optim.AdaBound(\n",
        "        model_ft.parameters(),\n",
        "        lr= 1e-3,\n",
        "        betas= (0.9, 0.999),\n",
        "        final_lr = 0.1,\n",
        "        gamma=1e-3,\n",
        "        eps= 1e-8,\n",
        "        weight_decay=0,\n",
        "        amsbound=False,\n",
        "    )\n",
        "    return (model_ft, criterion, optimizer_ft)\n",
        "        "
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ugZyB_gxU2uX",
        "outputId": "93097df2-81cd-4734-fdc5-92e7cab39c03"
      },
      "source": [
        "#まとめて解析\n",
        "# 出力名を記入\n",
        "out_name = \"ResNet50_VGGFace_all\"\n",
        "csv_path = dst_path + \"/img_list_\"+out_name+\".csv\"\n",
        "\n",
        "#create data_dir_list\n",
        "data_dir = dst_path\n",
        "fold = split_num\n",
        "print(str(fold)+'-fold cross validation')\n",
        "\n",
        "\n",
        "data_dir_list = [0]*fold\n",
        "\n",
        "for i in range(fold):\n",
        "    data_dir_list[i] = data_dir + '/' + str(i)\n",
        "    print(data_dir_list[i])\n",
        "\n",
        "#create roc_label_list\n",
        "roc_label_list = [0]*fold\n",
        "roc_label_list = list(range(fold))\n",
        "#print(roc_label_list)\n",
        "\n",
        "\n",
        "\n",
        "df = make_csv(roc_label_list)\n",
        "\n",
        "label_list_list, model_pred_prob_list, Y_TRUE, Y_SCORE = [],[],[],[]\n",
        "\n",
        "#print(data_dir_list)\n",
        "#print(roc_label_list)\n",
        "\n",
        "for i, t in enumerate(zip(data_dir_list, roc_label_list)):\n",
        "    image_datasets, dataloaders, dataset_sizes, class_names, device = pre_process(t[0]) #path\n",
        "    inputs, classes = getBatch(dataloaders)\n",
        "    #model_ft, criterion, optimizer_ft = convnet()\n",
        "    model_ft, criterion, optimizer_ft = convnet_VGGFace() #VGGFace使用時はこちら\n",
        "    training(model_ft, criterion, optimizer_ft,  patience=30, num_epochs=50)  \n",
        "    torch.save(model_ft.state_dict(), data_dir + '/'+str(out_name)+\"_\"+str(i)+\".pth\")    #ネットワークの保存\n",
        "    TP,TN,FP,FN, accuracy, precision, recall, specificity, f_value, label_list, model_pred_prob, model_pred_class, val_img_path = evaluation(model_ft, data_dir + \"/\" +str(i)+\"/val\")\n",
        "    prediction_results_to_df(df_cross, val_img_path, model_pred_class)\n",
        "    roc_auc, y_true, y_score = calculate_auc(label_list, model_pred_prob, class_names)\n",
        "    Y_TRUE.append(y_true)\n",
        "    Y_SCORE.append(y_score)\n",
        "    df = write_csv(df, i,TP,TN,FP,FN, accuracy, precision, recall, specificity, f_value, roc_auc) #numberをcsvの行として指定\n",
        "\n",
        "    label_list_list.append(label_list)\n",
        "    model_pred_prob_list.append(model_pred_prob)\n",
        "    print(\"\")\n",
        "    print(\"\")\n",
        "\n",
        "#Draw ROC curve\n",
        "fig = Draw_roc_curve(label_list_list, model_pred_prob_list, roc_label_list, len(label_list_list), class_names)\n",
        "\n",
        "pd.set_option('display.max_columns', 100)\n",
        "#それぞれの項目の平均を計算しcsvに追記する\n",
        "df.iloc[0:4,fold], df.iloc[9,fold]   = df.mean(axis=1)[0:4], df.mean(axis=1)[9] \n",
        "df.iloc[0:10,fold+1] = df.std(axis=1)[0:10]\n",
        "TP,TN,FP,FN = df.mean(axis=1)[0:4]\n",
        "df.iloc[4:9,fold] = calculateAccuracy (TP, TN, FP, FN)\n",
        "print(df)\n",
        "\n",
        "# CSVとして出力\n",
        "makefolder(data_dir + \"/crossvalidation_csv\")\n",
        "df.to_csv(data_dir + \"/crossvalidation_csv/\" + out_name + \".csv\",encoding=\"shift_jis\")\n",
        "\n",
        "#ROC_curveを保存\n",
        "makefolder(data_dir + \"/crossvalidation_ROCfigure\")\n",
        "fig.savefig(data_dir + \"/crossvalidation_ROCfigure/\" + out_name +\".png\")\n",
        "\n",
        "\"\"\"\n",
        "#Save ROC data\n",
        "makefolder(data_dir + \"/crossvalidation_ROCdata\")\n",
        "with open(data_dir + \"/crossvalidation_ROCdata/\"+out_name+\".csv\", 'w') as f:\n",
        "    writer = csv.writer(f)\n",
        "    for i, t in enumerate(zip(Y_TRUE, Y_SCORE)):\n",
        "        writer.writerow([t[0],t[1]])\n",
        "\"\"\"\n",
        "\n",
        "#リストCSVを保存\n",
        "df_cross.to_csv(csv_path, encoding='utf_8_sig')"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5-fold cross validation\n",
            "/content/drive/MyDrive/Deep_learning/Strabismus/Dataset_250px_crossvalidation_exo/0\n",
            "/content/drive/MyDrive/Deep_learning/Strabismus/Dataset_250px_crossvalidation_exo/1\n",
            "/content/drive/MyDrive/Deep_learning/Strabismus/Dataset_250px_crossvalidation_exo/2\n",
            "/content/drive/MyDrive/Deep_learning/Strabismus/Dataset_250px_crossvalidation_exo/3\n",
            "/content/drive/MyDrive/Deep_learning/Strabismus/Dataset_250px_crossvalidation_exo/4\n",
            "['cont', 'exo']\n",
            "cont_train:292\n",
            "exo_train:238\n",
            "cont_val:74\n",
            "exo_val:60\n",
            "training data set_total：530\n",
            "validating data set_total：134\n",
            "Epoch 0/49\n",
            "----------\n",
            "train Loss: 1.3301 Acc: 0.6000\n",
            "val Loss: 0.6900 Acc: 0.5522\n",
            "Validation loss decreased (inf --> 0.690014).  Saving model ...\n",
            "\n",
            "Epoch 1/49\n",
            "----------\n",
            "train Loss: 0.6973 Acc: 0.6340\n",
            "val Loss: 0.7213 Acc: 0.5896\n",
            "EarlyStopping counter: 1 out of 30\n",
            "\n",
            "Epoch 2/49\n",
            "----------\n",
            "train Loss: 0.7172 Acc: 0.6075\n",
            "val Loss: 0.7199 Acc: 0.5075\n",
            "EarlyStopping counter: 2 out of 30\n",
            "\n",
            "Epoch 3/49\n",
            "----------\n",
            "train Loss: 0.7062 Acc: 0.6226\n",
            "val Loss: 1.8258 Acc: 0.5373\n",
            "EarlyStopping counter: 3 out of 30\n",
            "\n",
            "Epoch 4/49\n",
            "----------\n",
            "train Loss: 0.6805 Acc: 0.6226\n",
            "val Loss: 0.6981 Acc: 0.5522\n",
            "EarlyStopping counter: 4 out of 30\n",
            "\n",
            "Epoch 5/49\n",
            "----------\n",
            "train Loss: 0.7040 Acc: 0.6377\n",
            "val Loss: 0.6909 Acc: 0.5522\n",
            "EarlyStopping counter: 5 out of 30\n",
            "\n",
            "Epoch 6/49\n",
            "----------\n",
            "train Loss: 0.6581 Acc: 0.6377\n",
            "val Loss: 0.7405 Acc: 0.4328\n",
            "EarlyStopping counter: 6 out of 30\n",
            "\n",
            "Epoch 7/49\n",
            "----------\n",
            "train Loss: 0.6658 Acc: 0.6264\n",
            "val Loss: 0.7039 Acc: 0.5448\n",
            "EarlyStopping counter: 7 out of 30\n",
            "\n",
            "Epoch 8/49\n",
            "----------\n",
            "train Loss: 0.6669 Acc: 0.6604\n",
            "val Loss: 0.7628 Acc: 0.5224\n",
            "EarlyStopping counter: 8 out of 30\n",
            "\n",
            "Epoch 9/49\n",
            "----------\n",
            "train Loss: 0.6429 Acc: 0.6434\n",
            "val Loss: 14.4211 Acc: 0.3881\n",
            "EarlyStopping counter: 9 out of 30\n",
            "\n",
            "Epoch 10/49\n",
            "----------\n",
            "train Loss: 0.6236 Acc: 0.6321\n",
            "val Loss: 1.2268 Acc: 0.4627\n",
            "EarlyStopping counter: 10 out of 30\n",
            "\n",
            "Epoch 11/49\n",
            "----------\n",
            "train Loss: 0.6391 Acc: 0.7208\n",
            "val Loss: 1.9395 Acc: 0.4104\n",
            "EarlyStopping counter: 11 out of 30\n",
            "\n",
            "Epoch 12/49\n",
            "----------\n",
            "train Loss: 0.5527 Acc: 0.7491\n",
            "val Loss: 0.8929 Acc: 0.5149\n",
            "EarlyStopping counter: 12 out of 30\n",
            "\n",
            "Epoch 13/49\n",
            "----------\n",
            "train Loss: 0.5213 Acc: 0.7472\n",
            "val Loss: 0.9489 Acc: 0.6119\n",
            "EarlyStopping counter: 13 out of 30\n",
            "\n",
            "Epoch 14/49\n",
            "----------\n",
            "train Loss: 0.5021 Acc: 0.7660\n",
            "val Loss: 0.8263 Acc: 0.5746\n",
            "EarlyStopping counter: 14 out of 30\n",
            "\n",
            "Epoch 15/49\n",
            "----------\n",
            "train Loss: 0.4400 Acc: 0.8057\n",
            "val Loss: 1.0419 Acc: 0.4701\n",
            "EarlyStopping counter: 15 out of 30\n",
            "\n",
            "Epoch 16/49\n",
            "----------\n",
            "train Loss: 0.5401 Acc: 0.7660\n",
            "val Loss: 0.7714 Acc: 0.5896\n",
            "EarlyStopping counter: 16 out of 30\n",
            "\n",
            "Epoch 17/49\n",
            "----------\n",
            "train Loss: 0.5063 Acc: 0.7472\n",
            "val Loss: 1.0724 Acc: 0.4478\n",
            "EarlyStopping counter: 17 out of 30\n",
            "\n",
            "Epoch 18/49\n",
            "----------\n",
            "train Loss: 0.4321 Acc: 0.8151\n",
            "val Loss: 0.7676 Acc: 0.6716\n",
            "EarlyStopping counter: 18 out of 30\n",
            "\n",
            "Epoch 19/49\n",
            "----------\n",
            "train Loss: 0.4761 Acc: 0.7943\n",
            "val Loss: 0.5313 Acc: 0.7985\n",
            "Validation loss decreased (0.690014 --> 0.531262).  Saving model ...\n",
            "\n",
            "Epoch 20/49\n",
            "----------\n",
            "train Loss: 0.4198 Acc: 0.8189\n",
            "val Loss: 0.7707 Acc: 0.6567\n",
            "EarlyStopping counter: 1 out of 30\n",
            "\n",
            "Epoch 21/49\n",
            "----------\n",
            "train Loss: 0.4365 Acc: 0.8151\n",
            "val Loss: 0.8876 Acc: 0.6866\n",
            "EarlyStopping counter: 2 out of 30\n",
            "\n",
            "Epoch 22/49\n",
            "----------\n",
            "train Loss: 0.3922 Acc: 0.8170\n",
            "val Loss: 0.6773 Acc: 0.5896\n",
            "EarlyStopping counter: 3 out of 30\n",
            "\n",
            "Epoch 23/49\n",
            "----------\n",
            "train Loss: 0.3635 Acc: 0.8377\n",
            "val Loss: 1.8873 Acc: 0.4552\n",
            "EarlyStopping counter: 4 out of 30\n",
            "\n",
            "Epoch 24/49\n",
            "----------\n",
            "train Loss: 0.3663 Acc: 0.8623\n",
            "val Loss: 0.8529 Acc: 0.6791\n",
            "EarlyStopping counter: 5 out of 30\n",
            "\n",
            "Epoch 25/49\n",
            "----------\n",
            "train Loss: 0.3467 Acc: 0.8491\n",
            "val Loss: 0.9271 Acc: 0.5896\n",
            "EarlyStopping counter: 6 out of 30\n",
            "\n",
            "Epoch 26/49\n",
            "----------\n",
            "train Loss: 0.3454 Acc: 0.8604\n",
            "val Loss: 0.6294 Acc: 0.7164\n",
            "EarlyStopping counter: 7 out of 30\n",
            "\n",
            "Epoch 27/49\n",
            "----------\n",
            "train Loss: 0.3713 Acc: 0.8340\n",
            "val Loss: 1.1549 Acc: 0.5970\n",
            "EarlyStopping counter: 8 out of 30\n",
            "\n",
            "Epoch 28/49\n",
            "----------\n",
            "train Loss: 0.3653 Acc: 0.8509\n",
            "val Loss: 0.8337 Acc: 0.5970\n",
            "EarlyStopping counter: 9 out of 30\n",
            "\n",
            "Epoch 29/49\n",
            "----------\n",
            "train Loss: 0.2899 Acc: 0.8774\n",
            "val Loss: 2.1615 Acc: 0.4776\n",
            "EarlyStopping counter: 10 out of 30\n",
            "\n",
            "Epoch 30/49\n",
            "----------\n",
            "train Loss: 0.3343 Acc: 0.8491\n",
            "val Loss: 0.4940 Acc: 0.7836\n",
            "Validation loss decreased (0.531262 --> 0.494044).  Saving model ...\n",
            "\n",
            "Epoch 31/49\n",
            "----------\n",
            "train Loss: 0.2924 Acc: 0.8811\n",
            "val Loss: 0.7658 Acc: 0.6418\n",
            "EarlyStopping counter: 1 out of 30\n",
            "\n",
            "Epoch 32/49\n",
            "----------\n",
            "train Loss: 0.3935 Acc: 0.8528\n",
            "val Loss: 0.6043 Acc: 0.8134\n",
            "EarlyStopping counter: 2 out of 30\n",
            "\n",
            "Epoch 33/49\n",
            "----------\n",
            "train Loss: 0.3087 Acc: 0.8925\n",
            "val Loss: 0.4973 Acc: 0.7761\n",
            "EarlyStopping counter: 3 out of 30\n",
            "\n",
            "Epoch 34/49\n",
            "----------\n",
            "train Loss: 0.2675 Acc: 0.8943\n",
            "val Loss: 1.2977 Acc: 0.6343\n",
            "EarlyStopping counter: 4 out of 30\n",
            "\n",
            "Epoch 35/49\n",
            "----------\n",
            "train Loss: 0.2114 Acc: 0.9094\n",
            "val Loss: 0.6295 Acc: 0.8060\n",
            "EarlyStopping counter: 5 out of 30\n",
            "\n",
            "Epoch 36/49\n",
            "----------\n",
            "train Loss: 0.2653 Acc: 0.8849\n",
            "val Loss: 0.4548 Acc: 0.7985\n",
            "Validation loss decreased (0.494044 --> 0.454767).  Saving model ...\n",
            "\n",
            "Epoch 37/49\n",
            "----------\n",
            "train Loss: 0.2949 Acc: 0.8792\n",
            "val Loss: 1.1852 Acc: 0.6642\n",
            "EarlyStopping counter: 1 out of 30\n",
            "\n",
            "Epoch 38/49\n",
            "----------\n",
            "train Loss: 0.2420 Acc: 0.9094\n",
            "val Loss: 1.2748 Acc: 0.6567\n",
            "EarlyStopping counter: 2 out of 30\n",
            "\n",
            "Epoch 39/49\n",
            "----------\n",
            "train Loss: 0.2225 Acc: 0.9264\n",
            "val Loss: 0.5257 Acc: 0.7836\n",
            "EarlyStopping counter: 3 out of 30\n",
            "\n",
            "Epoch 40/49\n",
            "----------\n",
            "train Loss: 0.2772 Acc: 0.8774\n",
            "val Loss: 0.5906 Acc: 0.7910\n",
            "EarlyStopping counter: 4 out of 30\n",
            "\n",
            "Epoch 41/49\n",
            "----------\n",
            "train Loss: 0.2498 Acc: 0.9151\n",
            "val Loss: 1.5940 Acc: 0.5970\n",
            "EarlyStopping counter: 5 out of 30\n",
            "\n",
            "Epoch 42/49\n",
            "----------\n",
            "train Loss: 0.2045 Acc: 0.9208\n",
            "val Loss: 1.3104 Acc: 0.7090\n",
            "EarlyStopping counter: 6 out of 30\n",
            "\n",
            "Epoch 43/49\n",
            "----------\n",
            "train Loss: 0.2071 Acc: 0.9189\n",
            "val Loss: 0.7176 Acc: 0.8060\n",
            "EarlyStopping counter: 7 out of 30\n",
            "\n",
            "Epoch 44/49\n",
            "----------\n",
            "train Loss: 0.2266 Acc: 0.8981\n",
            "val Loss: 0.7169 Acc: 0.7985\n",
            "EarlyStopping counter: 8 out of 30\n",
            "\n",
            "Epoch 45/49\n",
            "----------\n",
            "train Loss: 0.2315 Acc: 0.9038\n",
            "val Loss: 0.5282 Acc: 0.8060\n",
            "EarlyStopping counter: 9 out of 30\n",
            "\n",
            "Epoch 46/49\n",
            "----------\n",
            "train Loss: 0.1662 Acc: 0.9321\n",
            "val Loss: 1.0706 Acc: 0.7687\n",
            "EarlyStopping counter: 10 out of 30\n",
            "\n",
            "Epoch 47/49\n",
            "----------\n",
            "train Loss: 0.2164 Acc: 0.9226\n",
            "val Loss: 0.4502 Acc: 0.8284\n",
            "Validation loss decreased (0.454767 --> 0.450229).  Saving model ...\n",
            "\n",
            "Epoch 48/49\n",
            "----------\n",
            "train Loss: 0.2057 Acc: 0.9094\n",
            "val Loss: 2.0480 Acc: 0.5896\n",
            "EarlyStopping counter: 1 out of 30\n",
            "\n",
            "Epoch 49/49\n",
            "----------\n",
            "train Loss: 0.2073 Acc: 0.9226\n",
            "val Loss: 0.5041 Acc: 0.7687\n",
            "EarlyStopping counter: 2 out of 30\n",
            "\n",
            "Training complete in 3m 52s\n",
            "Best val Acc: 0.828358\n",
            "number of images: 134\n",
            "48 12 64 10\n",
            "Accuracy: 0.835820895522388\n",
            "Precision (positive predictive value): 0.8275862068965517\n",
            "Recall (sensitivity): 0.8\n",
            "Specificity: 0.8648648648648649\n",
            "F_value: 0.8135593220338982\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "134\n",
            "[0.09562450647354126, 0.02124232053756714, 0.8966132998466492, 0.8050733804702759, 0.10143452882766724, 0.09514439105987549, 0.9405251741409302, 0.42121148109436035, 0.9964524507522583, 0.23655259609222412, 0.04052644968032837, 0.013403356075286865, 0.008701622486114502, 0.00915074348449707, 0.03110182285308838, 0.1055459976196289, 0.0309944748878479, 0.5622888803482056, 0.4532204270362854, 0.06201273202896118, 0.07442587614059448, 0.05480611324310303, 0.05685979127883911, 0.006759285926818848, 0.021713614463806152, 0.3575572371482849, 0.16218209266662598, 0.1201048493385315, 0.04921907186508179, 0.9694892764091492, 0.06212502717971802, 0.0880056619644165, 0.45381325483322144, 0.2058132290840149, 0.24958181381225586, 0.21178442239761353, 0.11568999290466309, 0.029429733753204346, 0.13377821445465088, 0.10507804155349731, 0.042666077613830566, 0.1600250005722046, 0.14081817865371704, 0.05169254541397095, 0.03483623266220093, 0.21101456880569458, 0.04364323616027832, 0.10044920444488525, 0.3785462975502014, 0.0044724345207214355, 0.11373782157897949, 0.030786573886871338, 0.29682642221450806, 0.74073725938797, 0.12486648559570312, 0.027213871479034424, 0.0305708646774292, 0.12361019849777222, 0.07526254653930664, 0.0460088849067688, 0.7638289928436279, 0.12075871229171753, 0.11342000961303711, 0.02305448055267334, 0.02440202236175537, 0.5927718877792358, 0.12502586841583252, 0.11154866218566895, 0.045054733753204346, 0.4593884348869324, 0.9947986602783203, 0.0262642502784729, 0.08794069290161133, 0.028457343578338623, 0.9857708215713501, 0.9718523621559143, 0.908464252948761, 0.7723796367645264, 0.709288477897644, 0.9988299012184143, 0.9511505961418152, 0.39204806089401245, 0.4798995852470398, 0.9500335454940796, 0.15138459205627441, 0.2848391532897949, 0.9997727274894714, 0.9998906850814819, 0.9796456694602966, 0.9988922476768494, 0.8368651270866394, 0.9931058287620544, 0.33659785985946655, 0.8408276438713074, 0.9934367537498474, 0.9686545133590698, 0.09470659494400024, 0.9929913282394409, 0.9452671408653259, 0.2646189332008362, 0.9850812554359436, 0.9940045475959778, 0.9972002506256104, 0.9865603446960449, 0.690048098564148, 0.2673213481903076, 0.9970123767852783, 0.9764381051063538, 0.9900859594345093, 0.9641156196594238, 0.997740626335144, 0.38054120540618896, 0.5198293328285217, 0.761932373046875, 0.9476375579833984, 0.9654443860054016, 0.9940478801727295, 0.8867241144180298, 0.8630639910697937, 0.07502973079681396, 0.9968143105506897, 0.9423511028289795, 0.9248656034469604, 0.9955739974975586, 0.998193085193634, 0.22091567516326904, 0.9995206594467163, 0.11288034915924072, 0.9999860525131226, 0.994115948677063, 0.8950051665306091, 0.9994537234306335, 0.9952815175056458, 0.7703174948692322]\n",
            "134\n",
            "roc_auc: 0.9105855855855856\n",
            "\n",
            "\n",
            "['cont', 'exo']\n",
            "cont_train:293\n",
            "exo_train:238\n",
            "cont_val:73\n",
            "exo_val:60\n",
            "training data set_total：531\n",
            "validating data set_total：133\n",
            "Epoch 0/49\n",
            "----------\n",
            "train Loss: 1.6239 Acc: 0.5217\n",
            "val Loss: 1.3196 Acc: 0.4511\n",
            "Validation loss decreased (inf --> 1.319565).  Saving model ...\n",
            "\n",
            "Epoch 1/49\n",
            "----------\n",
            "train Loss: 0.7429 Acc: 0.5631\n",
            "val Loss: 0.8749 Acc: 0.5489\n",
            "Validation loss decreased (1.319565 --> 0.874860).  Saving model ...\n",
            "\n",
            "Epoch 2/49\n",
            "----------\n",
            "train Loss: 0.7330 Acc: 0.5669\n",
            "val Loss: 0.6968 Acc: 0.5940\n",
            "Validation loss decreased (0.874860 --> 0.696755).  Saving model ...\n",
            "\n",
            "Epoch 3/49\n",
            "----------\n",
            "train Loss: 0.7292 Acc: 0.5913\n",
            "val Loss: 0.8694 Acc: 0.6316\n",
            "EarlyStopping counter: 1 out of 30\n",
            "\n",
            "Epoch 4/49\n",
            "----------\n",
            "train Loss: 0.6968 Acc: 0.5989\n",
            "val Loss: 0.6535 Acc: 0.6466\n",
            "Validation loss decreased (0.696755 --> 0.653546).  Saving model ...\n",
            "\n",
            "Epoch 5/49\n",
            "----------\n",
            "train Loss: 0.6680 Acc: 0.5989\n",
            "val Loss: 0.7188 Acc: 0.5714\n",
            "EarlyStopping counter: 1 out of 30\n",
            "\n",
            "Epoch 6/49\n",
            "----------\n",
            "train Loss: 0.6628 Acc: 0.6196\n",
            "val Loss: 0.6992 Acc: 0.5564\n",
            "EarlyStopping counter: 2 out of 30\n",
            "\n",
            "Epoch 7/49\n",
            "----------\n",
            "train Loss: 0.6508 Acc: 0.6139\n",
            "val Loss: 0.6402 Acc: 0.6541\n",
            "Validation loss decreased (0.653546 --> 0.640160).  Saving model ...\n",
            "\n",
            "Epoch 8/49\n",
            "----------\n",
            "train Loss: 0.6665 Acc: 0.5951\n",
            "val Loss: 0.6838 Acc: 0.5714\n",
            "EarlyStopping counter: 1 out of 30\n",
            "\n",
            "Epoch 9/49\n",
            "----------\n",
            "train Loss: 0.6755 Acc: 0.6290\n",
            "val Loss: 0.6324 Acc: 0.6391\n",
            "Validation loss decreased (0.640160 --> 0.632411).  Saving model ...\n",
            "\n",
            "Epoch 10/49\n",
            "----------\n",
            "train Loss: 0.6555 Acc: 0.6234\n",
            "val Loss: 0.6745 Acc: 0.6316\n",
            "EarlyStopping counter: 1 out of 30\n",
            "\n",
            "Epoch 11/49\n",
            "----------\n",
            "train Loss: 0.6527 Acc: 0.6290\n",
            "val Loss: 0.6689 Acc: 0.6165\n",
            "EarlyStopping counter: 2 out of 30\n",
            "\n",
            "Epoch 12/49\n",
            "----------\n",
            "train Loss: 0.6275 Acc: 0.6422\n",
            "val Loss: 0.6722 Acc: 0.6617\n",
            "EarlyStopping counter: 3 out of 30\n",
            "\n",
            "Epoch 13/49\n",
            "----------\n",
            "train Loss: 0.6164 Acc: 0.6328\n",
            "val Loss: 1.5440 Acc: 0.5714\n",
            "EarlyStopping counter: 4 out of 30\n",
            "\n",
            "Epoch 14/49\n",
            "----------\n",
            "train Loss: 0.5584 Acc: 0.7194\n",
            "val Loss: 0.7331 Acc: 0.7143\n",
            "EarlyStopping counter: 5 out of 30\n",
            "\n",
            "Epoch 15/49\n",
            "----------\n",
            "train Loss: 0.5657 Acc: 0.7194\n",
            "val Loss: 0.8193 Acc: 0.6617\n",
            "EarlyStopping counter: 6 out of 30\n",
            "\n",
            "Epoch 16/49\n",
            "----------\n",
            "train Loss: 0.5204 Acc: 0.7382\n",
            "val Loss: 0.6167 Acc: 0.6692\n",
            "Validation loss decreased (0.632411 --> 0.616696).  Saving model ...\n",
            "\n",
            "Epoch 17/49\n",
            "----------\n",
            "train Loss: 0.5280 Acc: 0.7401\n",
            "val Loss: 0.6487 Acc: 0.6165\n",
            "EarlyStopping counter: 1 out of 30\n",
            "\n",
            "Epoch 18/49\n",
            "----------\n",
            "train Loss: 0.5280 Acc: 0.7476\n",
            "val Loss: 4.1940 Acc: 0.5564\n",
            "EarlyStopping counter: 2 out of 30\n",
            "\n",
            "Epoch 19/49\n",
            "----------\n",
            "train Loss: 0.5378 Acc: 0.7552\n",
            "val Loss: 0.5499 Acc: 0.7293\n",
            "Validation loss decreased (0.616696 --> 0.549852).  Saving model ...\n",
            "\n",
            "Epoch 20/49\n",
            "----------\n",
            "train Loss: 0.4471 Acc: 0.7985\n",
            "val Loss: 0.5207 Acc: 0.7970\n",
            "Validation loss decreased (0.549852 --> 0.520660).  Saving model ...\n",
            "\n",
            "Epoch 21/49\n",
            "----------\n",
            "train Loss: 0.4336 Acc: 0.8023\n",
            "val Loss: 0.5312 Acc: 0.7669\n",
            "EarlyStopping counter: 1 out of 30\n",
            "\n",
            "Epoch 22/49\n",
            "----------\n",
            "train Loss: 0.3854 Acc: 0.8249\n",
            "val Loss: 1.1564 Acc: 0.6090\n",
            "EarlyStopping counter: 2 out of 30\n",
            "\n",
            "Epoch 23/49\n",
            "----------\n",
            "train Loss: 0.3814 Acc: 0.8588\n",
            "val Loss: 2.9682 Acc: 0.5564\n",
            "EarlyStopping counter: 3 out of 30\n",
            "\n",
            "Epoch 24/49\n",
            "----------\n",
            "train Loss: 0.4392 Acc: 0.8079\n",
            "val Loss: 0.6554 Acc: 0.6541\n",
            "EarlyStopping counter: 4 out of 30\n",
            "\n",
            "Epoch 25/49\n",
            "----------\n",
            "train Loss: 0.5548 Acc: 0.7345\n",
            "val Loss: 1.1055 Acc: 0.5714\n",
            "EarlyStopping counter: 5 out of 30\n",
            "\n",
            "Epoch 26/49\n",
            "----------\n",
            "train Loss: 0.6092 Acc: 0.6836\n",
            "val Loss: 0.5485 Acc: 0.7368\n",
            "EarlyStopping counter: 6 out of 30\n",
            "\n",
            "Epoch 27/49\n",
            "----------\n",
            "train Loss: 0.4828 Acc: 0.7740\n",
            "val Loss: 2.1823 Acc: 0.5188\n",
            "EarlyStopping counter: 7 out of 30\n",
            "\n",
            "Epoch 28/49\n",
            "----------\n",
            "train Loss: 0.4031 Acc: 0.8173\n",
            "val Loss: 0.4375 Acc: 0.7970\n",
            "Validation loss decreased (0.520660 --> 0.437468).  Saving model ...\n",
            "\n",
            "Epoch 29/49\n",
            "----------\n",
            "train Loss: 0.3112 Acc: 0.8625\n",
            "val Loss: 0.4213 Acc: 0.8120\n",
            "Validation loss decreased (0.437468 --> 0.421318).  Saving model ...\n",
            "\n",
            "Epoch 30/49\n",
            "----------\n",
            "train Loss: 0.3544 Acc: 0.8343\n",
            "val Loss: 0.3448 Acc: 0.8271\n",
            "Validation loss decreased (0.421318 --> 0.344807).  Saving model ...\n",
            "\n",
            "Epoch 31/49\n",
            "----------\n",
            "train Loss: 0.3241 Acc: 0.8814\n",
            "val Loss: 0.3613 Acc: 0.8346\n",
            "EarlyStopping counter: 1 out of 30\n",
            "\n",
            "Epoch 32/49\n",
            "----------\n",
            "train Loss: 0.3281 Acc: 0.8625\n",
            "val Loss: 0.4822 Acc: 0.8421\n",
            "EarlyStopping counter: 2 out of 30\n",
            "\n",
            "Epoch 33/49\n",
            "----------\n",
            "train Loss: 0.2616 Acc: 0.8945\n",
            "val Loss: 0.2460 Acc: 0.8872\n",
            "Validation loss decreased (0.344807 --> 0.245951).  Saving model ...\n",
            "\n",
            "Epoch 34/49\n",
            "----------\n",
            "train Loss: 0.3137 Acc: 0.8870\n",
            "val Loss: 0.6144 Acc: 0.7368\n",
            "EarlyStopping counter: 1 out of 30\n",
            "\n",
            "Epoch 35/49\n",
            "----------\n",
            "train Loss: 0.3573 Acc: 0.8437\n",
            "val Loss: 0.3206 Acc: 0.8947\n",
            "EarlyStopping counter: 2 out of 30\n",
            "\n",
            "Epoch 36/49\n",
            "----------\n",
            "train Loss: 0.2468 Acc: 0.8927\n",
            "val Loss: 0.2410 Acc: 0.8647\n",
            "Validation loss decreased (0.245951 --> 0.241000).  Saving model ...\n",
            "\n",
            "Epoch 37/49\n",
            "----------\n",
            "train Loss: 0.2215 Acc: 0.9134\n",
            "val Loss: 0.2262 Acc: 0.9173\n",
            "Validation loss decreased (0.241000 --> 0.226151).  Saving model ...\n",
            "\n",
            "Epoch 38/49\n",
            "----------\n",
            "train Loss: 0.2838 Acc: 0.8870\n",
            "val Loss: 0.6338 Acc: 0.7068\n",
            "EarlyStopping counter: 1 out of 30\n",
            "\n",
            "Epoch 39/49\n",
            "----------\n",
            "train Loss: 0.2621 Acc: 0.8870\n",
            "val Loss: 0.2431 Acc: 0.9098\n",
            "EarlyStopping counter: 2 out of 30\n",
            "\n",
            "Epoch 40/49\n",
            "----------\n",
            "train Loss: 0.2892 Acc: 0.8795\n",
            "val Loss: 0.5245 Acc: 0.7744\n",
            "EarlyStopping counter: 3 out of 30\n",
            "\n",
            "Epoch 41/49\n",
            "----------\n",
            "train Loss: 0.1945 Acc: 0.9247\n",
            "val Loss: 0.4448 Acc: 0.7970\n",
            "EarlyStopping counter: 4 out of 30\n",
            "\n",
            "Epoch 42/49\n",
            "----------\n",
            "train Loss: 0.2174 Acc: 0.9228\n",
            "val Loss: 0.1951 Acc: 0.9323\n",
            "Validation loss decreased (0.226151 --> 0.195058).  Saving model ...\n",
            "\n",
            "Epoch 43/49\n",
            "----------\n",
            "train Loss: 0.2246 Acc: 0.9171\n",
            "val Loss: 0.3984 Acc: 0.7970\n",
            "EarlyStopping counter: 1 out of 30\n",
            "\n",
            "Epoch 44/49\n",
            "----------\n",
            "train Loss: 0.2144 Acc: 0.9247\n",
            "val Loss: 0.2631 Acc: 0.9398\n",
            "EarlyStopping counter: 2 out of 30\n",
            "\n",
            "Epoch 45/49\n",
            "----------\n",
            "train Loss: 0.1922 Acc: 0.9341\n",
            "val Loss: 0.2257 Acc: 0.9248\n",
            "EarlyStopping counter: 3 out of 30\n",
            "\n",
            "Epoch 46/49\n",
            "----------\n",
            "train Loss: 0.2527 Acc: 0.8908\n",
            "val Loss: 0.1848 Acc: 0.9323\n",
            "Validation loss decreased (0.195058 --> 0.184813).  Saving model ...\n",
            "\n",
            "Epoch 47/49\n",
            "----------\n",
            "train Loss: 0.1603 Acc: 0.9416\n",
            "val Loss: 0.4159 Acc: 0.8271\n",
            "EarlyStopping counter: 1 out of 30\n",
            "\n",
            "Epoch 48/49\n",
            "----------\n",
            "train Loss: 0.2422 Acc: 0.9040\n",
            "val Loss: 0.2711 Acc: 0.9098\n",
            "EarlyStopping counter: 2 out of 30\n",
            "\n",
            "Epoch 49/49\n",
            "----------\n",
            "train Loss: 0.2003 Acc: 0.9284\n",
            "val Loss: 0.3709 Acc: 0.8421\n",
            "EarlyStopping counter: 3 out of 30\n",
            "\n",
            "Training complete in 3m 55s\n",
            "Best val Acc: 0.939850\n",
            "number of images: 133\n",
            "58 2 58 15\n",
            "Accuracy: 0.8721804511278195\n",
            "Precision (positive predictive value): 0.7945205479452054\n",
            "Recall (sensitivity): 0.9666666666666667\n",
            "Specificity: 0.7945205479452054\n",
            "F_value: 0.8721804511278196\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "133\n",
            "[0.16921454668045044, 0.7175255417823792, 0.39975374937057495, 0.1501152515411377, 0.08982688188552856, 0.15993183851242065, 0.8876959681510925, 0.9851035475730896, 0.4321352243423462, 0.1049303412437439, 0.13705164194107056, 0.5244065523147583, 0.24323010444641113, 0.9971760511398315, 0.21835315227508545, 0.029100120067596436, 0.13836300373077393, 0.5012497901916504, 0.14765077829360962, 0.08447998762130737, 0.027256548404693604, 0.06280505657196045, 0.24397295713424683, 0.9894850850105286, 0.02163219451904297, 0.9557533264160156, 0.059139251708984375, 0.02053689956665039, 0.02303415536880493, 0.26073700189590454, 0.19872307777404785, 0.20580905675888062, 0.016302883625030518, 0.9760085344314575, 0.38293445110321045, 0.1271938681602478, 0.1593259572982788, 0.2585172653198242, 0.032666563987731934, 0.2712227702140808, 0.06599259376525879, 0.00910276174545288, 0.032590627670288086, 0.032590627670288086, 0.586197555065155, 0.0871538519859314, 0.7097827792167664, 0.043080806732177734, 0.03533369302749634, 0.039344191551208496, 0.11207985877990723, 0.08531832695007324, 0.4481603503227234, 0.8371520638465881, 0.06906044483184814, 0.12304991483688354, 0.020550251007080078, 0.415519654750824, 0.038156092166900635, 0.18264585733413696, 0.9967893958091736, 0.998943030834198, 0.03471970558166504, 0.045166015625, 0.10892230272293091, 0.6135528087615967, 0.0290071964263916, 0.01849740743637085, 0.02943253517150879, 0.044315993785858154, 0.44505637884140015, 0.04155784845352173, 0.05042535066604614, 0.9592457413673401, 0.9995124340057373, 0.9986901879310608, 0.9950043559074402, 0.9999532699584961, 0.9998438358306885, 0.9980992674827576, 0.9981708526611328, 0.9849921464920044, 0.9944456815719604, 0.9896407723426819, 0.9912671446800232, 0.9959041476249695, 0.10889911651611328, 0.9998548030853271, 0.990542471408844, 0.9999431371688843, 0.9953268766403198, 0.8255125284194946, 0.9965093731880188, 0.9883993864059448, 0.9965831637382507, 0.8099212646484375, 0.9997965693473816, 0.9998223185539246, 0.9923055768013, 0.9087762236595154, 0.7526929378509521, 0.9991403818130493, 0.9405884742736816, 0.9977501034736633, 0.9878284931182861, 0.9946980476379395, 0.9998948574066162, 0.9952172040939331, 0.9999406337738037, 0.9867522716522217, 0.9994359612464905, 0.9343118667602539, 0.3902396559715271, 0.9990934133529663, 0.5492027997970581, 0.9990027546882629, 0.982755720615387, 0.9996007084846497, 0.9653002619743347, 0.9995456337928772, 0.9944025874137878, 0.9996907711029053, 0.9896544218063354, 0.9982544779777527, 0.9998756647109985, 0.9927970767021179, 0.9998730421066284, 0.9992164373397827, 0.9986211061477661, 0.998547375202179, 0.9994856119155884, 0.9999994039535522, 0.9994027614593506]\n",
            "133\n",
            "roc_auc: 0.9525114155251141\n",
            "\n",
            "\n",
            "['cont', 'exo']\n",
            "cont_train:293\n",
            "exo_train:238\n",
            "cont_val:73\n",
            "exo_val:60\n",
            "training data set_total：531\n",
            "validating data set_total：133\n",
            "Epoch 0/49\n",
            "----------\n",
            "train Loss: 1.5309 Acc: 0.5443\n",
            "val Loss: 0.6940 Acc: 0.4586\n",
            "Validation loss decreased (inf --> 0.693992).  Saving model ...\n",
            "\n",
            "Epoch 1/49\n",
            "----------\n",
            "train Loss: 0.6755 Acc: 0.6930\n",
            "val Loss: 0.6756 Acc: 0.5489\n",
            "Validation loss decreased (0.693992 --> 0.675593).  Saving model ...\n",
            "\n",
            "Epoch 2/49\n",
            "----------\n",
            "train Loss: 0.6344 Acc: 0.6987\n",
            "val Loss: 0.6971 Acc: 0.6165\n",
            "EarlyStopping counter: 1 out of 30\n",
            "\n",
            "Epoch 3/49\n",
            "----------\n",
            "train Loss: 0.5872 Acc: 0.7062\n",
            "val Loss: 0.6619 Acc: 0.6692\n",
            "Validation loss decreased (0.675593 --> 0.661882).  Saving model ...\n",
            "\n",
            "Epoch 4/49\n",
            "----------\n",
            "train Loss: 0.6205 Acc: 0.6573\n",
            "val Loss: 0.6652 Acc: 0.5940\n",
            "EarlyStopping counter: 1 out of 30\n",
            "\n",
            "Epoch 5/49\n",
            "----------\n",
            "train Loss: 0.6258 Acc: 0.6234\n",
            "val Loss: 0.7619 Acc: 0.6692\n",
            "EarlyStopping counter: 2 out of 30\n",
            "\n",
            "Epoch 6/49\n",
            "----------\n",
            "train Loss: 0.5271 Acc: 0.7684\n",
            "val Loss: 0.6477 Acc: 0.7068\n",
            "Validation loss decreased (0.661882 --> 0.647708).  Saving model ...\n",
            "\n",
            "Epoch 7/49\n",
            "----------\n",
            "train Loss: 0.5217 Acc: 0.7778\n",
            "val Loss: 0.6592 Acc: 0.6391\n",
            "EarlyStopping counter: 1 out of 30\n",
            "\n",
            "Epoch 8/49\n",
            "----------\n",
            "train Loss: 0.4643 Acc: 0.7947\n",
            "val Loss: 0.5817 Acc: 0.6391\n",
            "Validation loss decreased (0.647708 --> 0.581694).  Saving model ...\n",
            "\n",
            "Epoch 9/49\n",
            "----------\n",
            "train Loss: 0.3250 Acc: 0.8757\n",
            "val Loss: 0.5480 Acc: 0.7669\n",
            "Validation loss decreased (0.581694 --> 0.547985).  Saving model ...\n",
            "\n",
            "Epoch 10/49\n",
            "----------\n",
            "train Loss: 0.3344 Acc: 0.8682\n",
            "val Loss: 0.4126 Acc: 0.8496\n",
            "Validation loss decreased (0.547985 --> 0.412561).  Saving model ...\n",
            "\n",
            "Epoch 11/49\n",
            "----------\n",
            "train Loss: 0.3908 Acc: 0.8475\n",
            "val Loss: 0.4213 Acc: 0.8271\n",
            "EarlyStopping counter: 1 out of 30\n",
            "\n",
            "Epoch 12/49\n",
            "----------\n",
            "train Loss: 0.3049 Acc: 0.8889\n",
            "val Loss: 1.0258 Acc: 0.5865\n",
            "EarlyStopping counter: 2 out of 30\n",
            "\n",
            "Epoch 13/49\n",
            "----------\n",
            "train Loss: 0.2593 Acc: 0.9002\n",
            "val Loss: 0.2535 Acc: 0.9023\n",
            "Validation loss decreased (0.412561 --> 0.253541).  Saving model ...\n",
            "\n",
            "Epoch 14/49\n",
            "----------\n",
            "train Loss: 0.2998 Acc: 0.8889\n",
            "val Loss: 0.7579 Acc: 0.7068\n",
            "EarlyStopping counter: 1 out of 30\n",
            "\n",
            "Epoch 15/49\n",
            "----------\n",
            "train Loss: 0.2733 Acc: 0.9134\n",
            "val Loss: 0.2764 Acc: 0.9173\n",
            "EarlyStopping counter: 2 out of 30\n",
            "\n",
            "Epoch 16/49\n",
            "----------\n",
            "train Loss: 0.1987 Acc: 0.9190\n",
            "val Loss: 0.3957 Acc: 0.8421\n",
            "EarlyStopping counter: 3 out of 30\n",
            "\n",
            "Epoch 17/49\n",
            "----------\n",
            "train Loss: 0.1838 Acc: 0.9473\n",
            "val Loss: 0.2021 Acc: 0.9098\n",
            "Validation loss decreased (0.253541 --> 0.202146).  Saving model ...\n",
            "\n",
            "Epoch 18/49\n",
            "----------\n",
            "train Loss: 0.2163 Acc: 0.9247\n",
            "val Loss: 0.2411 Acc: 0.8947\n",
            "EarlyStopping counter: 1 out of 30\n",
            "\n",
            "Epoch 19/49\n",
            "----------\n",
            "train Loss: 0.2067 Acc: 0.9190\n",
            "val Loss: 0.2021 Acc: 0.9248\n",
            "Validation loss decreased (0.202146 --> 0.202063).  Saving model ...\n",
            "\n",
            "Epoch 20/49\n",
            "----------\n",
            "train Loss: 0.2019 Acc: 0.9284\n",
            "val Loss: 0.4112 Acc: 0.8647\n",
            "EarlyStopping counter: 1 out of 30\n",
            "\n",
            "Epoch 21/49\n",
            "----------\n",
            "train Loss: 0.1792 Acc: 0.9341\n",
            "val Loss: 0.1511 Acc: 0.9398\n",
            "Validation loss decreased (0.202063 --> 0.151113).  Saving model ...\n",
            "\n",
            "Epoch 22/49\n",
            "----------\n",
            "train Loss: 0.1043 Acc: 0.9623\n",
            "val Loss: 0.1735 Acc: 0.9173\n",
            "EarlyStopping counter: 1 out of 30\n",
            "\n",
            "Epoch 23/49\n",
            "----------\n",
            "train Loss: 0.1994 Acc: 0.9284\n",
            "val Loss: 1.0961 Acc: 0.5489\n",
            "EarlyStopping counter: 2 out of 30\n",
            "\n",
            "Epoch 24/49\n",
            "----------\n",
            "train Loss: 0.1674 Acc: 0.9341\n",
            "val Loss: 0.2185 Acc: 0.9248\n",
            "EarlyStopping counter: 3 out of 30\n",
            "\n",
            "Epoch 25/49\n",
            "----------\n",
            "train Loss: 0.1530 Acc: 0.9360\n",
            "val Loss: 0.2130 Acc: 0.9098\n",
            "EarlyStopping counter: 4 out of 30\n",
            "\n",
            "Epoch 26/49\n",
            "----------\n",
            "train Loss: 0.1333 Acc: 0.9510\n",
            "val Loss: 0.1868 Acc: 0.9248\n",
            "EarlyStopping counter: 5 out of 30\n",
            "\n",
            "Epoch 27/49\n",
            "----------\n",
            "train Loss: 0.1475 Acc: 0.9548\n",
            "val Loss: 0.1606 Acc: 0.9549\n",
            "EarlyStopping counter: 6 out of 30\n",
            "\n",
            "Epoch 28/49\n",
            "----------\n",
            "train Loss: 0.1695 Acc: 0.9379\n",
            "val Loss: 0.2307 Acc: 0.9323\n",
            "EarlyStopping counter: 7 out of 30\n",
            "\n",
            "Epoch 29/49\n",
            "----------\n",
            "train Loss: 0.1551 Acc: 0.9473\n",
            "val Loss: 0.1787 Acc: 0.9474\n",
            "EarlyStopping counter: 8 out of 30\n",
            "\n",
            "Epoch 30/49\n",
            "----------\n",
            "train Loss: 0.1325 Acc: 0.9473\n",
            "val Loss: 0.3115 Acc: 0.8872\n",
            "EarlyStopping counter: 9 out of 30\n",
            "\n",
            "Epoch 31/49\n",
            "----------\n",
            "train Loss: 0.1404 Acc: 0.9473\n",
            "val Loss: 0.4019 Acc: 0.8045\n",
            "EarlyStopping counter: 10 out of 30\n",
            "\n",
            "Epoch 32/49\n",
            "----------\n",
            "train Loss: 0.1422 Acc: 0.9586\n",
            "val Loss: 0.2589 Acc: 0.9248\n",
            "EarlyStopping counter: 11 out of 30\n",
            "\n",
            "Epoch 33/49\n",
            "----------\n",
            "train Loss: 0.0755 Acc: 0.9774\n",
            "val Loss: 0.2898 Acc: 0.9173\n",
            "EarlyStopping counter: 12 out of 30\n",
            "\n",
            "Epoch 34/49\n",
            "----------\n",
            "train Loss: 0.1835 Acc: 0.9360\n",
            "val Loss: 0.3135 Acc: 0.8722\n",
            "EarlyStopping counter: 13 out of 30\n",
            "\n",
            "Epoch 35/49\n",
            "----------\n",
            "train Loss: 0.1573 Acc: 0.9416\n",
            "val Loss: 0.2737 Acc: 0.9173\n",
            "EarlyStopping counter: 14 out of 30\n",
            "\n",
            "Epoch 36/49\n",
            "----------\n",
            "train Loss: 0.1126 Acc: 0.9510\n",
            "val Loss: 0.1808 Acc: 0.9323\n",
            "EarlyStopping counter: 15 out of 30\n",
            "\n",
            "Epoch 37/49\n",
            "----------\n",
            "train Loss: 0.1195 Acc: 0.9586\n",
            "val Loss: 0.2641 Acc: 0.8872\n",
            "EarlyStopping counter: 16 out of 30\n",
            "\n",
            "Epoch 38/49\n",
            "----------\n",
            "train Loss: 0.1103 Acc: 0.9699\n",
            "val Loss: 0.2317 Acc: 0.9173\n",
            "EarlyStopping counter: 17 out of 30\n",
            "\n",
            "Epoch 39/49\n",
            "----------\n",
            "train Loss: 0.0889 Acc: 0.9793\n",
            "val Loss: 0.2622 Acc: 0.9248\n",
            "EarlyStopping counter: 18 out of 30\n",
            "\n",
            "Epoch 40/49\n",
            "----------\n",
            "train Loss: 0.1604 Acc: 0.9322\n",
            "val Loss: 0.6876 Acc: 0.7293\n",
            "EarlyStopping counter: 19 out of 30\n",
            "\n",
            "Epoch 41/49\n",
            "----------\n",
            "train Loss: 0.1782 Acc: 0.9435\n",
            "val Loss: 0.2655 Acc: 0.9098\n",
            "EarlyStopping counter: 20 out of 30\n",
            "\n",
            "Epoch 42/49\n",
            "----------\n",
            "train Loss: 0.0870 Acc: 0.9661\n",
            "val Loss: 0.3939 Acc: 0.8722\n",
            "EarlyStopping counter: 21 out of 30\n",
            "\n",
            "Epoch 43/49\n",
            "----------\n",
            "train Loss: 0.1179 Acc: 0.9492\n",
            "val Loss: 0.2854 Acc: 0.8872\n",
            "EarlyStopping counter: 22 out of 30\n",
            "\n",
            "Epoch 44/49\n",
            "----------\n",
            "train Loss: 0.1095 Acc: 0.9586\n",
            "val Loss: 0.1801 Acc: 0.9323\n",
            "EarlyStopping counter: 23 out of 30\n",
            "\n",
            "Epoch 45/49\n",
            "----------\n",
            "train Loss: 0.0994 Acc: 0.9623\n",
            "val Loss: 0.2034 Acc: 0.9248\n",
            "EarlyStopping counter: 24 out of 30\n",
            "\n",
            "Epoch 46/49\n",
            "----------\n",
            "train Loss: 0.1098 Acc: 0.9567\n",
            "val Loss: 0.1988 Acc: 0.9173\n",
            "EarlyStopping counter: 25 out of 30\n",
            "\n",
            "Epoch 47/49\n",
            "----------\n",
            "train Loss: 0.1653 Acc: 0.9360\n",
            "val Loss: 0.3955 Acc: 0.8271\n",
            "EarlyStopping counter: 26 out of 30\n",
            "\n",
            "Epoch 48/49\n",
            "----------\n",
            "train Loss: 0.1045 Acc: 0.9661\n",
            "val Loss: 0.1875 Acc: 0.9248\n",
            "EarlyStopping counter: 27 out of 30\n",
            "\n",
            "Epoch 49/49\n",
            "----------\n",
            "train Loss: 0.0850 Acc: 0.9718\n",
            "val Loss: 0.1441 Acc: 0.9549\n",
            "Validation loss decreased (0.151113 --> 0.144129).  Saving model ...\n",
            "\n",
            "Training complete in 3m 55s\n",
            "Best val Acc: 0.954887\n",
            "number of images: 133\n",
            "58 2 68 5\n",
            "Accuracy: 0.9473684210526315\n",
            "Precision (positive predictive value): 0.9206349206349206\n",
            "Recall (sensitivity): 0.9666666666666667\n",
            "Specificity: 0.9315068493150684\n",
            "F_value: 0.943089430894309\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "133\n",
            "[0.14493811130523682, 0.8328308463096619, 0.0249100923538208, 0.13550984859466553, 0.0072182416915893555, 0.018418550491333008, 0.012961089611053467, 0.17337816953659058, 0.003543078899383545, 0.011268317699432373, 0.07759171724319458, 0.031374573707580566, 0.023285388946533203, 0.07334524393081665, 0.011760473251342773, 0.005317509174346924, 0.03495824337005615, 0.013161957263946533, 0.0728445053100586, 0.04054027795791626, 0.00930112600326538, 0.1881614327430725, 0.001536726951599121, 0.009552359580993652, 0.0048789381980896, 0.028432846069335938, 0.3581337332725525, 0.9900267124176025, 0.058152616024017334, 0.9933174848556519, 0.06355249881744385, 0.9304566383361816, 0.015348315238952637, 0.0033625364303588867, 0.010644376277923584, 0.5414133071899414, 0.006116747856140137, 0.14132291078567505, 0.03583008050918579, 0.06112140417098999, 0.0021588802337646484, 0.06858247518539429, 0.016626477241516113, 0.0025582313537597656, 0.30076152086257935, 0.34939372539520264, 0.008059024810791016, 0.3105979561805725, 0.2803195118904114, 0.4268990159034729, 0.04280674457550049, 0.012337327003479004, 0.002519547939300537, 0.03616905212402344, 0.19831311702728271, 0.04112285375595093, 0.4437054991722107, 0.054997801780700684, 0.061370909214019775, 0.00045102834701538086, 0.0315815806388855, 0.037757039070129395, 0.01662808656692505, 0.37432438135147095, 0.26138734817504883, 0.014375925064086914, 0.22644883394241333, 0.33165252208709717, 0.014556884765625, 0.025436818599700928, 0.021226823329925537, 0.25527721643447876, 0.05594313144683838, 0.9990817308425903, 0.9968550205230713, 0.7459399700164795, 0.9988644123077393, 0.9997043013572693, 0.9987962245941162, 0.9980048537254333, 0.992988646030426, 0.9997254014015198, 0.9928925037384033, 0.9794536232948303, 0.996665894985199, 0.9987589120864868, 0.9986506104469299, 0.6848284006118774, 0.9024744033813477, 0.901738703250885, 0.9998849630355835, 0.987643837928772, 0.9997484087944031, 0.9891029596328735, 0.9983043670654297, 0.9992732405662537, 0.4934040307998657, 0.9999927282333374, 0.9955651164054871, 0.8585507869720459, 0.5755437016487122, 0.9955586194992065, 0.9985938668251038, 0.9990309476852417, 0.9988460540771484, 0.9986207485198975, 0.9155413508415222, 0.8184671998023987, 0.9986943602561951, 0.9982578158378601, 0.998778760433197, 0.9999167919158936, 0.16512805223464966, 0.8481338620185852, 0.9327345490455627, 0.9993821382522583, 0.9991920590400696, 0.9856659770011902, 0.753844141960144, 0.9979148507118225, 0.999954104423523, 0.9990932941436768, 0.9999934434890747, 0.999018669128418, 0.9999921321868896, 0.9984809756278992, 0.9979922771453857, 0.9938098788261414, 0.9981405735015869, 0.9992320537567139, 0.9995802044868469, 0.9999910593032837, 0.9970920085906982]\n",
            "133\n",
            "roc_auc: 0.9835616438356164\n",
            "\n",
            "\n",
            "['cont', 'exo']\n",
            "cont_train:293\n",
            "exo_train:239\n",
            "cont_val:73\n",
            "exo_val:59\n",
            "training data set_total：532\n",
            "validating data set_total：132\n",
            "Epoch 0/49\n",
            "----------\n",
            "train Loss: 1.2801 Acc: 0.5338\n",
            "val Loss: 5.3320 Acc: 0.4470\n",
            "Validation loss decreased (inf --> 5.332023).  Saving model ...\n",
            "\n",
            "Epoch 1/49\n",
            "----------\n",
            "train Loss: 0.7764 Acc: 0.5094\n",
            "val Loss: 0.6955 Acc: 0.3939\n",
            "Validation loss decreased (5.332023 --> 0.695512).  Saving model ...\n",
            "\n",
            "Epoch 2/49\n",
            "----------\n",
            "train Loss: 0.7360 Acc: 0.5150\n",
            "val Loss: 0.6910 Acc: 0.5152\n",
            "Validation loss decreased (0.695512 --> 0.690953).  Saving model ...\n",
            "\n",
            "Epoch 3/49\n",
            "----------\n",
            "train Loss: 0.7648 Acc: 0.5733\n",
            "val Loss: 0.6773 Acc: 0.6288\n",
            "Validation loss decreased (0.690953 --> 0.677269).  Saving model ...\n",
            "\n",
            "Epoch 4/49\n",
            "----------\n",
            "train Loss: 0.7448 Acc: 0.5827\n",
            "val Loss: 0.6729 Acc: 0.5530\n",
            "Validation loss decreased (0.677269 --> 0.672920).  Saving model ...\n",
            "\n",
            "Epoch 5/49\n",
            "----------\n",
            "train Loss: 0.7744 Acc: 0.5301\n",
            "val Loss: 0.6797 Acc: 0.5530\n",
            "EarlyStopping counter: 1 out of 30\n",
            "\n",
            "Epoch 6/49\n",
            "----------\n",
            "train Loss: 0.7093 Acc: 0.5545\n",
            "val Loss: 0.8685 Acc: 0.4470\n",
            "EarlyStopping counter: 2 out of 30\n",
            "\n",
            "Epoch 7/49\n",
            "----------\n",
            "train Loss: 0.6907 Acc: 0.5789\n",
            "val Loss: 0.6976 Acc: 0.4394\n",
            "EarlyStopping counter: 3 out of 30\n",
            "\n",
            "Epoch 8/49\n",
            "----------\n",
            "train Loss: 0.6759 Acc: 0.6147\n",
            "val Loss: 0.9246 Acc: 0.6061\n",
            "EarlyStopping counter: 4 out of 30\n",
            "\n",
            "Epoch 9/49\n",
            "----------\n",
            "train Loss: 0.6522 Acc: 0.6015\n",
            "val Loss: 1.1067 Acc: 0.6061\n",
            "EarlyStopping counter: 5 out of 30\n",
            "\n",
            "Epoch 10/49\n",
            "----------\n",
            "train Loss: 0.6521 Acc: 0.5996\n",
            "val Loss: 0.6734 Acc: 0.6439\n",
            "EarlyStopping counter: 6 out of 30\n",
            "\n",
            "Epoch 11/49\n",
            "----------\n",
            "train Loss: 0.6579 Acc: 0.5959\n",
            "val Loss: 0.6534 Acc: 0.5076\n",
            "Validation loss decreased (0.672920 --> 0.653404).  Saving model ...\n",
            "\n",
            "Epoch 12/49\n",
            "----------\n",
            "train Loss: 0.6440 Acc: 0.6053\n",
            "val Loss: 0.6339 Acc: 0.6212\n",
            "Validation loss decreased (0.653404 --> 0.633943).  Saving model ...\n",
            "\n",
            "Epoch 13/49\n",
            "----------\n",
            "train Loss: 0.6267 Acc: 0.6353\n",
            "val Loss: 0.7338 Acc: 0.5530\n",
            "EarlyStopping counter: 1 out of 30\n",
            "\n",
            "Epoch 14/49\n",
            "----------\n",
            "train Loss: 0.6086 Acc: 0.6541\n",
            "val Loss: 0.7135 Acc: 0.5530\n",
            "EarlyStopping counter: 2 out of 30\n",
            "\n",
            "Epoch 15/49\n",
            "----------\n",
            "train Loss: 0.5954 Acc: 0.7049\n",
            "val Loss: 0.5713 Acc: 0.7500\n",
            "Validation loss decreased (0.633943 --> 0.571292).  Saving model ...\n",
            "\n",
            "Epoch 16/49\n",
            "----------\n",
            "train Loss: 0.5269 Acc: 0.7556\n",
            "val Loss: 0.6021 Acc: 0.6970\n",
            "EarlyStopping counter: 1 out of 30\n",
            "\n",
            "Epoch 17/49\n",
            "----------\n",
            "train Loss: 0.5737 Acc: 0.7218\n",
            "val Loss: 0.7598 Acc: 0.6515\n",
            "EarlyStopping counter: 2 out of 30\n",
            "\n",
            "Epoch 18/49\n",
            "----------\n",
            "train Loss: 0.4892 Acc: 0.7462\n",
            "val Loss: 1.3211 Acc: 0.4697\n",
            "EarlyStopping counter: 3 out of 30\n",
            "\n",
            "Epoch 19/49\n",
            "----------\n",
            "train Loss: 0.5030 Acc: 0.7688\n",
            "val Loss: 0.7444 Acc: 0.5606\n",
            "EarlyStopping counter: 4 out of 30\n",
            "\n",
            "Epoch 20/49\n",
            "----------\n",
            "train Loss: 0.5200 Acc: 0.7462\n",
            "val Loss: 0.5627 Acc: 0.7273\n",
            "Validation loss decreased (0.571292 --> 0.562695).  Saving model ...\n",
            "\n",
            "Epoch 21/49\n",
            "----------\n",
            "train Loss: 0.4799 Acc: 0.7857\n",
            "val Loss: 0.3975 Acc: 0.8409\n",
            "Validation loss decreased (0.562695 --> 0.397510).  Saving model ...\n",
            "\n",
            "Epoch 22/49\n",
            "----------\n",
            "train Loss: 0.4416 Acc: 0.8233\n",
            "val Loss: 0.6255 Acc: 0.7727\n",
            "EarlyStopping counter: 1 out of 30\n",
            "\n",
            "Epoch 23/49\n",
            "----------\n",
            "train Loss: 0.4522 Acc: 0.7744\n",
            "val Loss: 0.4700 Acc: 0.7500\n",
            "EarlyStopping counter: 2 out of 30\n",
            "\n",
            "Epoch 24/49\n",
            "----------\n",
            "train Loss: 0.4358 Acc: 0.8102\n",
            "val Loss: 0.7397 Acc: 0.5606\n",
            "EarlyStopping counter: 3 out of 30\n",
            "\n",
            "Epoch 25/49\n",
            "----------\n",
            "train Loss: 0.4287 Acc: 0.8158\n",
            "val Loss: 0.4302 Acc: 0.8106\n",
            "EarlyStopping counter: 4 out of 30\n",
            "\n",
            "Epoch 26/49\n",
            "----------\n",
            "train Loss: 0.3621 Acc: 0.8609\n",
            "val Loss: 1.3842 Acc: 0.5682\n",
            "EarlyStopping counter: 5 out of 30\n",
            "\n",
            "Epoch 27/49\n",
            "----------\n",
            "train Loss: 0.4321 Acc: 0.7951\n",
            "val Loss: 0.4192 Acc: 0.8182\n",
            "EarlyStopping counter: 6 out of 30\n",
            "\n",
            "Epoch 28/49\n",
            "----------\n",
            "train Loss: 0.3769 Acc: 0.8383\n",
            "val Loss: 0.3933 Acc: 0.8182\n",
            "Validation loss decreased (0.397510 --> 0.393322).  Saving model ...\n",
            "\n",
            "Epoch 29/49\n",
            "----------\n",
            "train Loss: 0.3188 Acc: 0.8609\n",
            "val Loss: 0.7619 Acc: 0.7273\n",
            "EarlyStopping counter: 1 out of 30\n",
            "\n",
            "Epoch 30/49\n",
            "----------\n",
            "train Loss: 0.3494 Acc: 0.8609\n",
            "val Loss: 0.4515 Acc: 0.8030\n",
            "EarlyStopping counter: 2 out of 30\n",
            "\n",
            "Epoch 31/49\n",
            "----------\n",
            "train Loss: 0.3556 Acc: 0.8477\n",
            "val Loss: 0.4916 Acc: 0.7803\n",
            "EarlyStopping counter: 3 out of 30\n",
            "\n",
            "Epoch 32/49\n",
            "----------\n",
            "train Loss: 0.2929 Acc: 0.8910\n",
            "val Loss: 0.3090 Acc: 0.8788\n",
            "Validation loss decreased (0.393322 --> 0.309033).  Saving model ...\n",
            "\n",
            "Epoch 33/49\n",
            "----------\n",
            "train Loss: 0.3145 Acc: 0.8684\n",
            "val Loss: 0.3397 Acc: 0.8409\n",
            "EarlyStopping counter: 1 out of 30\n",
            "\n",
            "Epoch 34/49\n",
            "----------\n",
            "train Loss: 0.2742 Acc: 0.8853\n",
            "val Loss: 0.5203 Acc: 0.8485\n",
            "EarlyStopping counter: 2 out of 30\n",
            "\n",
            "Epoch 35/49\n",
            "----------\n",
            "train Loss: 0.3428 Acc: 0.8609\n",
            "val Loss: 1.1512 Acc: 0.6136\n",
            "EarlyStopping counter: 3 out of 30\n",
            "\n",
            "Epoch 36/49\n",
            "----------\n",
            "train Loss: 0.2903 Acc: 0.8778\n",
            "val Loss: 0.4640 Acc: 0.8485\n",
            "EarlyStopping counter: 4 out of 30\n",
            "\n",
            "Epoch 37/49\n",
            "----------\n",
            "train Loss: 0.2236 Acc: 0.9023\n",
            "val Loss: 0.3622 Acc: 0.8485\n",
            "EarlyStopping counter: 5 out of 30\n",
            "\n",
            "Epoch 38/49\n",
            "----------\n",
            "train Loss: 0.2286 Acc: 0.9041\n",
            "val Loss: 0.2515 Acc: 0.8864\n",
            "Validation loss decreased (0.309033 --> 0.251459).  Saving model ...\n",
            "\n",
            "Epoch 39/49\n",
            "----------\n",
            "train Loss: 0.2488 Acc: 0.8853\n",
            "val Loss: 0.4917 Acc: 0.8485\n",
            "EarlyStopping counter: 1 out of 30\n",
            "\n",
            "Epoch 40/49\n",
            "----------\n",
            "train Loss: 0.2620 Acc: 0.8910\n",
            "val Loss: 0.2985 Acc: 0.8788\n",
            "EarlyStopping counter: 2 out of 30\n",
            "\n",
            "Epoch 41/49\n",
            "----------\n",
            "train Loss: 0.2058 Acc: 0.9211\n",
            "val Loss: 0.3256 Acc: 0.8636\n",
            "EarlyStopping counter: 3 out of 30\n",
            "\n",
            "Epoch 42/49\n",
            "----------\n",
            "train Loss: 0.2321 Acc: 0.9023\n",
            "val Loss: 0.2375 Acc: 0.8788\n",
            "Validation loss decreased (0.251459 --> 0.237471).  Saving model ...\n",
            "\n",
            "Epoch 43/49\n",
            "----------\n",
            "train Loss: 0.2118 Acc: 0.9098\n",
            "val Loss: 0.2280 Acc: 0.9091\n",
            "Validation loss decreased (0.237471 --> 0.228048).  Saving model ...\n",
            "\n",
            "Epoch 44/49\n",
            "----------\n",
            "train Loss: 0.2123 Acc: 0.9173\n",
            "val Loss: 0.2498 Acc: 0.8864\n",
            "EarlyStopping counter: 1 out of 30\n",
            "\n",
            "Epoch 45/49\n",
            "----------\n",
            "train Loss: 0.1924 Acc: 0.9305\n",
            "val Loss: 0.2481 Acc: 0.8939\n",
            "EarlyStopping counter: 2 out of 30\n",
            "\n",
            "Epoch 46/49\n",
            "----------\n",
            "train Loss: 0.1860 Acc: 0.9342\n",
            "val Loss: 0.2715 Acc: 0.8864\n",
            "EarlyStopping counter: 3 out of 30\n",
            "\n",
            "Epoch 47/49\n",
            "----------\n",
            "train Loss: 0.2033 Acc: 0.9173\n",
            "val Loss: 0.3268 Acc: 0.8485\n",
            "EarlyStopping counter: 4 out of 30\n",
            "\n",
            "Epoch 48/49\n",
            "----------\n",
            "train Loss: 0.1478 Acc: 0.9361\n",
            "val Loss: 0.3256 Acc: 0.8939\n",
            "EarlyStopping counter: 5 out of 30\n",
            "\n",
            "Epoch 49/49\n",
            "----------\n",
            "train Loss: 0.1480 Acc: 0.9380\n",
            "val Loss: 0.4026 Acc: 0.8636\n",
            "EarlyStopping counter: 6 out of 30\n",
            "\n",
            "Training complete in 3m 56s\n",
            "Best val Acc: 0.909091\n",
            "number of images: 132\n",
            "50 9 69 4\n",
            "Accuracy: 0.9015151515151515\n",
            "Precision (positive predictive value): 0.9259259259259259\n",
            "Recall (sensitivity): 0.847457627118644\n",
            "Specificity: 0.9452054794520548\n",
            "F_value: 0.8849557522123893\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "132\n",
            "[0.0037857890129089355, 0.008049607276916504, 0.160350501537323, 0.028181612491607666, 0.02046149969100952, 0.005658149719238281, 0.0921320915222168, 0.014918088912963867, 0.17577844858169556, 0.05640476942062378, 0.05278778076171875, 0.06342625617980957, 0.7545036673545837, 0.026488900184631348, 0.5903469324111938, 0.17111992835998535, 0.1481637954711914, 0.021474897861480713, 0.05848485231399536, 0.9380134344100952, 0.0142899751663208, 0.034969449043273926, 0.36682456731796265, 0.0168304443359375, 0.37092703580856323, 0.004065513610839844, 0.0077201128005981445, 0.006078600883483887, 0.017613649368286133, 0.12817567586898804, 0.019145846366882324, 0.04501080513000488, 0.030187785625457764, 0.30700814723968506, 0.013696014881134033, 0.15218621492385864, 0.004774212837219238, 0.01425480842590332, 0.12577104568481445, 0.006503105163574219, 0.030897200107574463, 0.014666974544525146, 0.07046180963516235, 0.01130831241607666, 0.004934728145599365, 0.010661721229553223, 0.01651298999786377, 0.059524595737457275, 0.013241231441497803, 0.021885216236114502, 0.0223543643951416, 0.008265972137451172, 0.9651886224746704, 0.19748055934906006, 0.15150099992752075, 0.02000504732131958, 0.07418966293334961, 0.1398305892944336, 0.013349294662475586, 0.017021596431732178, 0.0006133317947387695, 0.002825498580932617, 0.0030750632286071777, 0.016556620597839355, 0.02139759063720703, 0.12387305498123169, 0.0017518997192382812, 0.028860390186309814, 0.1680188775062561, 0.2524021863937378, 0.0037420988082885742, 0.46945613622665405, 0.0019887685775756836, 0.9961336851119995, 0.9977529644966125, 0.8886090517044067, 0.9988858103752136, 0.9362224340438843, 0.9713854789733887, 0.37385034561157227, 0.9862368106842041, 0.9986423850059509, 0.99983811378479, 0.9998630285263062, 0.9826518297195435, 0.9940980672836304, 0.9988405108451843, 0.9990567564964294, 0.9966716766357422, 0.5553377866744995, 0.9942883253097534, 0.8985572457313538, 0.13647246360778809, 0.12457478046417236, 0.9999654293060303, 0.8903979063034058, 0.9998027682304382, 0.7474061250686646, 0.21885037422180176, 0.9987302422523499, 0.7475131750106812, 0.9819869995117188, 0.5233266353607178, 0.26388782262802124, 0.9953685998916626, 0.9937451481819153, 0.9567546844482422, 0.9615083932876587, 0.3341463804244995, 0.9978206157684326, 0.20829325914382935, 0.03584027290344238, 0.993118166923523, 0.969449520111084, 0.9939541220664978, 0.9680148959159851, 0.9999257326126099, 0.9581144452095032, 0.974513828754425, 0.9999923706054688, 0.6964843273162842, 0.10996919870376587, 0.9997705817222595, 0.9930210709571838, 0.9994431138038635, 0.9992223978042603, 0.8092986345291138, 0.9990129470825195, 0.9994660019874573, 0.9991976618766785, 0.9938803911209106, 0.9563886523246765]\n",
            "132\n",
            "roc_auc: 0.9633155328534944\n",
            "\n",
            "\n",
            "['cont', 'exo']\n",
            "cont_train:293\n",
            "exo_train:239\n",
            "cont_val:73\n",
            "exo_val:59\n",
            "training data set_total：532\n",
            "validating data set_total：132\n",
            "Epoch 0/49\n",
            "----------\n",
            "train Loss: 1.2939 Acc: 0.5883\n",
            "val Loss: 0.8085 Acc: 0.5530\n",
            "Validation loss decreased (inf --> 0.808527).  Saving model ...\n",
            "\n",
            "Epoch 1/49\n",
            "----------\n",
            "train Loss: 0.6323 Acc: 0.7180\n",
            "val Loss: 1.5276 Acc: 0.4697\n",
            "EarlyStopping counter: 1 out of 30\n",
            "\n",
            "Epoch 2/49\n",
            "----------\n",
            "train Loss: 0.4698 Acc: 0.7932\n",
            "val Loss: 4.9775 Acc: 0.5227\n",
            "EarlyStopping counter: 2 out of 30\n",
            "\n",
            "Epoch 3/49\n",
            "----------\n",
            "train Loss: 0.3678 Acc: 0.8703\n",
            "val Loss: 0.6287 Acc: 0.8030\n",
            "Validation loss decreased (0.808527 --> 0.628660).  Saving model ...\n",
            "\n",
            "Epoch 4/49\n",
            "----------\n",
            "train Loss: 0.3069 Acc: 0.9060\n",
            "val Loss: 0.3948 Acc: 0.8182\n",
            "Validation loss decreased (0.628660 --> 0.394754).  Saving model ...\n",
            "\n",
            "Epoch 5/49\n",
            "----------\n",
            "train Loss: 0.2983 Acc: 0.8741\n",
            "val Loss: 0.8923 Acc: 0.7273\n",
            "EarlyStopping counter: 1 out of 30\n",
            "\n",
            "Epoch 6/49\n",
            "----------\n",
            "train Loss: 0.3004 Acc: 0.8872\n",
            "val Loss: 0.2219 Acc: 0.9242\n",
            "Validation loss decreased (0.394754 --> 0.221948).  Saving model ...\n",
            "\n",
            "Epoch 7/49\n",
            "----------\n",
            "train Loss: 0.2473 Acc: 0.9004\n",
            "val Loss: 0.3038 Acc: 0.8939\n",
            "EarlyStopping counter: 1 out of 30\n",
            "\n",
            "Epoch 8/49\n",
            "----------\n",
            "train Loss: 0.2335 Acc: 0.9173\n",
            "val Loss: 0.7832 Acc: 0.8030\n",
            "EarlyStopping counter: 2 out of 30\n",
            "\n",
            "Epoch 9/49\n",
            "----------\n",
            "train Loss: 0.4677 Acc: 0.8214\n",
            "val Loss: 0.3781 Acc: 0.8333\n",
            "EarlyStopping counter: 3 out of 30\n",
            "\n",
            "Epoch 10/49\n",
            "----------\n",
            "train Loss: 0.2992 Acc: 0.8853\n",
            "val Loss: 0.4298 Acc: 0.8030\n",
            "EarlyStopping counter: 4 out of 30\n",
            "\n",
            "Epoch 11/49\n",
            "----------\n",
            "train Loss: 0.1984 Acc: 0.9248\n",
            "val Loss: 0.3964 Acc: 0.8106\n",
            "EarlyStopping counter: 5 out of 30\n",
            "\n",
            "Epoch 12/49\n",
            "----------\n",
            "train Loss: 0.2322 Acc: 0.9173\n",
            "val Loss: 0.4569 Acc: 0.8788\n",
            "EarlyStopping counter: 6 out of 30\n",
            "\n",
            "Epoch 13/49\n",
            "----------\n",
            "train Loss: 0.1983 Acc: 0.9248\n",
            "val Loss: 0.3148 Acc: 0.8939\n",
            "EarlyStopping counter: 7 out of 30\n",
            "\n",
            "Epoch 14/49\n",
            "----------\n",
            "train Loss: 0.2233 Acc: 0.9211\n",
            "val Loss: 2.2320 Acc: 0.4470\n",
            "EarlyStopping counter: 8 out of 30\n",
            "\n",
            "Epoch 15/49\n",
            "----------\n",
            "train Loss: 0.2473 Acc: 0.9173\n",
            "val Loss: 0.2639 Acc: 0.9318\n",
            "EarlyStopping counter: 9 out of 30\n",
            "\n",
            "Epoch 16/49\n",
            "----------\n",
            "train Loss: 0.1782 Acc: 0.9417\n",
            "val Loss: 0.9950 Acc: 0.7576\n",
            "EarlyStopping counter: 10 out of 30\n",
            "\n",
            "Epoch 17/49\n",
            "----------\n",
            "train Loss: 0.2481 Acc: 0.9192\n",
            "val Loss: 0.1834 Acc: 0.9318\n",
            "Validation loss decreased (0.221948 --> 0.183391).  Saving model ...\n",
            "\n",
            "Epoch 18/49\n",
            "----------\n",
            "train Loss: 0.1712 Acc: 0.9417\n",
            "val Loss: 0.1882 Acc: 0.9167\n",
            "EarlyStopping counter: 1 out of 30\n",
            "\n",
            "Epoch 19/49\n",
            "----------\n",
            "train Loss: 0.1515 Acc: 0.9511\n",
            "val Loss: 0.3646 Acc: 0.8788\n",
            "EarlyStopping counter: 2 out of 30\n",
            "\n",
            "Epoch 20/49\n",
            "----------\n",
            "train Loss: 0.1240 Acc: 0.9492\n",
            "val Loss: 0.8031 Acc: 0.7803\n",
            "EarlyStopping counter: 3 out of 30\n",
            "\n",
            "Epoch 21/49\n",
            "----------\n",
            "train Loss: 0.1242 Acc: 0.9568\n",
            "val Loss: 0.3149 Acc: 0.8864\n",
            "EarlyStopping counter: 4 out of 30\n",
            "\n",
            "Epoch 22/49\n",
            "----------\n",
            "train Loss: 0.1777 Acc: 0.9380\n",
            "val Loss: 0.3280 Acc: 0.8788\n",
            "EarlyStopping counter: 5 out of 30\n",
            "\n",
            "Epoch 23/49\n",
            "----------\n",
            "train Loss: 0.1160 Acc: 0.9586\n",
            "val Loss: 0.3663 Acc: 0.8712\n",
            "EarlyStopping counter: 6 out of 30\n",
            "\n",
            "Epoch 24/49\n",
            "----------\n",
            "train Loss: 0.1020 Acc: 0.9643\n",
            "val Loss: 0.3935 Acc: 0.9015\n",
            "EarlyStopping counter: 7 out of 30\n",
            "\n",
            "Epoch 25/49\n",
            "----------\n",
            "train Loss: 0.0971 Acc: 0.9624\n",
            "val Loss: 0.2515 Acc: 0.9242\n",
            "EarlyStopping counter: 8 out of 30\n",
            "\n",
            "Epoch 26/49\n",
            "----------\n",
            "train Loss: 0.1444 Acc: 0.9455\n",
            "val Loss: 0.2666 Acc: 0.9167\n",
            "EarlyStopping counter: 9 out of 30\n",
            "\n",
            "Epoch 27/49\n",
            "----------\n",
            "train Loss: 0.1313 Acc: 0.9455\n",
            "val Loss: 0.3087 Acc: 0.9091\n",
            "EarlyStopping counter: 10 out of 30\n",
            "\n",
            "Epoch 28/49\n",
            "----------\n",
            "train Loss: 0.1223 Acc: 0.9492\n",
            "val Loss: 0.3511 Acc: 0.8788\n",
            "EarlyStopping counter: 11 out of 30\n",
            "\n",
            "Epoch 29/49\n",
            "----------\n",
            "train Loss: 0.1665 Acc: 0.9417\n",
            "val Loss: 0.3724 Acc: 0.8561\n",
            "EarlyStopping counter: 12 out of 30\n",
            "\n",
            "Epoch 30/49\n",
            "----------\n",
            "train Loss: 0.1472 Acc: 0.9380\n",
            "val Loss: 0.5652 Acc: 0.7727\n",
            "EarlyStopping counter: 13 out of 30\n",
            "\n",
            "Epoch 31/49\n",
            "----------\n",
            "train Loss: 0.1276 Acc: 0.9474\n",
            "val Loss: 0.3360 Acc: 0.8712\n",
            "EarlyStopping counter: 14 out of 30\n",
            "\n",
            "Epoch 32/49\n",
            "----------\n",
            "train Loss: 0.1485 Acc: 0.9530\n",
            "val Loss: 0.4555 Acc: 0.8636\n",
            "EarlyStopping counter: 15 out of 30\n",
            "\n",
            "Epoch 33/49\n",
            "----------\n",
            "train Loss: 0.0895 Acc: 0.9662\n",
            "val Loss: 0.2623 Acc: 0.8939\n",
            "EarlyStopping counter: 16 out of 30\n",
            "\n",
            "Epoch 34/49\n",
            "----------\n",
            "train Loss: 0.0835 Acc: 0.9643\n",
            "val Loss: 0.9646 Acc: 0.7424\n",
            "EarlyStopping counter: 17 out of 30\n",
            "\n",
            "Epoch 35/49\n",
            "----------\n",
            "train Loss: 0.0953 Acc: 0.9549\n",
            "val Loss: 0.3613 Acc: 0.8636\n",
            "EarlyStopping counter: 18 out of 30\n",
            "\n",
            "Epoch 36/49\n",
            "----------\n",
            "train Loss: 0.0924 Acc: 0.9680\n",
            "val Loss: 0.9137 Acc: 0.8030\n",
            "EarlyStopping counter: 19 out of 30\n",
            "\n",
            "Epoch 37/49\n",
            "----------\n",
            "train Loss: 0.0907 Acc: 0.9737\n",
            "val Loss: 0.2483 Acc: 0.9242\n",
            "EarlyStopping counter: 20 out of 30\n",
            "\n",
            "Epoch 38/49\n",
            "----------\n",
            "train Loss: 0.1113 Acc: 0.9699\n",
            "val Loss: 0.2489 Acc: 0.8939\n",
            "EarlyStopping counter: 21 out of 30\n",
            "\n",
            "Epoch 39/49\n",
            "----------\n",
            "train Loss: 0.0917 Acc: 0.9643\n",
            "val Loss: 0.4800 Acc: 0.8409\n",
            "EarlyStopping counter: 22 out of 30\n",
            "\n",
            "Epoch 40/49\n",
            "----------\n",
            "train Loss: 0.0632 Acc: 0.9718\n",
            "val Loss: 0.2999 Acc: 0.8939\n",
            "EarlyStopping counter: 23 out of 30\n",
            "\n",
            "Epoch 41/49\n",
            "----------\n",
            "train Loss: 0.0835 Acc: 0.9718\n",
            "val Loss: 0.4936 Acc: 0.8485\n",
            "EarlyStopping counter: 24 out of 30\n",
            "\n",
            "Epoch 42/49\n",
            "----------\n",
            "train Loss: 0.0485 Acc: 0.9850\n",
            "val Loss: 0.2929 Acc: 0.9091\n",
            "EarlyStopping counter: 25 out of 30\n",
            "\n",
            "Epoch 43/49\n",
            "----------\n",
            "train Loss: 0.0803 Acc: 0.9718\n",
            "val Loss: 0.4230 Acc: 0.9015\n",
            "EarlyStopping counter: 26 out of 30\n",
            "\n",
            "Epoch 44/49\n",
            "----------\n",
            "train Loss: 0.0579 Acc: 0.9831\n",
            "val Loss: 0.3910 Acc: 0.9015\n",
            "EarlyStopping counter: 27 out of 30\n",
            "\n",
            "Epoch 45/49\n",
            "----------\n",
            "train Loss: 0.0712 Acc: 0.9793\n",
            "val Loss: 0.5474 Acc: 0.8561\n",
            "EarlyStopping counter: 28 out of 30\n",
            "\n",
            "Epoch 46/49\n",
            "----------\n",
            "train Loss: 0.0778 Acc: 0.9699\n",
            "val Loss: 0.2423 Acc: 0.9318\n",
            "EarlyStopping counter: 29 out of 30\n",
            "\n",
            "Epoch 47/49\n",
            "----------\n",
            "train Loss: 0.1311 Acc: 0.9474\n",
            "val Loss: 3.9095 Acc: 0.5758\n",
            "EarlyStopping counter: 30 out of 30\n",
            "Early stopping\n",
            "Training complete in 3m 45s\n",
            "Best val Acc: 0.931818\n",
            "number of images: 132\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No handles with labels found to put in legend.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "51 8 67 6\n",
            "Accuracy: 0.8939393939393939\n",
            "Precision (positive predictive value): 0.8947368421052632\n",
            "Recall (sensitivity): 0.864406779661017\n",
            "Specificity: 0.9178082191780822\n",
            "F_value: 0.8793103448275862\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "132\n",
            "[0.02901226282119751, 0.14231860637664795, 0.0180930495262146, 0.056987762451171875, 0.12621605396270752, 0.04655730724334717, 0.13813871145248413, 0.06872260570526123, 0.014671623706817627, 0.0920533537864685, 0.020156145095825195, 0.022641897201538086, 0.04331415891647339, 0.018978238105773926, 0.09552526473999023, 0.028324246406555176, 0.00854039192199707, 0.012180328369140625, 0.041143059730529785, 0.01815211772918701, 0.012433528900146484, 0.01597052812576294, 0.02014148235321045, 0.21451526880264282, 0.10834509134292603, 0.07643365859985352, 0.08331030607223511, 0.06209850311279297, 0.01610511541366577, 0.06267416477203369, 0.05626100301742554, 0.08817118406295776, 0.23257708549499512, 0.1592477560043335, 0.6963987946510315, 0.01436460018157959, 0.037313878536224365, 0.3838459849357605, 0.03158003091812134, 0.13230562210083008, 0.014413237571716309, 0.8162718415260315, 0.21940630674362183, 0.006817281246185303, 0.9762742519378662, 0.020324110984802246, 0.03398776054382324, 0.028900861740112305, 0.04463928937911987, 0.05590254068374634, 0.01658576726913452, 0.06185406446456909, 0.18145954608917236, 0.5423674583435059, 0.5312926173210144, 0.8294503688812256, 0.04570424556732178, 0.03771698474884033, 0.12772244215011597, 0.06872379779815674, 0.10684210062026978, 0.028269529342651367, 0.037305593490600586, 0.17200243473052979, 0.07843559980392456, 0.10436230897903442, 0.13836222887039185, 0.35105687379837036, 0.020878374576568604, 0.03561139106750488, 0.020156025886535645, 0.1366673707962036, 0.11185014247894287, 0.905279815196991, 0.7665899395942688, 0.5966852307319641, 0.6992636919021606, 0.9582090973854065, 1.0, 1.0, 1.0, 0.7260047793388367, 0.9536144733428955, 0.020359575748443604, 0.7455888390541077, 0.9541870951652527, 0.9270052909851074, 1.0, 0.9999624490737915, 0.4845430850982666, 0.9496515393257141, 0.9879385828971863, 0.9773492217063904, 0.986358106136322, 0.9591783285140991, 0.19785696268081665, 0.9999524354934692, 0.9504669308662415, 1.0, 0.8141160011291504, 0.9533712863922119, 0.09118008613586426, 0.5836254954338074, 0.9997456669807434, 1.0, 0.1092800498008728, 0.9131954312324524, 0.1140788197517395, 1.0, 0.9987995624542236, 0.4193073511123657, 0.995665967464447, 0.9378419518470764, 0.969322144985199, 1.0, 1.0, 0.9684579968452454, 0.9979621171951294, 0.9999839067459106, 0.9750555753707886, 1.0, 0.9523280262947083, 1.0, 0.9907853603363037, 1.0, 0.9999970197677612, 0.47633129358291626, 0.9921470284461975, 0.9762041568756104, 1.0, 0.5310637354850769, 0.9539076089859009]\n",
            "132\n",
            "roc_auc: 0.9533317854655212\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                  0         1         2         3         4  \\\n",
            "TP                               48        58        58        50        51   \n",
            "TN                               64        58        68        69        67   \n",
            "FP                               10        15         5         4         6   \n",
            "FN                               12         2         2         9         8   \n",
            "Accuracy                   0.835821   0.87218  0.947368  0.901515  0.893939   \n",
            "Positive predictive value  0.827586  0.794521  0.920635  0.925926  0.894737   \n",
            "sensitity                       0.8  0.966667  0.966667  0.847458  0.864407   \n",
            "specificity                0.864865  0.794521  0.931507  0.945205  0.917808   \n",
            "F-value                    0.813559   0.87218  0.943089  0.884956   0.87931   \n",
            "roc_auc                    0.910586  0.952511  0.983562  0.963316  0.953332   \n",
            "\n",
            "                                avg        std  \n",
            "TP                               53    4.19524  \n",
            "TN                             65.2    3.96989  \n",
            "FP                                8    4.04969  \n",
            "FN                              6.6    3.97995  \n",
            "Accuracy                   0.882374  0.0409024  \n",
            "Positive predictive value  0.860921  0.0586593  \n",
            "sensitity                  0.880856  0.0746924  \n",
            "specificity                0.883615   0.061824  \n",
            "F-value                    0.870774  0.0460198  \n",
            "roc_auc                    0.952661  0.0238293  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Od7Y2_he021W"
      },
      "source": [
        "df_cross.to_csv(csv_path, encoding='utf_8_sig')"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blaWE7qw6GjP"
      },
      "source": [
        "#**作ったフォルダの削除**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ats9BT0d6OAP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "132815e6-74a1-4990-ba35-e696ae88903a"
      },
      "source": [
        "dst_path = \"/content/drive/MyDrive/Deep_learning/Strabismus/Dataset_250px_crossvalidation_eso\"\n",
        "directory = dst_path\n",
        "try:\n",
        "    shutil.rmtree(directory)\n",
        "except FileNotFoundError:\n",
        "    print(\"file not found\")\n",
        "    pass"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "file not found\n"
          ]
        }
      ]
    }
  ]
}