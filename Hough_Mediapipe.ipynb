{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled62.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMDbJlmUXhRkMBtp1HT74fO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ykitaguchi77/Strabismus_AI_project/blob/main/Hough_Mediapipe.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWiEi5bze3hE"
      },
      "source": [
        "#**Hough変換を用いた虹彩検出**\n",
        "https://ipsj.ixsq.nii.ac.jp/ej/?action=repository_action_common_download&item_id=113806&item_no=1&attribute_id=1&file_no=1<br>\n",
        "※HEICファイルには未対応。https://www.apowersoft.jp/heic-to-jpgで先に変換。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3lGivAN7eveG"
      },
      "source": [
        "from __future__ import print_function, division\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.autograd import Variable\n",
        "import torch.utils.data as data\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "import pandas as pd\n",
        "\n",
        "#Advanced Pytorchから\n",
        "import glob\n",
        "import os.path as osp\n",
        "import random\n",
        "import json\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "%matplotlib inline\n",
        "\n",
        "#サポートパッチのインポート\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "\n",
        "plt.ion()   # interactive mode\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hq8oSrWcfNgV",
        "outputId": "2315c13e-491c-45bd-b327-6a2aaac14127"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jlx0lP8QQIWP"
      },
      "source": [
        "#**Google Mediapipe modules**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPoLqXy7PcGi",
        "outputId": "9994d766-a80e-427c-e1b6-64b1f28da079",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install mediapipe\n",
        "\n",
        "import mediapipe as mp\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "mp_hands = mp.solutions.hands\n",
        "\n",
        "\n",
        "#サポートパッチのインポート\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "#Face Mesh\n",
        "\n",
        "#!/usr/bin/env python\n",
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "import tensorflow as tf\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "import copy\n",
        "\n",
        "\n",
        "class FaceMesh(object):\n",
        "    def __init__(\n",
        "        self,\n",
        "        max_num_faces=1,\n",
        "        min_detection_confidence=0.7,\n",
        "        min_tracking_confidence=0.7,\n",
        "    ):\n",
        "        mp_face_mesh = mp.solutions.face_mesh\n",
        "        self._face_mesh = mp_face_mesh.FaceMesh(\n",
        "            max_num_faces=max_num_faces,\n",
        "            min_detection_confidence=min_detection_confidence,\n",
        "            min_tracking_confidence=min_tracking_confidence,\n",
        "        )\n",
        "\n",
        "    def __call__(\n",
        "        self,\n",
        "        image,\n",
        "    ):\n",
        "        # 推論\n",
        "        image = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
        "        results = self._face_mesh.process(image)\n",
        "\n",
        "        # X,Y座標を相対座標から絶対座標に変換\n",
        "        # [X座標, Y座標, Z座標, Visibility, Presence]のリストに変更\n",
        "        face_mesh_results = []\n",
        "        if results.multi_face_landmarks is not None:\n",
        "            for face_landmarks in results.multi_face_landmarks:\n",
        "                face_mesh_results.append(\n",
        "                    self._calc_landmarks(image, face_landmarks.landmark))\n",
        "        return face_mesh_results\n",
        "\n",
        "    def _calc_landmarks(self, image, landmarks):\n",
        "        image_width, image_height = image.shape[1], image.shape[0]\n",
        "\n",
        "        landmark_list = []\n",
        "        for _, landmark in enumerate(landmarks):\n",
        "            landmark_x = min(int(landmark.x * image_width), image_width - 1)\n",
        "            landmark_y = min(int(landmark.y * image_height), image_height - 1)\n",
        "\n",
        "            landmark_list.append((landmark_x, landmark_y, landmark.z,\n",
        "                                  landmark.visibility, landmark.presence))\n",
        "        return landmark_list\n",
        "\n",
        "    def _calc_bounding_rect(self, landmarks):\n",
        "        landmark_array = np.empty((0, 2), int)\n",
        "\n",
        "        for _, landmark in enumerate(landmarks):\n",
        "            landmark_x = int(landmark[0])\n",
        "            landmark_y = int(landmark[1])\n",
        "\n",
        "            landmark_point = [np.array((landmark_x, landmark_y))]\n",
        "            landmark_array = np.append(landmark_array, landmark_point, axis=0)\n",
        "\n",
        "        x, y, w, h = cv.boundingRect(landmark_array)\n",
        "\n",
        "        return [x, y, x + w, y + h]\n",
        "\n",
        "    def get_eye_landmarks(self, landmarks):\n",
        "        # 目の輪郭の座標列を取得\n",
        "\n",
        "        left_eye_landmarks = []\n",
        "        right_eye_landmarks = []\n",
        "\n",
        "        if len(landmarks) > 0:\n",
        "            # 参考：https://github.com/tensorflow/tfjs-models/blob/master/facemesh/mesh_map.jpg\n",
        "            # 左目\n",
        "            left_eye_landmarks.append((landmarks[133][0], landmarks[133][1]))\n",
        "            left_eye_landmarks.append((landmarks[173][0], landmarks[173][1]))\n",
        "            left_eye_landmarks.append((landmarks[157][0], landmarks[157][1]))\n",
        "            left_eye_landmarks.append((landmarks[158][0], landmarks[158][1]))\n",
        "            left_eye_landmarks.append((landmarks[159][0], landmarks[159][1]))\n",
        "            left_eye_landmarks.append((landmarks[160][0], landmarks[160][1]))\n",
        "            left_eye_landmarks.append((landmarks[161][0], landmarks[161][1]))\n",
        "            left_eye_landmarks.append((landmarks[246][0], landmarks[246][1]))\n",
        "            left_eye_landmarks.append((landmarks[163][0], landmarks[163][1]))\n",
        "            left_eye_landmarks.append((landmarks[144][0], landmarks[144][1]))\n",
        "            left_eye_landmarks.append((landmarks[145][0], landmarks[145][1]))\n",
        "            left_eye_landmarks.append((landmarks[153][0], landmarks[153][1]))\n",
        "            left_eye_landmarks.append((landmarks[154][0], landmarks[154][1]))\n",
        "            left_eye_landmarks.append((landmarks[155][0], landmarks[155][1]))\n",
        "\n",
        "            # 右目\n",
        "            right_eye_landmarks.append((landmarks[362][0], landmarks[362][1]))\n",
        "            right_eye_landmarks.append((landmarks[398][0], landmarks[398][1]))\n",
        "            right_eye_landmarks.append((landmarks[384][0], landmarks[384][1]))\n",
        "            right_eye_landmarks.append((landmarks[385][0], landmarks[385][1]))\n",
        "            right_eye_landmarks.append((landmarks[386][0], landmarks[386][1]))\n",
        "            right_eye_landmarks.append((landmarks[387][0], landmarks[387][1]))\n",
        "            right_eye_landmarks.append((landmarks[388][0], landmarks[388][1]))\n",
        "            right_eye_landmarks.append((landmarks[466][0], landmarks[466][1]))\n",
        "            right_eye_landmarks.append((landmarks[390][0], landmarks[390][1]))\n",
        "            right_eye_landmarks.append((landmarks[373][0], landmarks[373][1]))\n",
        "            right_eye_landmarks.append((landmarks[374][0], landmarks[374][1]))\n",
        "            right_eye_landmarks.append((landmarks[380][0], landmarks[380][1]))\n",
        "            right_eye_landmarks.append((landmarks[381][0], landmarks[381][1]))\n",
        "            right_eye_landmarks.append((landmarks[382][0], landmarks[382][1]))\n",
        "\n",
        "        return left_eye_landmarks, right_eye_landmarks\n",
        "\n",
        "    def calc_eye_bbox(self, landmarks):\n",
        "        # 目に隣接するバウンディングボックスを取得\n",
        "\n",
        "        left_eye_lm, right_eye_lm = self.get_eye_landmarks(landmarks)\n",
        "\n",
        "        left_eye_bbox = self._calc_bounding_rect(left_eye_lm)\n",
        "        right_eye_bbox = self._calc_bounding_rect(right_eye_lm)\n",
        "\n",
        "        return left_eye_bbox, right_eye_bbox\n",
        "\n",
        "    def calc_around_eye_bbox(self, landmarks, around_ratio=0.5):\n",
        "        # 目の周囲のバウンディングボックスを取得\n",
        "\n",
        "        left_eye_bbox, right_eye_bbox = self.calc_eye_bbox(landmarks)\n",
        "\n",
        "        left_eye_bbox = self._calc_around_eye(left_eye_bbox, around_ratio)\n",
        "        right_eye_bbox = self._calc_around_eye(right_eye_bbox, around_ratio)\n",
        "\n",
        "        return left_eye_bbox, right_eye_bbox\n",
        "\n",
        "    def _calc_around_eye(self, bbox, around_ratio=0.5):\n",
        "        x1, y1, x2, y2 = bbox\n",
        "        x = x1\n",
        "        y = y1\n",
        "        w = x2 - x1\n",
        "        h = y2 - y1\n",
        "\n",
        "        cx = int(x + (w / 2))\n",
        "        cy = int(y + (h / 2))\n",
        "        square_length = max(w, h)\n",
        "        x = int(cx - (square_length / 2))\n",
        "        y = int(cy - (square_length / 2))\n",
        "        w = square_length\n",
        "        h = square_length\n",
        "\n",
        "        around_ratio = 0.5\n",
        "        x = int(x - (square_length * around_ratio))\n",
        "        y = int(y - (square_length * around_ratio))\n",
        "        w = int(square_length * (1 + (around_ratio * 2)))\n",
        "        h = int(square_length * (1 + (around_ratio * 2)))\n",
        "\n",
        "        return [x, y, x + w, y + h]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#iris landmark\n",
        "\n",
        "#!/usr/bin/env python\n",
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "class IrisLandmark(object):\n",
        "    def __init__(\n",
        "        self,\n",
        "        model_path='/content/drive/MyDrive/Deep_learning/iris_landmark.tflite',\n",
        "        num_threads=1,\n",
        "    ):\n",
        "        self._interpreter = tf.lite.Interpreter(model_path=model_path,\n",
        "                                                num_threads=num_threads)\n",
        "        self._interpreter.allocate_tensors()\n",
        "        self._input_details = self._interpreter.get_input_details()\n",
        "        self._output_details = self._interpreter.get_output_details()\n",
        "\n",
        "    def __call__(\n",
        "        self,\n",
        "        image,\n",
        "    ):\n",
        "        input_shape = self._input_details[0]['shape']\n",
        "\n",
        "        # 正規化・リサイズ\n",
        "        img = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
        "        img = img / 255.0\n",
        "        img_resized = tf.image.resize(img, [input_shape[1], input_shape[2]],\n",
        "                                      method='bicubic',\n",
        "                                      preserve_aspect_ratio=False)\n",
        "        img_input = img_resized.numpy()\n",
        "        img_input = (img_input - 0.5) / 0.5\n",
        "\n",
        "        reshape_img = img_input.reshape(1, input_shape[1], input_shape[2],\n",
        "                                        input_shape[3])\n",
        "        tensor = tf.convert_to_tensor(reshape_img, dtype=tf.float32)\n",
        "\n",
        "        # 推論実行\n",
        "        input_details_tensor_index = self._input_details[0]['index']\n",
        "        self._interpreter.set_tensor(input_details_tensor_index, tensor)\n",
        "        self._interpreter.invoke()\n",
        "\n",
        "        # 推論結果取得\n",
        "        output_details_tensor_index0 = self._output_details[0]['index']\n",
        "        output_details_tensor_index1 = self._output_details[1]['index']\n",
        "        eye_contour = self._interpreter.get_tensor(\n",
        "            output_details_tensor_index0)\n",
        "        iris = self._interpreter.get_tensor(output_details_tensor_index1)\n",
        "\n",
        "        return np.squeeze(eye_contour), np.squeeze(iris)\n",
        "\n",
        "    def get_input_shape(self):\n",
        "        input_shape = self._input_details[0]['shape']\n",
        "        return [input_shape[1], input_shape[2]]\n",
        "\n",
        "\n",
        "\n",
        "#Module\n",
        "\n",
        "def detect_iris(image, iris_detector, left_eye, right_eye):\n",
        "    image_width, image_height = image.shape[1], image.shape[0]\n",
        "    input_shape = iris_detector.get_input_shape()\n",
        "\n",
        "    # 左目\n",
        "    # 目の周辺の画像を切り抜き\n",
        "    left_eye_x1 = max(left_eye[0], 0)\n",
        "    left_eye_y1 = max(left_eye[1], 0)\n",
        "    left_eye_x2 = min(left_eye[2], image_width)\n",
        "    left_eye_y2 = min(left_eye[3], image_height)\n",
        "    left_eye_image = copy.deepcopy(image[left_eye_y1:left_eye_y2,\n",
        "                                         left_eye_x1:left_eye_x2])\n",
        "    # 虹彩検出\n",
        "    eye_contour, iris = iris_detector(left_eye_image)\n",
        "    # 座標を相対座標から絶対座標に変換\n",
        "    left_iris = calc_iris_point(left_eye, eye_contour, iris, input_shape)\n",
        "\n",
        "    # 右目\n",
        "    # 目の周辺の画像を切り抜き\n",
        "    right_eye_x1 = max(right_eye[0], 0)\n",
        "    right_eye_y1 = max(right_eye[1], 0)\n",
        "    right_eye_x2 = min(right_eye[2], image_width)\n",
        "    right_eye_y2 = min(right_eye[3], image_height)\n",
        "    right_eye_image = copy.deepcopy(image[right_eye_y1:right_eye_y2,\n",
        "                                          right_eye_x1:right_eye_x2])\n",
        "    # 虹彩検出\n",
        "    eye_contour, iris = iris_detector(right_eye_image)\n",
        "    # 座標を相対座標から絶対座標に変換\n",
        "    right_iris = calc_iris_point(right_eye, eye_contour, iris, input_shape)\n",
        "\n",
        "    return left_iris, right_iris\n",
        "\n",
        "\n",
        "def calc_iris_point(eye_bbox, eye_contour, iris, input_shape):\n",
        "    iris_list = []\n",
        "    for index in range(5):\n",
        "        point_x = int(iris[index * 3] *\n",
        "                      ((eye_bbox[2] - eye_bbox[0]) / input_shape[0]))\n",
        "        point_y = int(iris[index * 3 + 1] *\n",
        "                      ((eye_bbox[3] - eye_bbox[1]) / input_shape[1]))\n",
        "        point_x += eye_bbox[0]\n",
        "        point_y += eye_bbox[1]\n",
        "\n",
        "        iris_list.append((point_x, point_y))\n",
        "\n",
        "    return iris_list\n",
        "\n",
        "\n",
        "def calc_min_enc_losingCircle(landmark_list):\n",
        "    center, radius = cv.minEnclosingCircle(np.array(landmark_list))\n",
        "    center = (int(center[0]), int(center[1]))\n",
        "    radius = int(radius)\n",
        "\n",
        "    return center, radius\n",
        "\n",
        "\n",
        "def draw_debug_image(\n",
        "    debug_image,\n",
        "    left_iris,\n",
        "    right_iris,\n",
        "    left_center,\n",
        "    left_radius,\n",
        "    right_center,\n",
        "    right_radius,\n",
        "):\n",
        "    # 虹彩：外接円\n",
        "    cv.circle(debug_image, left_center, left_radius, (0, 255, 0), 2)\n",
        "    cv.circle(debug_image, right_center, right_radius, (0, 255, 0), 2)\n",
        "\n",
        "    # 虹彩：ランドマーク\n",
        "    for point in left_iris:\n",
        "        cv.circle(debug_image, (point[0], point[1]), 1, (0, 0, 255), 1)\n",
        "    for point in right_iris:\n",
        "        cv.circle(debug_image, (point[0], point[1]), 1, (0, 0, 255), 1)\n",
        "\n",
        "    # 虹彩：半径\n",
        "    cv.putText(debug_image, 'r:' + str(left_radius) + 'px',\n",
        "               (left_center[0] + int(left_radius * 1.5),\n",
        "                left_center[1] + int(left_radius * 0.5)),\n",
        "               cv.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 1)\n",
        "    cv.putText(debug_image, 'l:' + str(right_radius) + 'px',\n",
        "               (right_center[0] + int(right_radius * 1.5),\n",
        "                right_center[1] + int(right_radius * 0.5)),\n",
        "               cv.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 1)\n",
        "\n",
        "    return debug_image"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mediapipe in /usr/local/lib/python3.7/dist-packages (0.8.7.1)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from mediapipe) (0.12.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from mediapipe) (1.15.0)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.7/dist-packages (from mediapipe) (4.1.2.30)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from mediapipe) (3.2.2)\n",
            "Requirement already satisfied: protobuf>=3.11.4 in /usr/local/lib/python3.7/dist-packages (from mediapipe) (3.17.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mediapipe) (1.19.5)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from mediapipe) (0.37.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.7/dist-packages (from mediapipe) (21.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mediapipe) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mediapipe) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mediapipe) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mediapipe) (0.10.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-4P9240Q7sb",
        "outputId": "e67f9899-cf0d-45de-fcd8-a0a801afd6a3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# For static images:\n",
        "\n",
        "img_path = \"/content/drive/MyDrive/Deep_learning/Face_Images/IMG_3990.JPG\"\n",
        "image = cv2.imread(img_path)\n",
        "\n",
        "\n",
        "# 引数 #####################################################################\n",
        "\n",
        "max_num_faces = 1\n",
        "min_detection_confidence = 0.7\n",
        "min_tracking_confidence = 0.7\n",
        "\n",
        "\n",
        "# モデルロード #############################################################\n",
        "face_mesh = FaceMesh(\n",
        "    max_num_faces,\n",
        "    min_detection_confidence,\n",
        "    min_tracking_confidence,\n",
        ")\n",
        "iris_detector = IrisLandmark()\n",
        "\n",
        "# 検出実施 #############################################################\n",
        "# Face Mesh検出\n",
        "face_results = face_mesh(image)\n",
        "for face_result in face_results:\n",
        "    # 目周辺のバウンディングボックス計算\n",
        "    left_eye, right_eye = face_mesh.calc_around_eye_bbox(face_result)\n",
        "\n",
        "    # 虹彩検出\n",
        "    left_iris, right_iris = detect_iris(image, iris_detector, left_eye,\n",
        "                                        right_eye)\n",
        "\n",
        "    # 虹彩の外接円を計算\n",
        "    left_center, left_radius = calc_min_enc_losingCircle(left_iris)\n",
        "    right_center, right_radius = calc_min_enc_losingCircle(right_iris)\n",
        "\n",
        "    # デバッグ描画\n",
        "    debug_image = copy.deepcopy(image)\n",
        "    debug_image = draw_debug_image(\n",
        "        debug_image,\n",
        "        left_iris,\n",
        "        right_iris,\n",
        "        left_center,\n",
        "        left_radius,\n",
        "        right_center,\n",
        "        right_radius,\n",
        "    )\n",
        "\n",
        "print(left_center)\n",
        "print(left_radius)\n",
        "print(right_center)\n",
        "print(right_radius)\n",
        "\n",
        "#cv2_imshow(debug_image)\n",
        "#cv.destroyAllWindows()\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1688, 1368)\n",
            "34\n",
            "(2078, 1368)\n",
            "35\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JhetphMaW0ER"
      },
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.transform import hough_circle, hough_circle_peaks, hough_ellipse\n",
        "from skimage.feature import canny\n",
        "from skimage.draw import circle_perimeter, ellipse_perimeter\n",
        "from skimage.color import rgb2gray\n",
        "from skimage import data, color, img_as_ubyte\n",
        "import matplotlib.patches as patches\n",
        "\n",
        "#眼周囲の画像を切り抜き\n",
        "\n",
        "x0 = left_center[0]-left_radius*2\n",
        "x1 = left_center[0]+left_radius*2\n",
        "y0 = left_center[1]-left_radius*2\n",
        "y1 = left_center[1]+left_radius*2\n",
        "\n",
        "img3 = image[y0 : y1, x0 : x1]\n",
        "cv2_imshow(img3)\n",
        "\n",
        "#白黒化\n",
        "gray = cv2.cvtColor(img3, cv2.COLOR_BGR2GRAY)\n",
        "cv2_imshow(gray)\n",
        "\n",
        "\n",
        "#OTSUの2値化\n",
        "ret, th = cv2.threshold(gray, 0, 255, cv2.THRESH_OTSU)\n",
        "cv2_imshow(th)\n",
        "\n",
        "#Canny法によるedge検出\n",
        "edges = canny(th)\n",
        "fig, ax = plt.subplots()\n",
        "ax.imshow(edges, cmap=plt.cm.gray)\n",
        "\n",
        "#ハフ変換による円検出\n",
        "min_radius = int(left_radius*0.8)\n",
        "max_radius = int(left_radius*1.5)\n",
        "\n",
        "hough_radii = np.arange(min_radius, max_radius, 1)\n",
        "hough_res = hough_circle(edges, hough_radii)\n",
        "hough_res.shape\n",
        "#(4, 400, 400)\n",
        "\n",
        "#誤差が少なく近似されている円の選出\n",
        "accums, cx, cy, radii = hough_circle_peaks(hough_res, hough_radii,\n",
        "                                           total_num_peaks=1) #数字を増やすと検出する円の種類を増やせる\n",
        "#print(accums)\n",
        "print(cx)\n",
        "print(cy)\n",
        "#print(radii)\n",
        "\n",
        "\n",
        "#結果の表示\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "# Draw the most prominent 1 circles\n",
        "image = color.gray2rgb(img3)\n",
        "for center_y, center_x, radius in zip(cy, cx, radii):\n",
        "    circy, circx = circle_perimeter(center_y, center_x, radius,\n",
        "                                    shape=image.shape)\n",
        "    image[circy, circx] = (220, 20, 20)\n",
        "\n",
        "ax.imshow(image, cmap=plt.cm.gray)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HdbG8mFaKmf7"
      },
      "source": [
        "#**角膜反射検出**\n",
        "検出した角膜内の明るい点を全て抜き出し、妥当な場所（横幅は画像の中央、縦幅は上3/10に最も近い所）にあるものを選択する"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPj5fgnaaDy1"
      },
      "source": [
        "h, w = img3.shape[:2]\n",
        "#print(h)\n",
        "#print(w)\n",
        "print(\"center_y: \"+str(center_y))\n",
        "print(\"center_x: \"+str(center_x))\n",
        "print(\"radius: \"+str(radius))\n",
        "\n",
        "# 検出した虹彩に沿ったマスク作成 (黒く塗りつぶす画素の値は0)\n",
        "mask = np.zeros((h, w), dtype=np.uint8)\n",
        "# 円を描画する関数 circle() を利用してマスクの残したい部分を 255 にしている。\n",
        "cv2.circle(mask, center=(center_x, center_y), radius=radius, color=255, thickness=-1)\n",
        "\n",
        "# マスクを描画\n",
        "plt.imshow(mask, cmap='gray')\n",
        "plt.axis('off')\n",
        "#plt.show()\n",
        "\n",
        "img4[mask==0] = [0, 0, 0]  # mask の値が 0 の画素は黒で塗りつぶす。\n",
        "plt.imshow(cv2.cvtColor(img4, cv2.COLOR_BGR2RGB))\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# 画像の白いところを抜き出す\n",
        "hsv = cv2.cvtColor(img4, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "lower_white = np.array([0,0,200])\n",
        "upper_white = np.array([180,45,255])\n",
        "\n",
        "mask_white = cv2.inRange(hsv, lower_white, upper_white)\n",
        "res_white = cv2.bitwise_and(img4, img4, mask= mask_white)\n",
        "\n",
        "plt.imshow(res_white)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vj4WTwr1QYCS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}