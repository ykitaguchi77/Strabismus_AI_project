{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled62.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNOVoKqZ0fbXXzQYdpZ6hEe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ykitaguchi77/Strabismus_AI_project/blob/main/Hough_Mediapipe1.4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWiEi5bze3hE"
      },
      "source": [
        "#**Hough変換を用いた虹彩検出**\n",
        "https://ipsj.ixsq.nii.ac.jp/ej/?action=repository_action_common_download&item_id=113806&item_no=1&attribute_id=1&file_no=1<br>\n",
        "※HEICファイルには未対応。https://www.apowersoft.jp/heic-to-jpgで先に変換。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3lGivAN7eveG"
      },
      "source": [
        "from __future__ import print_function, division\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.autograd import Variable\n",
        "import torch.utils.data as data\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "import pandas as pd\n",
        "\n",
        "#Advanced Pytorchから\n",
        "import glob\n",
        "import os.path as osp\n",
        "import random\n",
        "import json\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "%matplotlib inline\n",
        "\n",
        "#サポートパッチのインポート\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "\n",
        "plt.ion()   # interactive mode\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hq8oSrWcfNgV",
        "outputId": "61d577d2-71dc-4dd7-8a9c-3e8e81e9abd1"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jlx0lP8QQIWP"
      },
      "source": [
        "#**Google Mediapipe modules**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPoLqXy7PcGi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e13a8b6a-9569-48a2-a520-952a4eb1a023"
      },
      "source": [
        "!pip install mediapipe\n",
        "\n",
        "import mediapipe as mp\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "mp_hands = mp.solutions.hands\n",
        "\n",
        "\n",
        "#サポートパッチのインポート\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "#Face Mesh\n",
        "\n",
        "#!/usr/bin/env python\n",
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "import tensorflow as tf\n",
        "import cv2 as cv\n",
        "import numpy as np\n",
        "import copy\n",
        "\n",
        "\n",
        "class FaceMesh(object):\n",
        "    def __init__(\n",
        "        self,\n",
        "        max_num_faces=1,\n",
        "        min_detection_confidence=0.7,\n",
        "        min_tracking_confidence=0.7,\n",
        "    ):\n",
        "        mp_face_mesh = mp.solutions.face_mesh\n",
        "        self._face_mesh = mp_face_mesh.FaceMesh(\n",
        "            max_num_faces=max_num_faces,\n",
        "            min_detection_confidence=min_detection_confidence,\n",
        "            min_tracking_confidence=min_tracking_confidence,\n",
        "        )\n",
        "\n",
        "    def __call__(\n",
        "        self,\n",
        "        image,\n",
        "    ):\n",
        "        # 推論\n",
        "        image = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
        "        results = self._face_mesh.process(image)\n",
        "\n",
        "        # X,Y座標を相対座標から絶対座標に変換\n",
        "        # [X座標, Y座標, Z座標, Visibility, Presence]のリストに変更\n",
        "        face_mesh_results = []\n",
        "        if results.multi_face_landmarks is not None:\n",
        "            for face_landmarks in results.multi_face_landmarks:\n",
        "                face_mesh_results.append(\n",
        "                    self._calc_landmarks(image, face_landmarks.landmark))\n",
        "        return face_mesh_results\n",
        "\n",
        "    def _calc_landmarks(self, image, landmarks):\n",
        "        image_width, image_height = image.shape[1], image.shape[0]\n",
        "\n",
        "        landmark_list = []\n",
        "        for _, landmark in enumerate(landmarks):\n",
        "            landmark_x = min(int(landmark.x * image_width), image_width - 1)\n",
        "            landmark_y = min(int(landmark.y * image_height), image_height - 1)\n",
        "\n",
        "            landmark_list.append((landmark_x, landmark_y, landmark.z,\n",
        "                                  landmark.visibility, landmark.presence))\n",
        "        return landmark_list\n",
        "\n",
        "    def _calc_bounding_rect(self, landmarks):\n",
        "        landmark_array = np.empty((0, 2), int)\n",
        "\n",
        "        for _, landmark in enumerate(landmarks):\n",
        "            landmark_x = int(landmark[0])\n",
        "            landmark_y = int(landmark[1])\n",
        "\n",
        "            landmark_point = [np.array((landmark_x, landmark_y))]\n",
        "            landmark_array = np.append(landmark_array, landmark_point, axis=0)\n",
        "\n",
        "        x, y, w, h = cv.boundingRect(landmark_array)\n",
        "\n",
        "        return [x, y, x + w, y + h]\n",
        "\n",
        "    def get_eye_landmarks(self, landmarks):\n",
        "        # 目の輪郭の座標列を取得\n",
        "\n",
        "        left_eye_landmarks = []\n",
        "        right_eye_landmarks = []\n",
        "\n",
        "        if len(landmarks) > 0:\n",
        "            # 参考：https://github.com/tensorflow/tfjs-models/blob/master/facemesh/mesh_map.jpg\n",
        "            # 左目\n",
        "            left_eye_landmarks.append((landmarks[133][0], landmarks[133][1]))\n",
        "            left_eye_landmarks.append((landmarks[173][0], landmarks[173][1]))\n",
        "            left_eye_landmarks.append((landmarks[157][0], landmarks[157][1]))\n",
        "            left_eye_landmarks.append((landmarks[158][0], landmarks[158][1]))\n",
        "            left_eye_landmarks.append((landmarks[159][0], landmarks[159][1]))\n",
        "            left_eye_landmarks.append((landmarks[160][0], landmarks[160][1]))\n",
        "            left_eye_landmarks.append((landmarks[161][0], landmarks[161][1]))\n",
        "            left_eye_landmarks.append((landmarks[246][0], landmarks[246][1]))\n",
        "            left_eye_landmarks.append((landmarks[163][0], landmarks[163][1]))\n",
        "            left_eye_landmarks.append((landmarks[144][0], landmarks[144][1]))\n",
        "            left_eye_landmarks.append((landmarks[145][0], landmarks[145][1]))\n",
        "            left_eye_landmarks.append((landmarks[153][0], landmarks[153][1]))\n",
        "            left_eye_landmarks.append((landmarks[154][0], landmarks[154][1]))\n",
        "            left_eye_landmarks.append((landmarks[155][0], landmarks[155][1]))\n",
        "\n",
        "            # 右目\n",
        "            right_eye_landmarks.append((landmarks[362][0], landmarks[362][1]))\n",
        "            right_eye_landmarks.append((landmarks[398][0], landmarks[398][1]))\n",
        "            right_eye_landmarks.append((landmarks[384][0], landmarks[384][1]))\n",
        "            right_eye_landmarks.append((landmarks[385][0], landmarks[385][1]))\n",
        "            right_eye_landmarks.append((landmarks[386][0], landmarks[386][1]))\n",
        "            right_eye_landmarks.append((landmarks[387][0], landmarks[387][1]))\n",
        "            right_eye_landmarks.append((landmarks[388][0], landmarks[388][1]))\n",
        "            right_eye_landmarks.append((landmarks[466][0], landmarks[466][1]))\n",
        "            right_eye_landmarks.append((landmarks[390][0], landmarks[390][1]))\n",
        "            right_eye_landmarks.append((landmarks[373][0], landmarks[373][1]))\n",
        "            right_eye_landmarks.append((landmarks[374][0], landmarks[374][1]))\n",
        "            right_eye_landmarks.append((landmarks[380][0], landmarks[380][1]))\n",
        "            right_eye_landmarks.append((landmarks[381][0], landmarks[381][1]))\n",
        "            right_eye_landmarks.append((landmarks[382][0], landmarks[382][1]))\n",
        "\n",
        "        return left_eye_landmarks, right_eye_landmarks\n",
        "\n",
        "    def calc_eye_bbox(self, landmarks):\n",
        "        # 目に隣接するバウンディングボックスを取得\n",
        "\n",
        "        left_eye_lm, right_eye_lm = self.get_eye_landmarks(landmarks)\n",
        "\n",
        "        left_eye_bbox = self._calc_bounding_rect(left_eye_lm)\n",
        "        right_eye_bbox = self._calc_bounding_rect(right_eye_lm)\n",
        "\n",
        "        return left_eye_bbox, right_eye_bbox\n",
        "\n",
        "    def calc_around_eye_bbox(self, landmarks, around_ratio=0.5):\n",
        "        # 目の周囲のバウンディングボックスを取得\n",
        "\n",
        "        left_eye_bbox, right_eye_bbox = self.calc_eye_bbox(landmarks)\n",
        "\n",
        "        left_eye_bbox = self._calc_around_eye(left_eye_bbox, around_ratio)\n",
        "        right_eye_bbox = self._calc_around_eye(right_eye_bbox, around_ratio)\n",
        "\n",
        "        return left_eye_bbox, right_eye_bbox\n",
        "\n",
        "    def _calc_around_eye(self, bbox, around_ratio=0.5):\n",
        "        x1, y1, x2, y2 = bbox\n",
        "        x = x1\n",
        "        y = y1\n",
        "        w = x2 - x1\n",
        "        h = y2 - y1\n",
        "\n",
        "        cx = int(x + (w / 2))\n",
        "        cy = int(y + (h / 2))\n",
        "        square_length = max(w, h)\n",
        "        x = int(cx - (square_length / 2))\n",
        "        y = int(cy - (square_length / 2))\n",
        "        w = square_length\n",
        "        h = square_length\n",
        "\n",
        "        around_ratio = 0.5\n",
        "        x = int(x - (square_length * around_ratio))\n",
        "        y = int(y - (square_length * around_ratio))\n",
        "        w = int(square_length * (1 + (around_ratio * 2)))\n",
        "        h = int(square_length * (1 + (around_ratio * 2)))\n",
        "\n",
        "        return [x, y, x + w, y + h]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#iris landmark\n",
        "\n",
        "#!/usr/bin/env python\n",
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "class IrisLandmark(object):\n",
        "    def __init__(\n",
        "        self,\n",
        "        model_path='/content/drive/MyDrive/Deep_learning/iris_landmark.tflite',\n",
        "        num_threads=1,\n",
        "    ):\n",
        "        self._interpreter = tf.lite.Interpreter(model_path=model_path,\n",
        "                                                num_threads=num_threads)\n",
        "        self._interpreter.allocate_tensors()\n",
        "        self._input_details = self._interpreter.get_input_details()\n",
        "        self._output_details = self._interpreter.get_output_details()\n",
        "\n",
        "    def __call__(\n",
        "        self,\n",
        "        image,\n",
        "    ):\n",
        "        input_shape = self._input_details[0]['shape']\n",
        "\n",
        "        # 正規化・リサイズ\n",
        "        img = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
        "        img = img / 255.0\n",
        "        img_resized = tf.image.resize(img, [input_shape[1], input_shape[2]],\n",
        "                                      method='bicubic',\n",
        "                                      preserve_aspect_ratio=False)\n",
        "        img_input = img_resized.numpy()\n",
        "        img_input = (img_input - 0.5) / 0.5\n",
        "\n",
        "        reshape_img = img_input.reshape(1, input_shape[1], input_shape[2],\n",
        "                                        input_shape[3])\n",
        "        tensor = tf.convert_to_tensor(reshape_img, dtype=tf.float32)\n",
        "\n",
        "        # 推論実行\n",
        "        input_details_tensor_index = self._input_details[0]['index']\n",
        "        self._interpreter.set_tensor(input_details_tensor_index, tensor)\n",
        "        self._interpreter.invoke()\n",
        "\n",
        "        # 推論結果取得\n",
        "        output_details_tensor_index0 = self._output_details[0]['index']\n",
        "        output_details_tensor_index1 = self._output_details[1]['index']\n",
        "        eye_contour = self._interpreter.get_tensor(\n",
        "            output_details_tensor_index0)\n",
        "        iris = self._interpreter.get_tensor(output_details_tensor_index1)\n",
        "\n",
        "        return np.squeeze(eye_contour), np.squeeze(iris)\n",
        "\n",
        "    def get_input_shape(self):\n",
        "        input_shape = self._input_details[0]['shape']\n",
        "        return [input_shape[1], input_shape[2]]\n",
        "\n",
        "\n",
        "\n",
        "#Module\n",
        "\n",
        "def detect_iris(image, iris_detector, left_eye, right_eye):\n",
        "    image_width, image_height = image.shape[1], image.shape[0]\n",
        "    input_shape = iris_detector.get_input_shape()\n",
        "\n",
        "    # 左目\n",
        "    # 目の周辺の画像を切り抜き\n",
        "    left_eye_x1 = max(left_eye[0], 0)\n",
        "    left_eye_y1 = max(left_eye[1], 0)\n",
        "    left_eye_x2 = min(left_eye[2], image_width)\n",
        "    left_eye_y2 = min(left_eye[3], image_height)\n",
        "    left_eye_image = copy.deepcopy(image[left_eye_y1:left_eye_y2,\n",
        "                                         left_eye_x1:left_eye_x2])\n",
        "    # 虹彩検出\n",
        "    eye_contour, iris = iris_detector(left_eye_image)\n",
        "    # 座標を相対座標から絶対座標に変換\n",
        "    left_iris = calc_iris_point(left_eye, eye_contour, iris, input_shape)\n",
        "\n",
        "    # 右目\n",
        "    # 目の周辺の画像を切り抜き\n",
        "    right_eye_x1 = max(right_eye[0], 0)\n",
        "    right_eye_y1 = max(right_eye[1], 0)\n",
        "    right_eye_x2 = min(right_eye[2], image_width)\n",
        "    right_eye_y2 = min(right_eye[3], image_height)\n",
        "    right_eye_image = copy.deepcopy(image[right_eye_y1:right_eye_y2,\n",
        "                                          right_eye_x1:right_eye_x2])\n",
        "    # 虹彩検出\n",
        "    eye_contour, iris = iris_detector(right_eye_image)\n",
        "    # 座標を相対座標から絶対座標に変換\n",
        "    right_iris = calc_iris_point(right_eye, eye_contour, iris, input_shape)\n",
        "\n",
        "    return left_iris, right_iris\n",
        "\n",
        "\n",
        "def calc_iris_point(eye_bbox, eye_contour, iris, input_shape):\n",
        "    iris_list = []\n",
        "    for index in range(5):\n",
        "        point_x = int(iris[index * 3] *\n",
        "                      ((eye_bbox[2] - eye_bbox[0]) / input_shape[0]))\n",
        "        point_y = int(iris[index * 3 + 1] *\n",
        "                      ((eye_bbox[3] - eye_bbox[1]) / input_shape[1]))\n",
        "        point_x += eye_bbox[0]\n",
        "        point_y += eye_bbox[1]\n",
        "\n",
        "        iris_list.append((point_x, point_y))\n",
        "\n",
        "    return iris_list\n",
        "\n",
        "\n",
        "def calc_min_enc_losingCircle(landmark_list):\n",
        "    center, radius = cv.minEnclosingCircle(np.array(landmark_list))\n",
        "    center = (int(center[0]), int(center[1]))\n",
        "    radius = int(radius)\n",
        "\n",
        "    return center, radius\n",
        "\n",
        "\n",
        "def draw_debug_image(\n",
        "    debug_image,\n",
        "    left_iris,\n",
        "    right_iris,\n",
        "    left_center,\n",
        "    left_radius,\n",
        "    right_center,\n",
        "    right_radius,\n",
        "):\n",
        "    # 虹彩：外接円\n",
        "    cv.circle(debug_image, left_center, left_radius, (0, 255, 0), 2)\n",
        "    cv.circle(debug_image, right_center, right_radius, (0, 255, 0), 2)\n",
        "\n",
        "    # 虹彩：ランドマーク\n",
        "    for point in left_iris:\n",
        "        cv.circle(debug_image, (point[0], point[1]), 1, (0, 0, 255), 1)\n",
        "    for point in right_iris:\n",
        "        cv.circle(debug_image, (point[0], point[1]), 1, (0, 0, 255), 1)\n",
        "\n",
        "    # 虹彩：半径\n",
        "    cv.putText(debug_image, 'r:' + str(left_radius) + 'px',\n",
        "               (left_center[0] + int(left_radius * 1.5),\n",
        "                left_center[1] + int(left_radius * 0.5)),\n",
        "               cv.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 1)\n",
        "    cv.putText(debug_image, 'l:' + str(right_radius) + 'px',\n",
        "               (right_center[0] + int(right_radius * 1.5),\n",
        "                right_center[1] + int(right_radius * 0.5)),\n",
        "               cv.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 1)\n",
        "\n",
        "    return debug_image"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mediapipe in /usr/local/lib/python3.7/dist-packages (0.8.7.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mediapipe) (1.19.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from mediapipe) (1.15.0)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.7/dist-packages (from mediapipe) (4.1.2.30)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from mediapipe) (0.37.0)\n",
            "Requirement already satisfied: protobuf>=3.11.4 in /usr/local/lib/python3.7/dist-packages (from mediapipe) (3.17.3)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from mediapipe) (0.12.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from mediapipe) (3.2.2)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.7/dist-packages (from mediapipe) (21.2.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mediapipe) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mediapipe) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mediapipe) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mediapipe) (0.10.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o4e7cwIKpCin"
      },
      "source": [
        "#**Hough変換を用いた角膜反射と虹彩のセグメンテーション**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JhetphMaW0ER"
      },
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage.transform import hough_circle, hough_circle_peaks, hough_ellipse\n",
        "from skimage.feature import canny\n",
        "from skimage.draw import circle_perimeter, ellipse_perimeter\n",
        "from skimage.color import rgb2gray\n",
        "from skimage import data, color, img_as_ubyte\n",
        "import matplotlib.patches as patches\n",
        "\n",
        "\n",
        "def eye_segmentation(center, radius, image):\n",
        "    #眼周囲の画像を切り抜き\n",
        "    x0 = center[0]-left_radius*2\n",
        "    x1 = center[0]+left_radius*2\n",
        "    y0 = int(center[1]-left_radius*0.5)\n",
        "    y1 = left_center[1]+left_radius*2\n",
        "\n",
        "    out_img = image[y0 : y1, x0 : x1]\n",
        "    #print(\"cropped_img_shape: \"+str(out_img.shape))\n",
        "    return out_img, x0, y0  #抜き出し画像の左上の座標をアウトプットしておく\n",
        "\n",
        "\n",
        "def hough_segmentation(image):\n",
        "    #白黒化\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    #cv2_imshow(gray)\n",
        "\n",
        "\n",
        "    #OTSUの2値化\n",
        "    ret, th = cv2.threshold(gray, 0, 255, cv2.THRESH_OTSU)\n",
        "    #cv2_imshow(th)\n",
        "\n",
        "    #Canny法によるedge検出\n",
        "    edges = canny(th)\n",
        "    #fig, ax = plt.subplots()\n",
        "    #ax.imshow(edges, cmap=plt.cm.gray)\n",
        "\n",
        "    #ハフ変換による円検出\n",
        "    min_radius = int(left_radius*0.8)\n",
        "    max_radius = int(left_radius*1.5)\n",
        "\n",
        "    hough_radii = np.arange(min_radius, max_radius, 1)\n",
        "    hough_res = hough_circle(edges, hough_radii)\n",
        "    hough_res.shape\n",
        "    #(4, 400, 400)\n",
        "\n",
        "    #誤差が少なく近似されている円の選出\n",
        "    accums, cx, cy, radii = hough_circle_peaks(hough_res, hough_radii,\n",
        "                                              total_num_peaks=1) #数字を増やすと検出する円の種類を増やせる\n",
        "    #print(accums)\n",
        "    #print(cx)\n",
        "    #print(cy)\n",
        "    #print(radii)\n",
        "\n",
        "    #結果の表示\n",
        "    #fig, ax = plt.subplots()\n",
        "\n",
        "    # Draw the most prominent 1 circles\n",
        "    image_cornea = color.gray2rgb(image)\n",
        "    for center_y, center_x, radius in zip(cy, cx, radii):\n",
        "        circy, circx = circle_perimeter(center_y, center_x, radius,\n",
        "                                        shape=image.shape)\n",
        "        image_cornea[circy, circx] = (220, 20, 20)\n",
        "\n",
        "    #ax.imshow(image_cornea, cmap=plt.cm.gray)\n",
        "    #plt.show()\n",
        "\n",
        "    #ここから角膜反射検出\n",
        "\n",
        "    h, w = image.shape[:2]\n",
        "    #print(h)\n",
        "    #print(w)\n",
        "    print(\"center_y: \"+str(center_y))\n",
        "    print(\"center_x: \"+str(center_x))\n",
        "    print(\"radius: \"+str(radius))\n",
        "\n",
        "    # 検出した虹彩に沿ったマスク作成 (黒く塗りつぶす画素の値は0)\n",
        "    mask = np.zeros((h, w), dtype=np.uint8)\n",
        "    # 円を描画する関数 circle() を利用してマスクの残したい部分を 255 にしている。\n",
        "    cv2.circle(mask, center=(center_x, center_y), radius=radius, color=255, thickness=-1)\n",
        "\n",
        "    # マスクを描画\n",
        "    #plt.imshow(mask, cmap='gray')\n",
        "    #plt.axis('off')\n",
        "    #plt.show()\n",
        "\n",
        "    img4 = copy.deepcopy(image)\n",
        "    img4[mask==0] = [0, 0, 0]  # mask の値が 0 の画素は黒で塗りつぶす。\n",
        "    #plt.imshow(cv2.cvtColor(img4, cv2.COLOR_BGR2RGB))\n",
        "    #plt.axis('off')\n",
        "    #plt.show()\n",
        "\n",
        "\n",
        "    # 画像の白いところを抜き出す\n",
        "    hsv = cv2.cvtColor(img4, cv2.COLOR_BGR2HSV)\n",
        "\n",
        "    lower_white = np.array([0,0,200])\n",
        "    upper_white = np.array([180,45,255])\n",
        "\n",
        "    mask_white = cv2.inRange(hsv, lower_white, upper_white)\n",
        "    res_white = cv2.bitwise_and(img4, img4, mask= mask_white)\n",
        "\n",
        "    #plt.imshow(res_white)\n",
        "    #plt.axis('off')\n",
        "    #plt.show()\n",
        "\n",
        "\n",
        "    #RGBに直す\n",
        "    res_white_WB = cv2.cvtColor(res_white, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    #輪郭検出\n",
        "    contours, hierarchy = cv2.findContours(\n",
        "        res_white_WB, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE\n",
        "    )\n",
        "\n",
        "    # 小さい輪郭は誤検出として削除する\n",
        "    contours = list(filter(lambda x: cv2.contourArea(x) > 1, contours))\n",
        "\n",
        "    #輪郭の重心を計算(検出されたすべての輪郭に対して)\n",
        "    candidate = center_of_gravity(contours)\n",
        "\n",
        "    #画像の中心（横幅の中心、縦幅の上2/10）に近いものを選択する\n",
        "    #※上1/3にしているのは、MRD-1<MRD-2であるため\n",
        "    img_center = [int(0.5*img4.shape[0]), int(0.2*img4.shape[1])]\n",
        "    print(\"img_center: \"+str(img_center))\n",
        "\n",
        "    pupil_center = nearPoint(candidate, img_center)\n",
        "\n",
        "    print(\"nearest from the center: \"+str(pupil_center))\n",
        "\n",
        "    img5 = copy.deepcopy(image)\n",
        "    img5_rgb = cv2.cvtColor(img5, cv2.COLOR_BGR2RGB)\n",
        "    cv2.circle(img5_rgb, (pupil_center[0], pupil_center[1]), 2, (255,0,0), 2, 4)\n",
        "    #plt.imshow(img5_rgb)\n",
        "    #plt.show()\n",
        "\n",
        "    print(\"Center of cornea: [\"+str(int(cx))+\", \"+str(int(cy))+\"]\" )\n",
        "    print(\"Corneal reflex: [\"+str(pupil_center[0])+\", \"+str(pupil_center[1])+\"]\" )\n",
        "\n",
        "    return int(cx), int(cy), radius, pupil_center[0], pupil_center[1], img5_rgb\n",
        "\n",
        "\n",
        "\n",
        "def center_of_gravity(contours):\n",
        "    coordinate = []\n",
        "    k=0\n",
        "    for c in contours:\n",
        "        mu = cv2.moments(c)\n",
        "        coordinate.append([int(mu[\"m10\"]/mu[\"m00\"]), int(mu[\"m01\"]/mu[\"m00\"])])\n",
        "        print(\"candidate\"+str(k)+\": \"+str(coordinate[k]))\n",
        "        k+=1\n",
        "    return coordinate\n",
        "\n",
        "\n",
        "def nearPoint(coordinates, point):\n",
        "    pupil_coordinate = [0,0]\n",
        "    result = 10000000\n",
        "    for i in coordinates:\n",
        "        distance = int((i[0]-point[0])**2 + (i[1]-point[1])**2)\n",
        "        #print(distance)\n",
        "        if distance < result:\n",
        "            result = distance\n",
        "            pupil_coordinate[0] = i[0]\n",
        "            pupil_coordinate[1] = i[1]\n",
        "    return pupil_coordinate\n",
        "\n",
        "\n"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3pquSMLo26c"
      },
      "source": [
        "#**Google Mediapipeを用いて大まかな虹彩の位置を検出する**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uO6wxOohmkZN",
        "outputId": "3078c4d5-0439-4c8f-d340-dd0544aa9275"
      },
      "source": [
        "os.chdir(\"/content/drive/MyDrive/Deep_learning/Face_Images\")\n",
        "print(os.listdir())\n",
        "img_path = os.listdir()[10]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['IMG_3110.JPG', 'Face_4000x6000.jpg', '.ipynb_checkpoints', 'IMG_3990.JPG', 'IMG_4087.JPG', 'daen_hough.jpg', 'face2.jpg', 'IMG_4108.jpg', 'IMG_4109.jpg', 'IMG_4110.jpg', 'IMG_4111.jpg', 'IMG_4112.jpg']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-4P9240Q7sb"
      },
      "source": [
        "#@title デフォルトのタイトル テキスト\n",
        "# For static images:\n",
        "\n",
        "#img_path = \"/content/drive/MyDrive/Deep_learning/Face_Images/IMG_3990.JPG\"\n",
        "image = cv2.imread(img_path)\n",
        "#cv2_imshow(image)\n",
        "\n",
        "#デバッグ用の画像作成\n",
        "debug_image = copy.deepcopy(image)\n",
        "\n",
        "\n",
        "# 引数 #####################################################################\n",
        "\n",
        "max_num_faces = 1\n",
        "min_detection_confidence = 0.7\n",
        "min_tracking_confidence = 0.7\n",
        "\n",
        "\n",
        "# モデルロード #############################################################\n",
        "face_mesh = FaceMesh(\n",
        "    max_num_faces,\n",
        "    min_detection_confidence,\n",
        "    min_tracking_confidence,\n",
        ")\n",
        "iris_detector = IrisLandmark()\n",
        "\n",
        "# 検出実施 #############################################################\n",
        "# Face Mesh検出\n",
        "face_results = face_mesh(image)\n",
        "for face_result in face_results:\n",
        "    # 目周辺のバウンディングボックス計算\n",
        "    left_eye, right_eye = face_mesh.calc_around_eye_bbox(face_result)\n",
        "\n",
        "    # 虹彩検出\n",
        "    left_iris, right_iris = detect_iris(image, iris_detector, left_eye,\n",
        "                                        right_eye)\n",
        "\n",
        "    # 虹彩の外接円を計算\n",
        "    left_center, left_radius = calc_min_enc_losingCircle(left_iris)\n",
        "    right_center, right_radius = calc_min_enc_losingCircle(right_iris)\n",
        "\n",
        "\"\"\"    \n",
        "    # デバッグ描画\n",
        "    debug_image = copy.deepcopy(image)\n",
        "    debug_image = draw_debug_image(\n",
        "        debug_image,\n",
        "        left_iris,\n",
        "        right_iris,\n",
        "        left_center,\n",
        "        left_radius,\n",
        "        right_center,\n",
        "        right_radius,\n",
        "    )\n",
        "    \n",
        "\n",
        "cv2_imshow(debug_image)\n",
        "cv.destroyAllWindows()\n",
        "\"\"\"\n",
        "print(\"left_center: \"+str(left_center))\n",
        "print(\"left_radius: \"+str(left_radius))\n",
        "print(\"right_center: \"+str(right_center))\n",
        "print(\"right_radius: \"+str(right_radius))\n",
        "\n",
        "\n",
        "seg_img, x0, y0 = eye_segmentation(right_center, right_radius, image)\n",
        "cv2_imshow(seg_img)\n",
        "\n",
        "cx, cy, rad, lx, ly, out_img = hough_segmentation(seg_img)\n",
        "cv2_imshow(out_img)\n",
        "\n",
        "center_x = int(cx + x0)\n",
        "center_y = int(cy + y0)\n",
        "reflex_x = int(lx + x0)\n",
        "reflex_y = int(ly + y0)\n",
        "right_center_2 = [center_x, center_y]\n",
        "right_reflex_2 = [reflex_x, reflex_y]\n",
        "radius = rad\n",
        "\n",
        "print(right_radius)\n",
        "print(\"center: \"+str(right_center_2))\n",
        "print(\"reflex: \"+str(right_reflex_2))\n",
        "print(\"左上: \"+str(rect))\n",
        "\n",
        "#dst = cv2.resize(out_img, dsize=(200, 200),  interpolation=cv2.INTER_LINEAR)\n",
        "\n",
        "\n",
        "# デバッグ描画\n",
        "cv2.circle(debug_image, center=(center_x, center_y), radius=radius, color=(255,0,0), thickness=2)\n",
        "cv2.circle(debug_image, (reflex_x, reflex_y), radius=4, color=(0,255,0), thickness=5)\n",
        "cv2_imshow(debug_image)\n",
        "cv.destroyAllWindows()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UCJIYrvm_Klt",
        "outputId": "cb5855dc-d906-4fd5-940a-ccf33c2d3687"
      },
      "source": [
        "a = (1,2,3)\n",
        "a = (4,5,6)\n",
        "print(a)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4, 5, 6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0t3e7toJ7GXL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}