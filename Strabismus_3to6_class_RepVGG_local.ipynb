{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled31.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ykitaguchi77/Strabismus_AI_project/blob/main/Strabismus_3to6_class_RepVGG_local.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-a4ZBlqPNdU"
      },
      "source": [
        "#**Strabismus: RepVGG_rangerAdabrief**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**3-class to 6-class**"
      ],
      "metadata": {
        "id": "UXJqctl5YZCc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "3-class\n",
        "- cont\n",
        "- exo\n",
        "- eso\n",
        "\n",
        "6-class\n",
        "- exo → exo 1.0\n",
        "- exo-boundary: 1mm前後の外斜視 →　exo 0.5,cont 0.5\n",
        "- cont → cont 1.0\n",
        "- eso-boundary: 1mm前後の内斜視 → eso 0.5, cont 0.5\n",
        "- eso → eso 1.0\n",
        "- inadequate: 周辺視、片眼のみの写真、片眼あるいは両眼の瞳孔が出ていない、眼位写真以外のもの → inadequate 1.0\n",
        "\n",
        "3-classのモデルから転移学習を行う。\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "NWDJ_PhsYfqM",
        "outputId": "989176f6-49fc-4d9e-e6bd-366e05ce3ec2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n3-class\\n- cont\\n- exo\\n- eso\\n\\n6-class\\n- exo → exo 1.0\\n- exo-boundary: 1mm前後の外斜視 →\\u3000exo 0.5,cont 0.5\\n- cont → cont 1.0\\n- eso-boundary: 1mm前後の内斜視 → eso 0.5, cont 0.5\\n- eso → eso 1.0\\n- inadequate: 周辺視、片眼のみの写真、片眼あるいは両眼の瞳孔が出ていない、眼位写真以外のもの → inadequate 1.0\\n\\n3-classのモデルから転移学習を行う。\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgM-Y7SVPNkM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af340003-d84c-4d52-a150-55667541bac5"
      },
      "source": [
        "from __future__ import print_function, division\n",
        "!pip install torch_optimizer\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch_optimizer as optim\n",
        "import torch.utils.data as data\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "import math\n",
        "import shutil\n",
        "import csv\n",
        "import cv2\n",
        "import random\n",
        "import sys\n",
        "\n",
        "#Advanced Pytorchから\n",
        "import glob\n",
        "import os.path as osp\n",
        "import random\n",
        "import json\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "%matplotlib inline\n",
        "\n",
        "plt.ion()   # interactive mode\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Set random seem for reproducibility\n",
        "manualSeed = 1234\n",
        "#manualSeed = random.randint(1, 10000) # use if you want new results\n",
        "print(\"Random Seed: \", manualSeed)\n",
        "random.seed(manualSeed)\n",
        "torch.manual_seed(manualSeed)\n",
        "torch.cuda.manual_seed(manualSeed)\n",
        "\n",
        "torch.torch.backends.cudnn.benchmark = True\n",
        "torch.torch.backends.cudnn.enabled = True\n",
        "\n",
        "\"\"\"                                \n",
        "#サポートパッチのインポート\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "#google driveをcolabolatoryにマウント\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\"\"\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch_optimizer in c:\\users\\ykita\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (0.0.1a13)\n",
            "Requirement already satisfied: torch>=1.1.0 in c:\\users\\ykita\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from torch_optimizer) (1.5.0)\n",
            "Requirement already satisfied: pytorch-ranger>=0.1.1 in c:\\users\\ykita\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from torch_optimizer) (0.1.1)\n",
            "Requirement already satisfied: future in c:\\users\\ykita\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from torch>=1.1.0->torch_optimizer) (0.18.2)\n",
            "Requirement already satisfied: numpy in c:\\users\\ykita\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from torch>=1.1.0->torch_optimizer) (1.18.4)\n",
            "Random Seed:  1234\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"                                \\n#サポートパッチのインポート\\nfrom google.colab.patches import cv2_imshow\\n\\n#google driveをcolabolatoryにマウント\\nfrom google.colab import drive\\ndrive.mount('/content/drive')\\n\""
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**空のデータセットフォルダを作成**"
      ],
      "metadata": {
        "id": "e-XfwYta_lAD"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rg3cJNph6yia",
        "outputId": "ab44086c-8aee-42b9-ef7e-f82222a0b160",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "'''\n",
        "データの構造\n",
        "---Dataset_1to100_eval------ cont\n",
        "                        |--- exo\n",
        "                        |--- eso\n",
        "                        |--- eso-to --- eso-exo\n",
        "                        |            |- eso-cont\n",
        "                        |            |- eso-exo-boundary\n",
        "                        |            |- eso-eso-boundary\n",
        "                        |            |- eso-inadequate\n",
        "                        |--- exo-to --- exo-eso\n",
        "                        |            |- exo-cont\n",
        "                        |            |- exo-exo-boundary\n",
        "                        |            |- exo-eso-boundary\n",
        "                        |            |- exo-inadequate\n",
        "                        |--- cont-to --- cont-eso\n",
        "                        |            |- cont-exo\n",
        "                        |            |- cont-exo-boundary\n",
        "                        |            |- cont-eso-boundary\n",
        "                        |            |- cont-inadequate                         \n",
        "                        |--- corrected --- cont\n",
        "                                        |- exo\n",
        "                                        |- exo-boundary\n",
        "                                        |- eso\n",
        "                                        |- eso-boundary\n",
        "                                        |- inadequate\n",
        "'''"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nデータの構造\\n---Dataset_1to100_eval------ cont\\n                        |--- exo\\n                        |--- eso\\n                        |--- eso-to --- eso-exo\\n                        |            |- eso-cont\\n                        |            |- eso-exo-boundary\\n                        |            |- eso-eso-boundary\\n                        |            |- eso-inadequate\\n                        |--- exo-to --- exo-eso\\n                        |            |- exo-cont\\n                        |            |- exo-exo-boundary\\n                        |            |- exo-eso-boundary\\n                        |            |- exo-inadequate\\n                        |--- cont-to --- cont-eso\\n                        |            |- cont-exo\\n                        |            |- cont-exo-boundary\\n                        |            |- cont-eso-boundary\\n                        |            |- cont-inadequate                         \\n                        |--- corrected --- cont\\n                                        |- exo\\n                                        |- exo-boundary\\n                                        |- eso\\n                                        |- eso-boundary\\n                                        |- inadequate\\n'"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dst_dir = r\"F:\\Strabismus\\Dataset_1to100_eval_test\"\n",
        "\n",
        "def confirm():\n",
        "    dic={'y':True,'yes':True,'n':False,'no':False}\n",
        "    while True:\n",
        "        try:\n",
        "            return dic[input('すでにフォルダがあります。上書きしますか? [Y]es/[N]o >> ').lower()]\n",
        "        except:\n",
        "            pass\n",
        "        print('Error! Input again.')\n",
        "\n",
        "#保存先フォルダを作成\n",
        "if os.path.exists(dst_dir):\n",
        "    if confirm():\n",
        "        shutil.rmtree(dst_dir)\n",
        "    else:\n",
        "        sys.exit()\n",
        "\n",
        "os.makedirs(dst_dir)\n",
        "\n",
        "#作業フォルダの設定\n",
        "os.chdir(dst_dir)\n",
        "\n",
        "#テキストファイルの構造通りにフォルダを作成する\n",
        "#参考サイト：https://fastclassinfo.com/entry/python_makefolders/\n",
        "#プログラム1｜ライブラリの設定\n",
        "#import os\n",
        " \n",
        "#プログラム2｜フォルダパスの取得\n",
        "path = r\"F:\\Strabismus\\eval_folder_tree.txt\"\n",
        "fullpath = os.getcwd()\n",
        " \n",
        "#プログラム3｜ファイル格納リスト\n",
        "folderlist = []\n",
        " \n",
        "#プログラム4｜テキストファイル内のデータをリストへ格納\n",
        "with open(path, encoding='shift-jis') as lines:\n",
        "    for line in lines:\n",
        "        line = line.replace('\\n','')\n",
        "        folderlist.append(line.split('\\t'))\n",
        " \n",
        "#プログラム5｜作成したいフォルダを1つずつ編集\n",
        "for i, folders in enumerate(folderlist):\n",
        "    list1 = []\n",
        " \n",
        "    #プログラム6｜データがなければ、一つ前のパスを入れる\n",
        "    for j, folder in enumerate(folders):\n",
        "        if folder != '':\n",
        "            list1.append(folderlist[i][j])\n",
        "        else:\n",
        "            list1.append(folderlist[i-1][j])\n",
        "    folderlist[i] = list1\n",
        " \n",
        "    #プログラム7｜folderpathにフルパスを作る\n",
        "    folderpath = fullpath +'\\\\' + '\\\\'.join(folderlist[i])\n",
        "    \n",
        "    # プログラム8｜同じ名前のフォルダが存在しなければ、フォルダを作成\n",
        "    if os.path.exists(folderpath) == False:\n",
        "        os.makedirs(folderpath)\n",
        "\n",
        "os.listdir()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "SnIvaUAI_44K",
        "outputId": "baf3832a-e020-478d-d887-dd6c5d16d27f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "すでにフォルダがあります。上書きしますか? [Y]es/[N]o >> n\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "ignored",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[1;31mSystemExit\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "c:\\users\\ykita\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3339: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
            "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ファイル数をカウント"
      ],
      "metadata": {
        "id": "T7jkALUAWMtM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#それぞれの症例数をカウント\n",
        "def count(arg):\n",
        "    #print(arg)\n",
        "    dir = os.getcwd()\n",
        "    #print(glob.glob(dir+\"/**/\"+arg,recursive=True))\n",
        "    files_dir = glob.glob(dir+\"/**/\"+arg+\"/*\",recursive=True)\n",
        "    count = (len([name for name in files_dir if os.path.isfile(name)]))\n",
        "    #print(count)\n",
        "    #print(\"\")\n",
        "    return count\n",
        "\n",
        "dst_dir = r\"F:\\Strabismus\\Dataset_1to100_eval\"\n",
        "os.chdir(dst_dir)\n",
        "\n",
        "cont_num = count(\"cont\") + count(\"exo_cont\") + count(\"eso_cont\") + count(\"exo_boundary_cont\")+ count(\"eso_boundary_cont\") + count(\"inadequate_cont\")\n",
        "exo_num = count(\"exo\") + count(\"cont_exo\") + count(\"eso_exo\") + count(\"exo_boundary_exo\") + count(\"eso_boundary_exo\")+ count(\"inadequate_exo\")\n",
        "eso_num = count(\"eso\") + count(\"cont_eso\") + count(\"exo_eso\") + count(\"exo_boundary_eso\") + count(\"eso_boundary_eso\") +count(\"inadequate_eso\")\n",
        "eso_boundary_num = count(\"eso_boundary\") + count(\"cont_eso_boundary\") + count(\"exo_eso_boundary\")+ count(\"eso_eso_boundary\") + count(\"exo_boundary_eso_boundary\") + count(\"inadequate_eso_boundary\")\n",
        "exo_boundary_num = count(\"exo_boundary\") + count(\"cont_exo_boundary\") + count(\"exo_exo_boundary\")+ count(\"eso_exo_boundary\") + count(\"eso_boundary_exo_boundary\") + count(\"inadequate_exo_boundary\")\n",
        "inadequate_num = count(\"inadequate\") + count(\"exo_inadequate\") + count(\"eso_inadequate\") + count(\"cont_inadequate\")+ count(\"exo_boundary_inadequate\") + count(\"eso_boundary_inadequate\")\n",
        "\n",
        "print(\"cont: \"+str(cont_num))\n",
        "print(\"exo: \"+str(exo_num))\n",
        "print(\"eso: \"+str(eso_num))\n",
        "print(\"exo_boundary: \"+str(exo_boundary_num))\n",
        "print(\"eso_boundary: \"+str(eso_boundary_num))\n",
        "print(\"inadequate: \"+str(inadequate_num))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SgKpDDI9mKs7",
        "outputId": "bc7dd15b-e292-49bd-9bde-d4656fedd52e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cont: 357\n",
            "exo: 42\n",
            "eso: 124\n",
            "exo_boundary: 58\n",
            "eso_boundary: 25\n",
            "inadequate: 213\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#それぞれからcorrectフォルダに移すスクリプトが必要（後で書く）"
      ],
      "metadata": {
        "id": "I0En7ysfVkjY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jzp_09fWPNoU"
      },
      "source": [
        "#**モジュール群**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7sJV06qPNsM",
        "outputId": "f9ae6001-7184-4ffb-e059-da2407e3aa95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "data_dir = r\"F:\\Strabismus\\Dataset_1to100_eval\\corrected\"\n",
        "\n",
        "dataset = datasets.ImageFolder(data_dir)\n",
        "print(dataset.classes)\n",
        "print(dataset.class_to_idx)\n",
        "\n",
        "\n",
        "# 入力画像の前処理をするクラス\n",
        "# 訓練時と推論時で処理が異なる\n",
        "\n",
        "\"\"\"\n",
        "    画像の前処理クラス。訓練時、検証時で異なる動作をする。\n",
        "    画像のサイズをリサイズし、色を標準化する。\n",
        "    訓練時はRandomResizedCropとRandomHorizontalFlipでデータオーギュメンテーションする。\n",
        "\n",
        "\n",
        "    Attributes\n",
        "    ----------\n",
        "    resize : int\n",
        "        リサイズ先の画像の大きさ。\n",
        "    mean : (R, G, B)\n",
        "        各色チャネルの平均値。\n",
        "    std : (R, G, B)\n",
        "        各色チャネルの標準偏差。\n",
        "\"\"\"\n",
        "class Expand2square(object):\n",
        "    \"\"\"\n",
        "    長方形の元画像を長辺を1辺とする正方形に貼り付け、空白を黒く塗りつぶす\n",
        "    \"\"\"\n",
        "    def __init__(self, background_color):\n",
        "        self.background_color = background_color\n",
        "\n",
        "    def __call__(self, pil_img):\n",
        "        width, height = pil_img.size\n",
        "        if width == height:\n",
        "            return pil_img\n",
        "        elif width > height:\n",
        "            result = Image.new(pil_img.mode, (width, width), self.background_color)\n",
        "            result.paste(pil_img, (0, (width-height)//2))\n",
        "            return result\n",
        "        else:\n",
        "            result = Image.new(pil_img.mode, (height, height), self.background_color)\n",
        "            result.paste(pil_img, (0, (height - width) // 2))\n",
        "            return result\n",
        "\n",
        "\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "        Expand2square((0,0,0)),\n",
        "        transforms.RandomResizedCrop(224, scale=(0.85,1.0)), \n",
        "        transforms.RandomHorizontalFlip(),     \n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "val_transform = transforms.Compose([\n",
        "        Expand2square((0,0,0)),\n",
        "        transforms.Resize(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "test_transform = transforms.Compose([\n",
        "        Expand2square((0,0,0)),\n",
        "        transforms.Resize(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#データセットをシャッフルして分割\n",
        "#https://qiita.com/sin9270/items/c6023453e00bfead9e9f\n",
        "#https://pystyle.info/pytorch-split-dataset/\n",
        "\n",
        "\n",
        "class MySubset(torch.utils.data.Dataset):\n",
        "    def __init__(self, dataset, indices, transform=None):\n",
        "        self.dataset = dataset\n",
        "        self.indices = indices\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img, label = self.dataset[self.indices[idx]]\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        return img, label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.indices)\n",
        "\n",
        "\n",
        "\n",
        "# Train:val:testに 7:2:1 の割合で分割する(ランダムに分割）。\n",
        "\n",
        "train_size = int(0.7 * len(dataset))\n",
        "train_val_size = int(0.9 * len(dataset))\n",
        "indices = np.arange(len(dataset))\n",
        "np.random.shuffle(indices)\n",
        "\n",
        "train_dataset = MySubset(dataset, indices[:train_size], train_transform)\n",
        "val_dataset = MySubset(dataset, indices[train_size:train_val_size], val_transform)\n",
        "test_dataset = MySubset(dataset, indices[train_val_size:], test_transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size = 4, shuffle = True)\n",
        "val_loader = DataLoader(val_dataset, batch_size = 4, shuffle = True)\n",
        "test_loader = DataLoader(test_dataset, batch_size = 1, shuffle = False)\n",
        "\n",
        "#class_names = [f for f in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, f))]\n",
        "class_names = dataset.classes\n",
        "\n",
        "print(f\"full: {len(dataset)} -> train: {len(train_dataset)}, val: {len(val_dataset)},test: {len(test_dataset)}\")\n",
        "print(\"class_names -> \"+str(dataset.classes))\n",
        "\n",
        "\n",
        "\n",
        "#少数の画像を可視化\n",
        "def imshow(inp, title=None):\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    inp = std * inp + mean\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "    plt.imshow(inp)\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
        "\n",
        "\n",
        "# Get a batch of training data\n",
        "inputs, classes = next(iter(train_loader))\n",
        "\n",
        "# Make a grid from batch\n",
        "out = torchvision.utils.make_grid(inputs)\n",
        "\n",
        "imshow(out, title=[class_names[x] for x in classes])\n",
        "\n",
        "\n",
        "#Defining early stopping class\n",
        "\n",
        "class EarlyStopping:\n",
        "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
        "    def __init__(self, patience=7, verbose=False, delta=0):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            patience (int): How long to wait after last time validation loss improved.\n",
        "                            Default: 7\n",
        "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
        "                            Default: False\n",
        "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
        "                            Default: 0\n",
        "        \"\"\"\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.val_loss_min = np.Inf\n",
        "        self.delta = delta\n",
        "\n",
        "    def __call__(self, val_loss, model):\n",
        "\n",
        "        score = -val_loss\n",
        "\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "            self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, val_loss, model):\n",
        "        '''Saves model when validation loss decrease.'''\n",
        "        if self.verbose:\n",
        "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
        "        torch.save(model.state_dict(), 'checkpoint.pt')\n",
        "        self.val_loss_min = val_loss\n",
        "\n",
        "\n",
        "#Train models\n",
        "def train_model(model, criterion, optimizer, patience, num_epochs):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    # to track the training loss as the model trains\n",
        "    train_losses = []\n",
        "    # to track the validation loss as the model trains\n",
        "    valid_losses = []\n",
        "    # to track the average training loss per epoch as the model trains\n",
        "    avg_train_losses = []\n",
        "    # to track the average validation loss per epoch as the model trains\n",
        "    avg_valid_losses = [] \n",
        "\n",
        "\n",
        "    # initialize the early_stopping object\n",
        "    early_stopping = EarlyStopping(patience=patience, verbose=True)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
        "        print('-' * 10)\n",
        "\n",
        "        ###################\n",
        "        # train the model #\n",
        "        ###################\n",
        "        model.train() # Set model to training mode\n",
        "        \n",
        "        running_corrects, train_acc= 0, 0\n",
        "\n",
        "        # Iterate over data.\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward\n",
        "            # track history if only in train\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            loss = criterion(outputs, labels)\n",
        "            \n",
        "            \"\"\"\n",
        "            print(\"labels:\"+str(labels))\n",
        "            print(\"outputs: \"+str(outputs))\n",
        "            print(\"preds: \"+str(preds))\n",
        "            print(\"loss: \"+str(loss))\n",
        "            \"\"\"\n",
        "\n",
        "            # backward + optimize only if in training phase\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # record training loss\n",
        "            train_losses.append(loss.item())\n",
        "\n",
        "            running_corrects += torch.sum(preds==labels)\n",
        "\n",
        "            \"\"\"\n",
        "            print(\"preds:\"+str(preds))\n",
        "            print(\"labels:\"+str(labels))\n",
        "            print(\"running_corrects: \"+str(str(running_corrects)))\n",
        "            \"\"\"\n",
        "            \n",
        "        print()   \n",
        "        train_acc = running_corrects.item()/len(train_dataset)\n",
        "\n",
        "        #####################\n",
        "        # validate the model#\n",
        "        #####################\n",
        "\n",
        "        model.eval()   # Set model to evaluate mode\n",
        "\n",
        "        running_corrects, val_acc= 0, 0\n",
        "\n",
        "        # Iterate over data.\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward\n",
        "            # track history if only in train\n",
        "            with torch.no_grad():\n",
        "                outputs = model(inputs)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                loss = criterion(outputs, labels)\n",
        "           \n",
        "            \"\"\"\n",
        "            print(\"preds:\"+str(preds))\n",
        "            print(\"labels:\"+str(labels))\n",
        "            print(\"running_corrects: \"+str(str(running_corrects)))\n",
        "            \"\"\"\n",
        "\n",
        "            valid_losses.append(loss.item())\n",
        "\n",
        "            running_corrects += torch.sum(preds==labels)\n",
        "        val_acc = running_corrects.item()/len(val_dataset)\n",
        "\n",
        "\n",
        "\n",
        "        #####################\n",
        "        # test the model#\n",
        "        #####################\n",
        "\n",
        "        model.eval()   # Set model to evaluate mode\n",
        "\n",
        "        running_corrects, test_acc= 0, 0\n",
        "\n",
        "        # Iterate over data.\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward\n",
        "            # track history if only in train\n",
        "            with torch.no_grad():\n",
        "                outputs = model(inputs)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "           \n",
        "            \"\"\"\n",
        "            print(\"preds:\"+str(preds))\n",
        "            print(\"labels:\"+str(labels))\n",
        "            print(\"running_corrects: \"+str(str(running_corrects)))\n",
        "            \"\"\"\n",
        "            running_corrects += torch.sum(preds==labels)\n",
        "        test_acc = running_corrects.item()/len(test_dataset)\n",
        "\n",
        "\n",
        "\n",
        "        # print training/validation statistics \n",
        "        # calculate average loss over an epoch\n",
        "        train_loss = np.average(train_losses)\n",
        "        valid_loss = np.average(valid_losses)\n",
        "        avg_train_losses.append(train_loss)\n",
        "        avg_valid_losses.append(valid_loss)\n",
        "        \n",
        "        epoch_len = len(str(num_epochs))\n",
        "        \n",
        "        print_msg = (f'Epoch: [{epoch:>{epoch_len}}/{num_epochs:>{epoch_len}}] ' +'\\n'\n",
        "                     f'train_loss: {train_loss:.5f} ' +\n",
        "                     f'train_acc: {train_acc:.5f}' +'\\n'\n",
        "                     f'valid_loss: {valid_loss:.5f} ' +\n",
        "                     f'valid_acc: {val_acc:.5f}' +'\\n'\n",
        "                     f'test_acc: {test_acc:.5f}') \n",
        "\n",
        "        \n",
        "        print(print_msg)\n",
        "        \n",
        "        # clear lists to track next epoch\n",
        "        train_losses = []\n",
        "        valid_losses = []\n",
        "        \n",
        "        # early_stopping needs the validation loss to check if it has decresed, \n",
        "        # and if it has, it will make a checkpoint of the current model\n",
        "        early_stopping(valid_loss, model)\n",
        "        \n",
        "        if early_stopping.early_stop:\n",
        "            print(\"Early stopping\")\n",
        "            break\n",
        "        \n",
        "        print('')\n",
        "\n",
        "    # load the last checkpoint with the best model\n",
        "    model.load_state_dict(torch.load('checkpoint.pt'))\n",
        "\n",
        "    return model, avg_train_losses, avg_valid_losses\n",
        "\n",
        "\n",
        "\n",
        "#Visualize model\n",
        "def visualize_model(model, num_images=6):\n",
        "    was_training = model.training\n",
        "    model.eval()\n",
        "    images_so_far = 0\n",
        "    fig = plt.figure()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, labels) in enumerate(val_loader):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            for j in range(inputs.size()[0]):\n",
        "                images_so_far += 1\n",
        "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
        "                ax.axis('off')\n",
        "                ax.set_title('predicted: {}'.format(class_names[preds[j]]))\n",
        "                imshow(inputs.cpu().data[j])\n",
        "\n",
        "                if images_so_far == num_images:\n",
        "                    model.train(mode=was_training)\n",
        "                    return\n",
        "        model.train(mode=was_training)\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['corrected_cont', 'corrected_eso', 'corrected_eso-boundary', 'corrected_exo', 'corrected_exo-boundary', 'corrected_inadequate']\n",
            "{'corrected_cont': 0, 'corrected_eso': 1, 'corrected_eso-boundary': 2, 'corrected_exo': 3, 'corrected_exo-boundary': 4, 'corrected_inadequate': 5}\n",
            "full: 844 -> train: 590, val: 169,test: 85\n",
            "class_names -> ['corrected_cont', 'corrected_eso', 'corrected_eso-boundary', 'corrected_exo', 'corrected_exo-boundary', 'corrected_inadequate']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UDaWr9bLXpAz"
      },
      "source": [
        "#**Define RepVGG**\n",
        "https://github.com/DingXiaoH/RepVGG"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HW9Kd5meE3JK"
      },
      "source": [
        "def conv_bn(in_channels, out_channels, kernel_size, stride, padding, groups=1):\n",
        "    result = nn.Sequential()\n",
        "    result.add_module('conv', nn.Conv2d(in_channels=in_channels, out_channels=out_channels,\n",
        "                                                  kernel_size=kernel_size, stride=stride, padding=padding, groups=groups, bias=False))\n",
        "    result.add_module('bn', nn.BatchNorm2d(num_features=out_channels))\n",
        "    return result\n",
        "\n",
        "class RepVGGBlock(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, kernel_size,\n",
        "                 stride=1, padding=0, dilation=1, groups=1, padding_mode='zeros', deploy=False):\n",
        "        super(RepVGGBlock, self).__init__()\n",
        "        self.deploy = deploy\n",
        "        self.groups = groups\n",
        "        self.in_channels = in_channels\n",
        "\n",
        "        assert kernel_size == 3\n",
        "        assert padding == 1\n",
        "\n",
        "        padding_11 = padding - kernel_size // 2\n",
        "\n",
        "        self.nonlinearity = nn.ReLU()\n",
        "\n",
        "        if deploy:\n",
        "            self.rbr_reparam = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride,\n",
        "                                      padding=padding, dilation=dilation, groups=groups, bias=True, padding_mode=padding_mode)\n",
        "\n",
        "        else:\n",
        "            self.rbr_identity = nn.BatchNorm2d(num_features=in_channels) if out_channels == in_channels and stride == 1 else None\n",
        "            self.rbr_dense = conv_bn(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=padding, groups=groups)\n",
        "            self.rbr_1x1 = conv_bn(in_channels=in_channels, out_channels=out_channels, kernel_size=1, stride=stride, padding=padding_11, groups=groups)\n",
        "            print('RepVGG Block, identity = ', self.rbr_identity)\n",
        "\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        if hasattr(self, 'rbr_reparam'):\n",
        "            return self.nonlinearity(self.rbr_reparam(inputs))\n",
        "\n",
        "        if self.rbr_identity is None:\n",
        "            id_out = 0\n",
        "        else:\n",
        "            id_out = self.rbr_identity(inputs)\n",
        "\n",
        "        return self.nonlinearity(self.rbr_dense(inputs) + self.rbr_1x1(inputs) + id_out)\n",
        "\n",
        "\n",
        "\n",
        "#   This func derives the equivalent kernel and bias in a DIFFERENTIABLE way.\n",
        "#   You can get the equivalent kernel and bias at any time and do whatever you want,\n",
        "    #   for example, apply some penalties or constraints during training, just like you do to the other models.\n",
        "#   May be useful for quantization or pruning.\n",
        "    def get_equivalent_kernel_bias(self):\n",
        "        kernel3x3, bias3x3 = self._fuse_bn_tensor(self.rbr_dense)\n",
        "        kernel1x1, bias1x1 = self._fuse_bn_tensor(self.rbr_1x1)\n",
        "        kernelid, biasid = self._fuse_bn_tensor(self.rbr_identity)\n",
        "        return kernel3x3 + self._pad_1x1_to_3x3_tensor(kernel1x1) + kernelid, bias3x3 + bias1x1 + biasid\n",
        "\n",
        "    def _pad_1x1_to_3x3_tensor(self, kernel1x1):\n",
        "        if kernel1x1 is None:\n",
        "            return 0\n",
        "        else:\n",
        "            return torch.nn.functional.pad(kernel1x1, [1,1,1,1])\n",
        "\n",
        "    def _fuse_bn_tensor(self, branch):\n",
        "        if branch is None:\n",
        "            return 0, 0\n",
        "        if isinstance(branch, nn.Sequential):\n",
        "            kernel = branch.conv.weight\n",
        "            running_mean = branch.bn.running_mean\n",
        "            running_var = branch.bn.running_var\n",
        "            gamma = branch.bn.weight\n",
        "            beta = branch.bn.bias\n",
        "            eps = branch.bn.eps\n",
        "        else:\n",
        "            assert isinstance(branch, nn.BatchNorm2d)\n",
        "            if not hasattr(self, 'id_tensor'):\n",
        "                input_dim = self.in_channels // self.groups\n",
        "                kernel_value = np.zeros((self.in_channels, input_dim, 3, 3), dtype=np.float32)\n",
        "                for i in range(self.in_channels):\n",
        "                    kernel_value[i, i % input_dim, 1, 1] = 1\n",
        "                self.id_tensor = torch.from_numpy(kernel_value).to(branch.weight.device)\n",
        "            kernel = self.id_tensor\n",
        "            running_mean = branch.running_mean\n",
        "            running_var = branch.running_var\n",
        "            gamma = branch.weight\n",
        "            beta = branch.bias\n",
        "            eps = branch.eps\n",
        "        std = (running_var + eps).sqrt()\n",
        "        t = (gamma / std).reshape(-1, 1, 1, 1)\n",
        "        return kernel * t, beta - running_mean * gamma / std\n",
        "\n",
        "    def repvgg_convert(self):\n",
        "        kernel, bias = self.get_equivalent_kernel_bias()\n",
        "        return kernel.detach().cpu().numpy(), bias.detach().cpu().numpy(),\n",
        "\n",
        "\n",
        "\n",
        "class RepVGG(nn.Module):\n",
        "\n",
        "    def __init__(self, num_blocks, num_classes=1000, width_multiplier=None, override_groups_map=None, deploy=False):\n",
        "        super(RepVGG, self).__init__()\n",
        "\n",
        "        assert len(width_multiplier) == 4\n",
        "\n",
        "        self.deploy = deploy\n",
        "        self.override_groups_map = override_groups_map or dict()\n",
        "\n",
        "        assert 0 not in self.override_groups_map\n",
        "\n",
        "        self.in_planes = min(64, int(64 * width_multiplier[0]))\n",
        "\n",
        "        self.stage0 = RepVGGBlock(in_channels=3, out_channels=self.in_planes, kernel_size=3, stride=2, padding=1, deploy=self.deploy)\n",
        "        self.cur_layer_idx = 1\n",
        "        self.stage1 = self._make_stage(int(64 * width_multiplier[0]), num_blocks[0], stride=2)\n",
        "        self.stage2 = self._make_stage(int(128 * width_multiplier[1]), num_blocks[1], stride=2)\n",
        "        self.stage3 = self._make_stage(int(256 * width_multiplier[2]), num_blocks[2], stride=2)\n",
        "        self.stage4 = self._make_stage(int(512 * width_multiplier[3]), num_blocks[3], stride=2)\n",
        "        self.gap = nn.AdaptiveAvgPool2d(output_size=1)\n",
        "        self.linear = nn.Linear(int(512 * width_multiplier[3]), num_classes)\n",
        "\n",
        "\n",
        "    def _make_stage(self, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        blocks = []\n",
        "        for stride in strides:\n",
        "            cur_groups = self.override_groups_map.get(self.cur_layer_idx, 1)\n",
        "            blocks.append(RepVGGBlock(in_channels=self.in_planes, out_channels=planes, kernel_size=3,\n",
        "                                      stride=stride, padding=1, groups=cur_groups, deploy=self.deploy))\n",
        "            self.in_planes = planes\n",
        "            self.cur_layer_idx += 1\n",
        "        return nn.Sequential(*blocks)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.stage0(x)\n",
        "        out = self.stage1(out)\n",
        "        out = self.stage2(out)\n",
        "        out = self.stage3(out)\n",
        "        out = self.stage4(out)\n",
        "        out = self.gap(out)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "optional_groupwise_layers = [2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26]\n",
        "g2_map = {l: 2 for l in optional_groupwise_layers}\n",
        "g4_map = {l: 4 for l in optional_groupwise_layers}\n",
        "\n",
        "def create_RepVGG_A0(deploy=False):\n",
        "    return RepVGG(num_blocks=[2, 4, 14, 1], num_classes=1000,\n",
        "                  width_multiplier=[0.75, 0.75, 0.75, 2.5], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_A1(deploy=False):\n",
        "    return RepVGG(num_blocks=[2, 4, 14, 1], num_classes=1000,\n",
        "                  width_multiplier=[1, 1, 1, 2.5], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_A2(deploy=False):\n",
        "    return RepVGG(num_blocks=[2, 4, 14, 1], num_classes=1000,\n",
        "                  width_multiplier=[1.5, 1.5, 1.5, 2.75], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B0(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[1, 1, 1, 2.5], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B1(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2, 2, 2, 4], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B1g2(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2, 2, 2, 4], override_groups_map=g2_map, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B1g4(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2, 2, 2, 4], override_groups_map=g4_map, deploy=deploy)\n",
        "\n",
        "\n",
        "def create_RepVGG_B2(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2.5, 2.5, 2.5, 5], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B2g2(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2.5, 2.5, 2.5, 5], override_groups_map=g2_map, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B2g4(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[2.5, 2.5, 2.5, 5], override_groups_map=g4_map, deploy=deploy)\n",
        "\n",
        "\n",
        "def create_RepVGG_B3(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[3, 3, 3, 5], override_groups_map=None, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B3g2(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[3, 3, 3, 5], override_groups_map=g2_map, deploy=deploy)\n",
        "\n",
        "def create_RepVGG_B3g4(deploy=False):\n",
        "    return RepVGG(num_blocks=[4, 6, 16, 1], num_classes=1000,\n",
        "                  width_multiplier=[3, 3, 3, 5], override_groups_map=g4_map, deploy=deploy)\n",
        "\n",
        "\n",
        "func_dict = {\n",
        "'RepVGG-A0': create_RepVGG_A0,\n",
        "'RepVGG-A1': create_RepVGG_A1,\n",
        "'RepVGG-A2': create_RepVGG_A2,\n",
        "'RepVGG-B0': create_RepVGG_B0,\n",
        "'RepVGG-B1': create_RepVGG_B1,\n",
        "'RepVGG-B1g2': create_RepVGG_B1g2,\n",
        "'RepVGG-B1g4': create_RepVGG_B1g4,\n",
        "'RepVGG-B2': create_RepVGG_B2,\n",
        "'RepVGG-B2g2': create_RepVGG_B2g2,\n",
        "'RepVGG-B2g4': create_RepVGG_B2g4,\n",
        "'RepVGG-B3': create_RepVGG_B3,\n",
        "'RepVGG-B3g2': create_RepVGG_B3g2,\n",
        "'RepVGG-B3g4': create_RepVGG_B3g4,\n",
        "}\n",
        "def get_RepVGG_func_by_name(name):\n",
        "    return func_dict[name]\n",
        "\n",
        "\n",
        "\n",
        "#   Use this for converting a customized model with RepVGG as one of its components (e.g., the backbone of a semantic segmentation model)\n",
        "#   The use case will be like\n",
        "#   1.  Build train_model. For example, build a PSPNet with a training-time RepVGG as backbone\n",
        "#   2.  Train train_model or do whatever you want\n",
        "#   3.  Build deploy_model. In the above example, that will be a PSPNet with an inference-time RepVGG as backbone\n",
        "#   4.  Call this func\n",
        "#   ====================== the pseudo code will be like\n",
        "#   train_backbone = create_RepVGG_B2(deploy=False)\n",
        "#   train_backbone.load_state_dict(torch.load('RepVGG-B2-train.pth'))\n",
        "#   train_pspnet = build_pspnet(backbone=train_backbone)\n",
        "#   segmentation_train(train_pspnet)\n",
        "#   deploy_backbone = create_RepVGG_B2(deploy=True)\n",
        "#   deploy_pspnet = build_pspnet(backbone=deploy_backbone)\n",
        "#   whole_model_convert(train_pspnet, deploy_pspnet)\n",
        "#   segmentation_test(deploy_pspnet)\n",
        "def whole_model_convert(train_model:torch.nn.Module, deploy_model:torch.nn.Module, save_path=None):\n",
        "    all_weights = {}\n",
        "    for name, module in train_model.named_modules():\n",
        "        if hasattr(module, 'repvgg_convert'):\n",
        "            kernel, bias = module.repvgg_convert()\n",
        "            all_weights[name + '.rbr_reparam.weight'] = kernel\n",
        "            all_weights[name + '.rbr_reparam.bias'] = bias\n",
        "            print('convert RepVGG block')\n",
        "        else:\n",
        "            for p_name, p_tensor in module.named_parameters():\n",
        "                full_name = name + '.' + p_name\n",
        "                if full_name not in all_weights:\n",
        "                    all_weights[full_name] = p_tensor.detach().cpu().numpy()\n",
        "            for p_name, p_tensor in module.named_buffers():\n",
        "                full_name = name + '.' + p_name\n",
        "                if full_name not in all_weights:\n",
        "                    all_weights[full_name] = p_tensor.cpu().numpy()\n",
        "\n",
        "    deploy_model.load_state_dict(all_weights)\n",
        "    if save_path is not None:\n",
        "        torch.save(deploy_model.state_dict(), save_path)\n",
        "\n",
        "    return deploy_model\n",
        "\n",
        "\n",
        "#   Use this when converting a RepVGG without customized structures.\n",
        "#   train_model = create_RepVGG_A0(deploy=False)\n",
        "#   train train_model\n",
        "#   deploy_model = repvgg_convert(train_model, create_RepVGG_A0, save_path='repvgg_deploy.pth')\n",
        "def repvgg_model_convert(model:torch.nn.Module, build_func, save_path=None):\n",
        "    converted_weights = {}\n",
        "    for name, module in model.named_modules():\n",
        "        if hasattr(module, 'repvgg_convert'):\n",
        "            kernel, bias = module.repvgg_convert()\n",
        "            converted_weights[name + '.rbr_reparam.weight'] = kernel\n",
        "            converted_weights[name + '.rbr_reparam.bias'] = bias\n",
        "        elif isinstance(module, torch.nn.Linear):\n",
        "            converted_weights[name + '.weight'] = module.weight.detach().cpu().numpy()\n",
        "            converted_weights[name + '.bias'] = module.bias.detach().cpu().numpy()\n",
        "    del model\n",
        "\n",
        "    deploy_model = build_func(deploy=True)\n",
        "    for name, param in deploy_model.named_parameters():\n",
        "        print('deploy param: ', name, param.size(), np.mean(converted_weights[name]))\n",
        "        param.data = torch.from_numpy(converted_weights[name]).float()\n",
        "\n",
        "    if save_path is not None:\n",
        "        torch.save(deploy_model.state_dict(), save_path)\n",
        "\n",
        "    return deploy_model"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "226jazomBPzw"
      },
      "source": [
        "#RepVGG-A2のpretrained modelをダウンロード(1回ダウンロードすればあとは省略可)\n",
        "import requests\n",
        "\n",
        "def download_file_from_google_drive(id, destination):\n",
        "    URL = \"https://docs.google.com/uc?export=download\"\n",
        "\n",
        "    session = requests.Session()\n",
        "\n",
        "    response = session.get(URL, params = { 'id' : id }, stream = True)\n",
        "    token = get_confirm_token(response)\n",
        "\n",
        "    if token:\n",
        "        params = { 'id' : id, 'confirm' : token }\n",
        "        response = session.get(URL, params = params, stream = True)\n",
        "\n",
        "    save_response_content(response, destination)    \n",
        "\n",
        "def get_confirm_token(response):\n",
        "    for key, value in response.cookies.items():\n",
        "        if key.startswith('download_warning'):\n",
        "            return value\n",
        "\n",
        "    return None\n",
        "\n",
        "def save_response_content(response, destination):\n",
        "    CHUNK_SIZE = 32768\n",
        "\n",
        "    with open(destination, \"wb\") as f:\n",
        "        for chunk in response.iter_content(CHUNK_SIZE):\n",
        "            if chunk: # filter out keep-alive new chunks\n",
        "                f.write(chunk)\n",
        "\n",
        "file_id = '1PvtYTOX4gd-1VHX8LoT7s6KIyfTKOf8G'\n",
        "destination = r\"F:\\Strabismus/RepVGG-A2.pth\"\n",
        "download_file_from_google_drive(file_id, destination)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_APCDCmTE3PZ",
        "outputId": "84a403f4-36cb-479a-8891-3f73881f83b9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#deploy RepVGG-A2\n",
        "\"\"\"\n",
        "train_model = create_RepVGG_A2(deploy=False)\n",
        "train_model.load_state_dict(torch.load('/content/drive/MyDrive/Deep_learning/RepVGG-A2-train.pth'))   \n",
        "model_ft = repvgg_model_convert(train_model, create_RepVGG_A2, save_path='/content/drive/MyDrive/Deep_learning/repvgg-A2-deploy.pth')\n",
        "\"\"\"\n",
        "model_ft = create_RepVGG_A2(deploy=False)\n",
        "\n",
        "#use pretrained model\n",
        "model_ft.load_state_dict(torch.load(r\"F:\\Strabismus/RepVGG-A2.pth\"))   \n",
        "#model_ft.load_state_dict(torch.load('/content/RepVGG-A2.pth'))   \n",
        "num_ftrs = model_ft.linear.in_features\n",
        "model_ft.linear = nn.Linear(num_ftrs, 6)\n",
        "\n",
        "\n",
        "#GPU使用\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "#損失関数を定義\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "#https://blog.knjcode.com/adabound-memo/\n",
        "#https://pypi.org/project/torch-optimizer/\n",
        "\n",
        "!pip install ranger-adabelief==0.1.0\n",
        "from ranger_adabelief import RangerAdaBelief\n",
        "optimizer_ft = RangerAdaBelief(model_ft.parameters(), lr=1e-3, eps=1e-12, betas=(0.9,0.999))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "RepVGG Block, identity =  None\n",
            "Requirement already satisfied: ranger-adabelief==0.1.0 in c:\\users\\ykita\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (0.1.0)\n",
            "Requirement already satisfied: torch>=0.4.0 in c:\\users\\ykita\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from ranger-adabelief==0.1.0) (1.5.0)\n",
            "Requirement already satisfied: numpy in c:\\users\\ykita\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from torch>=0.4.0->ranger-adabelief==0.1.0) (1.18.4)\n",
            "Requirement already satisfied: future in c:\\users\\ykita\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from torch>=0.4.0->ranger-adabelief==0.1.0) (0.18.2)\n",
            "Ranger optimizer loaded. \n",
            "Gradient Centralization usage = True\n",
            "GC applied to both conv and fc layers\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BeHuwTdcJcDj"
      },
      "source": [
        "\"#モデルのサマリー（省略可）\n",
        "from torchsummary import summary\n",
        "model_ft.to(device)\n",
        "summary(model_ft, (3, 224, 224))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yGBXuY1JlOY"
      },
      "source": [
        "#モデルの表示（省略可）\n",
        "print(model_ft)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fvx3RgvOPNv0"
      },
      "source": [
        "#**Convnetの調整**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1du9txkSPN20"
      },
      "source": [
        "#**訓練と評価**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UpcgsmxPN6l",
        "outputId": "fe09fe2e-c338-4eb7-e4ed-618ad6fb851f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model_ft, train_loss, valid_loss = train_model(model_ft, criterion, optimizer_ft,  patience=30, num_epochs=150)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "----------\n",
            "\n",
            "Epoch: [  0/150] \n",
            "train_loss: 1.13521 train_acc: 0.60508\n",
            "valid_loss: 0.90446 valid_acc: 0.71598\n",
            "test_acc: 0.65882\n",
            "Validation loss decreased (inf --> 0.904461).  Saving model ...\n",
            "\n",
            "Epoch 2/150\n",
            "----------\n",
            "\n",
            "Epoch: [  1/150] \n",
            "train_loss: 0.97626 train_acc: 0.68644\n",
            "valid_loss: 0.80953 valid_acc: 0.71598\n",
            "test_acc: 0.68235\n",
            "Validation loss decreased (0.904461 --> 0.809526).  Saving model ...\n",
            "\n",
            "Epoch 3/150\n",
            "----------\n",
            "\n",
            "Epoch: [  2/150] \n",
            "train_loss: 0.81161 train_acc: 0.72712\n",
            "valid_loss: 0.79026 valid_acc: 0.76331\n",
            "test_acc: 0.71765\n",
            "Validation loss decreased (0.809526 --> 0.790256).  Saving model ...\n",
            "\n",
            "Epoch 4/150\n",
            "----------\n",
            "\n",
            "Epoch: [  3/150] \n",
            "train_loss: 0.77134 train_acc: 0.74237\n",
            "valid_loss: 0.98738 valid_acc: 0.63314\n",
            "test_acc: 0.58824\n",
            "EarlyStopping counter: 1 out of 30\n",
            "\n",
            "Epoch 5/150\n",
            "----------\n",
            "\n",
            "Epoch: [  4/150] \n",
            "train_loss: 0.78558 train_acc: 0.74068\n",
            "valid_loss: 0.88148 valid_acc: 0.71006\n",
            "test_acc: 0.67059\n",
            "EarlyStopping counter: 2 out of 30\n",
            "\n",
            "Epoch 6/150\n",
            "----------\n",
            "\n",
            "Epoch: [  5/150] \n",
            "train_loss: 0.70173 train_acc: 0.76949\n",
            "valid_loss: 0.73056 valid_acc: 0.76331\n",
            "test_acc: 0.68235\n",
            "Validation loss decreased (0.790256 --> 0.730563).  Saving model ...\n",
            "\n",
            "Epoch 7/150\n",
            "----------\n",
            "\n",
            "Epoch: [  6/150] \n",
            "train_loss: 0.65044 train_acc: 0.77458\n",
            "valid_loss: 0.83629 valid_acc: 0.74556\n",
            "test_acc: 0.68235\n",
            "EarlyStopping counter: 1 out of 30\n",
            "\n",
            "Epoch 8/150\n",
            "----------\n",
            "\n",
            "Epoch: [  7/150] \n",
            "train_loss: 0.58934 train_acc: 0.79661\n",
            "valid_loss: 0.77681 valid_acc: 0.72189\n",
            "test_acc: 0.71765\n",
            "EarlyStopping counter: 2 out of 30\n",
            "\n",
            "Epoch 9/150\n",
            "----------\n",
            "\n",
            "Epoch: [  8/150] \n",
            "train_loss: 0.62485 train_acc: 0.77966\n",
            "valid_loss: 0.68223 valid_acc: 0.82249\n",
            "test_acc: 0.74118\n",
            "Validation loss decreased (0.730563 --> 0.682233).  Saving model ...\n",
            "\n",
            "Epoch 10/150\n",
            "----------\n",
            "\n",
            "Epoch: [  9/150] \n",
            "train_loss: 0.50864 train_acc: 0.82203\n",
            "valid_loss: 1.07345 valid_acc: 0.67456\n",
            "test_acc: 0.61176\n",
            "EarlyStopping counter: 1 out of 30\n",
            "\n",
            "Epoch 11/150\n",
            "----------\n",
            "\n",
            "Epoch: [ 10/150] \n",
            "train_loss: 0.49243 train_acc: 0.82203\n",
            "valid_loss: 1.05858 valid_acc: 0.73964\n",
            "test_acc: 0.65882\n",
            "EarlyStopping counter: 2 out of 30\n",
            "\n",
            "Epoch 12/150\n",
            "----------\n",
            "\n",
            "Epoch: [ 11/150] \n",
            "train_loss: 0.47321 train_acc: 0.82712\n",
            "valid_loss: 0.91810 valid_acc: 0.69822\n",
            "test_acc: 0.69412\n",
            "EarlyStopping counter: 3 out of 30\n",
            "\n",
            "Epoch 13/150\n",
            "----------\n",
            "\n",
            "Epoch: [ 12/150] \n",
            "train_loss: 0.62156 train_acc: 0.79831\n",
            "valid_loss: 1.39508 valid_acc: 0.63905\n",
            "test_acc: 0.61176\n",
            "EarlyStopping counter: 4 out of 30\n",
            "\n",
            "Epoch 14/150\n",
            "----------\n",
            "\n",
            "Epoch: [ 13/150] \n",
            "train_loss: 0.42500 train_acc: 0.85085\n",
            "valid_loss: 1.54262 valid_acc: 0.65680\n",
            "test_acc: 0.61176\n",
            "EarlyStopping counter: 5 out of 30\n",
            "\n",
            "Epoch 15/150\n",
            "----------\n",
            "\n",
            "Epoch: [ 14/150] \n",
            "train_loss: 0.49094 train_acc: 0.83898\n",
            "valid_loss: 0.89669 valid_acc: 0.73964\n",
            "test_acc: 0.72941\n",
            "EarlyStopping counter: 6 out of 30\n",
            "\n",
            "Epoch 16/150\n",
            "----------\n",
            "\n",
            "Epoch: [ 15/150] \n",
            "train_loss: 0.43608 train_acc: 0.85593\n",
            "valid_loss: 1.03613 valid_acc: 0.74556\n",
            "test_acc: 0.71765\n",
            "EarlyStopping counter: 7 out of 30\n",
            "\n",
            "Epoch 17/150\n",
            "----------\n",
            "\n",
            "Epoch: [ 16/150] \n",
            "train_loss: 0.42619 train_acc: 0.85085\n",
            "valid_loss: 0.85137 valid_acc: 0.78107\n",
            "test_acc: 0.72941\n",
            "EarlyStopping counter: 8 out of 30\n",
            "\n",
            "Epoch 18/150\n",
            "----------\n",
            "\n",
            "Epoch: [ 17/150] \n",
            "train_loss: 0.38240 train_acc: 0.87458\n",
            "valid_loss: 1.14867 valid_acc: 0.69822\n",
            "test_acc: 0.62353\n",
            "EarlyStopping counter: 9 out of 30\n",
            "\n",
            "Epoch 19/150\n",
            "----------\n",
            "\n",
            "Epoch: [ 18/150] \n",
            "train_loss: 0.31367 train_acc: 0.89153\n",
            "valid_loss: 0.97610 valid_acc: 0.72189\n",
            "test_acc: 0.60000\n",
            "EarlyStopping counter: 10 out of 30\n",
            "\n",
            "Epoch 20/150\n",
            "----------\n",
            "\n",
            "Epoch: [ 19/150] \n",
            "train_loss: 0.34816 train_acc: 0.87458\n",
            "valid_loss: 1.09538 valid_acc: 0.69822\n",
            "test_acc: 0.69412\n",
            "EarlyStopping counter: 11 out of 30\n",
            "\n",
            "Epoch 21/150\n",
            "----------\n",
            "\n",
            "Epoch: [ 20/150] \n",
            "train_loss: 0.38805 train_acc: 0.87966\n",
            "valid_loss: 1.05636 valid_acc: 0.73964\n",
            "test_acc: 0.71765\n",
            "EarlyStopping counter: 12 out of 30\n",
            "\n",
            "Epoch 22/150\n",
            "----------\n",
            "\n",
            "Epoch: [ 21/150] \n",
            "train_loss: 0.27708 train_acc: 0.90678\n",
            "valid_loss: 0.89497 valid_acc: 0.79290\n",
            "test_acc: 0.78824\n",
            "EarlyStopping counter: 13 out of 30\n",
            "\n",
            "Epoch 23/150\n",
            "----------\n",
            "\n",
            "Epoch: [ 22/150] \n",
            "train_loss: 0.40485 train_acc: 0.87797\n",
            "valid_loss: 1.24635 valid_acc: 0.80473\n",
            "test_acc: 0.80000\n",
            "EarlyStopping counter: 14 out of 30\n",
            "\n",
            "Epoch 24/150\n",
            "----------\n",
            "\n",
            "Epoch: [ 23/150] \n",
            "train_loss: 0.23455 train_acc: 0.91525\n",
            "valid_loss: 0.87752 valid_acc: 0.76331\n",
            "test_acc: 0.75294\n",
            "EarlyStopping counter: 15 out of 30\n",
            "\n",
            "Epoch 25/150\n",
            "----------\n",
            "\n",
            "Epoch: [ 24/150] \n",
            "train_loss: 0.33982 train_acc: 0.87458\n",
            "valid_loss: 0.98508 valid_acc: 0.72781\n",
            "test_acc: 0.67059\n",
            "EarlyStopping counter: 16 out of 30\n",
            "\n",
            "Epoch 26/150\n",
            "----------\n",
            "\n",
            "Epoch: [ 25/150] \n",
            "train_loss: 0.32600 train_acc: 0.88305\n",
            "valid_loss: 0.92349 valid_acc: 0.76923\n",
            "test_acc: 0.74118\n",
            "EarlyStopping counter: 17 out of 30\n",
            "\n",
            "Epoch 27/150\n",
            "----------\n",
            "\n",
            "Epoch: [ 26/150] \n",
            "train_loss: 0.23416 train_acc: 0.92203\n",
            "valid_loss: 0.88600 valid_acc: 0.74556\n",
            "test_acc: 0.80000\n",
            "EarlyStopping counter: 18 out of 30\n",
            "\n",
            "Epoch 28/150\n",
            "----------\n",
            "\n",
            "Epoch: [ 27/150] \n",
            "train_loss: 0.25556 train_acc: 0.92373\n",
            "valid_loss: 3.31956 valid_acc: 0.71006\n",
            "test_acc: 0.74118\n",
            "EarlyStopping counter: 19 out of 30\n",
            "\n",
            "Epoch 29/150\n",
            "----------\n",
            "\n",
            "Epoch: [ 28/150] \n",
            "train_loss: 0.24071 train_acc: 0.92373\n",
            "valid_loss: 1.39902 valid_acc: 0.77515\n",
            "test_acc: 0.80000\n",
            "EarlyStopping counter: 20 out of 30\n",
            "\n",
            "Epoch 30/150\n",
            "----------\n",
            "\n",
            "Epoch: [ 29/150] \n",
            "train_loss: 0.27454 train_acc: 0.91864\n",
            "valid_loss: 0.93384 valid_acc: 0.78107\n",
            "test_acc: 0.81176\n",
            "EarlyStopping counter: 21 out of 30\n",
            "\n",
            "Epoch 31/150\n",
            "----------\n",
            "\n",
            "Epoch: [ 30/150] \n",
            "train_loss: 0.20925 train_acc: 0.92712\n",
            "valid_loss: 14.79079 valid_acc: 0.77515\n",
            "test_acc: 0.72941\n",
            "EarlyStopping counter: 22 out of 30\n",
            "\n",
            "Epoch 32/150\n",
            "----------\n",
            "\n",
            "Epoch: [ 31/150] \n",
            "train_loss: 0.31519 train_acc: 0.90339\n",
            "valid_loss: 1.22662 valid_acc: 0.76923\n",
            "test_acc: 0.74118\n",
            "EarlyStopping counter: 23 out of 30\n",
            "\n",
            "Epoch 33/150\n",
            "----------\n",
            "\n",
            "Epoch: [ 32/150] \n",
            "train_loss: 0.24258 train_acc: 0.92712\n",
            "valid_loss: 8.28140 valid_acc: 0.73373\n",
            "test_acc: 0.75294\n",
            "EarlyStopping counter: 24 out of 30\n",
            "\n",
            "Epoch 34/150\n",
            "----------\n",
            "\n",
            "Epoch: [ 33/150] \n",
            "train_loss: 0.22966 train_acc: 0.92712\n",
            "valid_loss: 18.22708 valid_acc: 0.73964\n",
            "test_acc: 0.74118\n",
            "EarlyStopping counter: 25 out of 30\n",
            "\n",
            "Epoch 35/150\n",
            "----------\n",
            "\n",
            "Epoch: [ 34/150] \n",
            "train_loss: 0.16648 train_acc: 0.94915\n",
            "valid_loss: 12.40163 valid_acc: 0.76331\n",
            "test_acc: 0.69412\n",
            "EarlyStopping counter: 26 out of 30\n",
            "\n",
            "Epoch 36/150\n",
            "----------\n",
            "\n",
            "Epoch: [ 35/150] \n",
            "train_loss: 0.14857 train_acc: 0.94915\n",
            "valid_loss: 0.96964 valid_acc: 0.78698\n",
            "test_acc: 0.75294\n",
            "EarlyStopping counter: 27 out of 30\n",
            "\n",
            "Epoch 37/150\n",
            "----------\n",
            "\n",
            "Epoch: [ 36/150] \n",
            "train_loss: 0.18778 train_acc: 0.94746\n",
            "valid_loss: 1.22961 valid_acc: 0.76923\n",
            "test_acc: 0.70588\n",
            "EarlyStopping counter: 28 out of 30\n",
            "\n",
            "Epoch 38/150\n",
            "----------\n",
            "\n",
            "Epoch: [ 37/150] \n",
            "train_loss: 0.24518 train_acc: 0.91186\n",
            "valid_loss: 1.46333 valid_acc: 0.74556\n",
            "test_acc: 0.70588\n",
            "EarlyStopping counter: 29 out of 30\n",
            "\n",
            "Epoch 39/150\n",
            "----------\n",
            "\n",
            "Epoch: [ 38/150] \n",
            "train_loss: 0.17163 train_acc: 0.95254\n",
            "valid_loss: 18.17594 valid_acc: 0.76923\n",
            "test_acc: 0.71765\n",
            "EarlyStopping counter: 30 out of 30\n",
            "Early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K6D7vVaHPN98"
      },
      "source": [
        "#**Calculate Accuracy**\n",
        "・True positive (TN)<br>\n",
        "・False positive (FP)<br>\n",
        "・True negative (TN)<br>\n",
        "・False negative (FN)<br>\n",
        "\n",
        "Accuracy = (TP + TN)/ (TP + TN + FP + FN)<br>\n",
        "Precision = TP/(FP + TP) ※positive predictive value<br>\n",
        "Recall = TP/(TP + FN)　※sensitivity<br>\n",
        "Specificity = TN/(FP + TN)<br>\n",
        "F_value = (2RecallPrecision)/(Recall+Precision)<br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2Fzf34FPOGk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "58393c17-9c27-45ad-e3a6-15aa63e18a5a"
      },
      "source": [
        "# visualize the loss as the network trained\n",
        "fig = plt.figure(figsize=(10,8))\n",
        "plt.plot(range(1,len(train_loss)+1),train_loss, label='Training Loss')\n",
        "plt.plot(range(1,len(valid_loss)+1),valid_loss,label='Validation Loss')\n",
        "\n",
        "# find position of lowest validation loss\n",
        "minposs = valid_loss.index(min(valid_loss))+1 \n",
        "plt.axvline(minposs, linestyle='--', color='r',label='Early Stopping Checkpoint')\n",
        "\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.ylim(0, 1.0) # consistent scale\n",
        "plt.xlim(0, len(train_loss)+1) # consistent scale\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "fig.savefig('loss_plot.png', bbox_inches='tight')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-10-b7dfd1faf622>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# visualize the loss as the network trained\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Training Loss'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalid_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalid_loss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Validation Loss'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mNameError\u001b[0m: name 'train_loss' is not defined"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x576 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1P_oH6gQQG9"
      },
      "source": [
        "visualize_model(model_ft)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uv4xXKF2POJ8"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SShmQdShtkMR"
      },
      "source": [
        "#ネットワークの保存\n",
        "PATH = r\"F:\\Strabismus\\Dataset_1to100_eval/base_model.pth\"\n",
        "torch.save(model_ft.state_dict(), PATH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "BVnnfPrTUmla"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PWpxojQitkOT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b413d980-747a-4f6a-ec2e-24e854b196a1"
      },
      "source": [
        "#ネットワークの読み込み\n",
        "PATH = r\"F:\\Strabismus\\Dataset_1to100_eval/base_model.pth\"\n",
        "model_ft.load_state_dict(torch.load(PATH))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XQuhBl0joHM"
      },
      "source": [
        "#**Evaluation using confusion matrix, and draw ROC curve**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 717
        },
        "id": "opNUHRr2jido",
        "outputId": "a2346e13-6a61-416e-ea78-3b932eaf14ac"
      },
      "source": [
        "import statistics\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import display\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn import metrics\n",
        "\n",
        "\n",
        "def make_cm(matrix, columns):\n",
        "    # matrix numpy配列\n",
        "\n",
        "    # columns 項目名リスト\n",
        "    n = len(columns)\n",
        "\n",
        "    # '正解データ'をn回繰り返すリスト生成\n",
        "    act = ['正解データ'] * n\n",
        "    pred = ['予測結果'] * n\n",
        "\n",
        "    #データフレーム生成\n",
        "    cm = pd.DataFrame(matrix, \n",
        "        columns=[pred, columns], index=[act, columns])\n",
        "    return cm\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "#デプロイ用のモデルに変更する\n",
        "copy_model_ft = model_ft\n",
        "copy_model_ft.eval()\n",
        "model_ft = repvgg_model_convert(copy_model_ft, create_RepVGG_A2).to(device)\n",
        "\"\"\"\n",
        "\n",
        "model_ft.eval() # prep model for evaluation\n",
        "\n",
        "targets, preds, probs =[], [], []\n",
        "for image_tensor, target in test_loader:  \n",
        "      #target = target.squeeze(1)     \n",
        "      image_tensor = image_tensor.to(device)\n",
        "      target = target.to(device)\n",
        "      # forward pass: compute predicted outputs by passing inputs to the model\n",
        "      output = model_ft(image_tensor)\n",
        "      #_, pred = torch.max(output, 1)  \n",
        "      prob, pred = torch.topk(nn.Softmax(dim=1)(output), 1)\n",
        "      \n",
        "      preds.append(int(pred))  #予測結果\n",
        "      targets.append(int(target)) #ラベル\n",
        "\n",
        "      #甲状腺眼症のprobabilityを計算（classが0なら1から減算、classが1ならそのまま）\n",
        "      prob = abs(1-float(prob)-float(pred))\n",
        "      probs.append(prob)  #予測結果(確率)\n",
        "\n",
        "y_test = np.array(targets)\n",
        "y_pred = np.array(preds)\n",
        "y_prob = np.array(probs)\n",
        "\n",
        "print(y_test)\n",
        "print(y_pred)\n",
        "#print(y_prob)\n",
        "\n",
        "\n",
        "# 混同行列(confusion matrix)の取得\n",
        "labels = class_names\n",
        "matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(matrix)\n",
        "\n",
        "# make_cmを使った混同行列標示\n",
        "cm = make_cm(matrix, labels)\n",
        "\n",
        "# 結果の表示\n",
        "display(cm)\n",
        "\n",
        "\n",
        "tn, fp, fn, tp = matrix.flatten()\n",
        "accuracy = (tp+tn)/(tp+tn+fp+fn)\n",
        "precision = tp/(tp+fp) #positive predictive value\n",
        "sensitivity = tp/(tp+fn)\n",
        "specificity = tn/(tn+fp)\n",
        "f1_score = 2*tp/(2*tp+fp+fn)\n",
        "\n",
        "#感度・特異度の計算\n",
        "print()\n",
        "print('accuracy: '+str(accuracy))\n",
        "print('positive predictive value: '+str(precision))\n",
        "print('sensitivity: '+str(sensitivity))\n",
        "print('specificity: '+str(specificity))\n",
        "print('f1_score: '+str(f1_score))\n",
        "print()\n",
        "\n",
        "\n",
        "fpr, tpr, thres = metrics.roc_curve(y_test, y_prob)\n",
        "auc = metrics.auc(fpr, tpr)\n",
        "print('auc:', auc)\n",
        "\n",
        "#Draw AUC curve\n",
        "plt.figure()\n",
        "lw = 2\n",
        "plt.plot(fpr, tpr, color='darkorange',lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver operating characteristic example')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[4 1 0 5 4 5 5 0 1 5 2 3 5 4 4 0 5 0 1 5 5 3 0 5 0 3 0 0 5 0 1 5 1 1 0 1 5\n",
            " 0 1 3 5 0 0 3 4 0 1 0 5 1 0 0 5 0 5 4 1 1 0 1 0 0 1 0 0 0 5 0 0 4 2 4 0 5\n",
            " 5 0 1 1 0 0 0 5 3 5 0]\n",
            "[0 1 0 5 0 5 5 0 1 5 0 3 5 0 0 0 5 0 1 5 2 3 0 5 0 3 0 1 5 0 1 5 1 1 0 1 0\n",
            " 0 1 3 5 0 0 3 4 0 3 0 5 1 0 5 5 0 5 0 1 1 0 0 0 0 1 0 0 0 5 0 0 4 0 0 0 5\n",
            " 5 4 1 1 0 0 0 5 0 5 0]\n",
            "[[29  1  0  0  1  1]\n",
            " [ 1 14  0  1  0  0]\n",
            " [ 2  0  0  0  0  0]\n",
            " [ 1  0  0  5  0  0]\n",
            " [ 6  0  0  0  2  0]\n",
            " [ 1  0  1  0  0 19]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                       予測結果                \\\n",
              "                             corrected_cont corrected_eso   \n",
              "正解データ corrected_cont                     29             1   \n",
              "      corrected_eso                       1            14   \n",
              "      corrected_eso-boundary              2             0   \n",
              "      corrected_exo                       1             0   \n",
              "      corrected_exo-boundary              6             0   \n",
              "      corrected_inadequate                1             0   \n",
              "\n",
              "                                                                   \\\n",
              "                             corrected_eso-boundary corrected_exo   \n",
              "正解データ corrected_cont                              0             0   \n",
              "      corrected_eso                               0             1   \n",
              "      corrected_eso-boundary                      0             0   \n",
              "      corrected_exo                               0             5   \n",
              "      corrected_exo-boundary                      0             0   \n",
              "      corrected_inadequate                        1             0   \n",
              "\n",
              "                                                                          \n",
              "                             corrected_exo-boundary corrected_inadequate  \n",
              "正解データ corrected_cont                              1                    1  \n",
              "      corrected_eso                               0                    0  \n",
              "      corrected_eso-boundary                      0                    0  \n",
              "      corrected_exo                               0                    0  \n",
              "      corrected_exo-boundary                      2                    0  \n",
              "      corrected_inadequate                        0                   19  "
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th colspan=\"6\" halign=\"left\">予測結果</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th>corrected_cont</th>\n",
              "      <th>corrected_eso</th>\n",
              "      <th>corrected_eso-boundary</th>\n",
              "      <th>corrected_exo</th>\n",
              "      <th>corrected_exo-boundary</th>\n",
              "      <th>corrected_inadequate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"6\" valign=\"top\">正解データ</th>\n",
              "      <th>corrected_cont</th>\n",
              "      <td>29</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>corrected_eso</th>\n",
              "      <td>1</td>\n",
              "      <td>14</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>corrected_eso-boundary</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>corrected_exo</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>corrected_exo-boundary</th>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>corrected_inadequate</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-12-ac0b9fef9f51>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m \u001b[0mtn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtp\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mtn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtp\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mtn\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[0mprecision\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtp\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtp\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#positive predictive value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 4)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2YAAHbdOJbv"
      },
      "source": [
        "#**GradCAM**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSDG3Lt1OMS_"
      },
      "source": [
        "class Flatten(nn.Module): \n",
        "    \"\"\"One layer module that flattens its input.\"\"\"\n",
        "    def __init__(self):\n",
        "        super(Flatten, self).__init__()\n",
        "    def forward(self, x):\n",
        "        x = x.view(x.size(0), -1)\n",
        "        return x\n",
        "\n",
        "# Split model in two parts\n",
        "features_fn = nn.Sequential(*list(model_ft.children())[:-2]) #最後の2層（AdaptiveAvgPool2dとLinear)を取り除いたもの\n",
        "classifier_fn = nn.Sequential(*(list(model_ft.children())[-2:-1] + [Flatten()] + list(model_ft.children())[-1:])) #最終層の前にFlatten()を挿入\n",
        " #最後の2層\n",
        "\n",
        "#評価モードにする    \n",
        "model_ft = model_ft.eval()\n",
        "model_ft = model_ft.to(device)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2c8FBsHOMW1"
      },
      "source": [
        "def GradCAM(img, c, features_fn, classifier_fn):\n",
        "    feats = features_fn(img.cuda())\n",
        "    _, N, H, W = feats.size() #[1,2048,7,7]\n",
        "    out = classifier_fn(feats) #out: [1,1000]\n",
        "    c_score = out[0, c]   #c_scoreとは？？\n",
        "\n",
        "    grads = torch.autograd.grad(c_score, feats)\n",
        "    w = grads[0][0].mean(-1).mean(-1)           #ここでGlobalAveragePoolingをしている\n",
        "    sal = torch.matmul(w, feats.view(N, H*W))\n",
        "    sal = sal.view(H, W).cpu().detach().numpy()\n",
        "    sal = np.maximum(sal, 0) #ReLUと同じ\n",
        "    return sal\n",
        "\n",
        "read_tensor = transforms.Compose([\n",
        "    lambda x: Image.open(x),\n",
        "    lambda x: x.convert('RGB'),\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    lambda x: torch.unsqueeze(x, 0) #次元を1に引き延ばす\n",
        "])"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NiEC41LROViv"
      },
      "source": [
        "#画像のパスを指定\n",
        "#for j in range(1):\n",
        "for j in range(len(test_dataset)):\n",
        "\n",
        "    #元画像\n",
        "\n",
        "    image = test_dataset[j][0]\n",
        "    image = image.permute(1, 2, 0)\n",
        "\n",
        "    img_tensor = test_dataset[j][0].unsqueeze(0)\n",
        "    #Softmaxにかけたときの確率上位1つのpp(確率)とcc(class番号)を取得(tench→正常,goldfish→斜視)\n",
        "    pp, cc = torch.topk(nn.Softmax(dim=1)(model_ft(img_tensor.to(device))), 1)\n",
        "\n",
        "    #pとcを対にして入力\n",
        "    for i, (p, c) in enumerate(zip(pp[0], cc[0])):  \n",
        "        sal = GradCAM(img_tensor, int(c), features_fn, classifier_fn)\n",
        "        tmp = image.to('cpu').detach().numpy().copy()\n",
        "        img = Image.fromarray((tmp*255).astype(np.uint8))\n",
        "        #TensorをImageに変換\n",
        "        sal = Image.fromarray(sal)\n",
        "        sal = sal.resize(img.size, resample=Image.LINEAR)\n",
        "\n",
        "        print()\n",
        "        #print(img_path) #あとで参照しやすいように画像のパスを表示\n",
        "\n",
        "        #plt.title('')\n",
        "        print('label: '+labels[test_dataset[j][1]])\n",
        "        print('pred:  '+'{}  {:.1f}%'.format(labels[c], 100*float(p)))\n",
        "        #plt.title('pred:'+'{}: { .1f}%'.format(labels[c], 100*float(p)))        \n",
        "        \n",
        "        plt.figure(figsize=(15, 10))\n",
        "\n",
        "        #グラフを1行2列に並べたうちの1番目\n",
        "        plt.subplots_adjust(wspace=0,hspace=0)\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.axis('off')\n",
        "        plt.imshow(img)\n",
        "        plt.imshow(np.array(sal), alpha=0.5, cmap='jet')\n",
        "\n",
        "        #元の画像を並べて表示\n",
        "        image = test_dataset[j][0]\n",
        "        image = image.permute(1, 2, 0)\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.axis('off')\n",
        "        plt.imshow(image)\n",
        "\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPO-b2cAT0yF"
      },
      "source": [
        "#**新しいデータセットの判定**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#評価モードにする\n",
        "model_ft.eval()\n",
        "\n",
        "#valフォルダ内のファイル名を取得\n",
        "image_path = glob.glob(data_dir + \"/*\")\n",
        "#random.shuffle(image_path)  #表示順をランダムにする\n",
        "print('number of images: ' +str(len(image_path)))\n",
        "#print(image_path) \n",
        "\n",
        "\n",
        "\n",
        "#評価のための画像下処理\n",
        "def image_transform(image_path):    \n",
        "    image=Image.open(image_path)\n",
        "\n",
        "    #expand2square\n",
        "    new_image = expand2square(image,(0,0,0))\n",
        "\n",
        "    transform = transforms.Compose([\n",
        "            transforms.Resize(256),\n",
        "            transforms.CenterCrop(224),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "    image_tensor = transform(new_image)\n",
        "    #show_image(image_tensor)\n",
        "\n",
        "    #バッチサイズの次元を先頭に追加した4Dテンソルに変換\n",
        "    image_tensor.unsqueeze_(0)\n",
        "    #print(image_tensor.size())  # torch.Size([1, 3, 224, 224])\n",
        "    image_tensor = image_tensor.to(device) #model_ftをGPUに載せる\n",
        "\n",
        "    return(image_tensor)\n",
        "\n",
        "\n",
        "def expand2square(pil_img, background_color):\n",
        "    width, height = pil_img.size\n",
        "    if width == height:\n",
        "        return pil_img\n",
        "    elif width > height:\n",
        "        result = Image.new(pil_img.mode, (width, width), background_color)\n",
        "        result.paste(pil_img, (0, (width-height)//2))\n",
        "        return result\n",
        "    else:\n",
        "        result = Image.new(pil_img.mode, (height, height), background_color)\n",
        "        result.paste(pil_img, (0, (height - width) // 2))\n",
        "        return result\n",
        "\n",
        "\n",
        "#モデルにした処理した画像を投入して予測結果を表示\n",
        "def image_eval(image_tensor, class_names):\n",
        "    output = model_ft(image_tensor)\n",
        "    #print(output.size())  # torch.Size([1, 1000])\n",
        "    #print(output)\n",
        "\n",
        "    #model_pred:クラス名前、prob:確率、pred:クラス番号\n",
        "    prob, pred = torch.topk(nn.Softmax(dim=1)(output), 1)\n",
        "    model_pred = class_names[pred]\n",
        "    \n",
        "    #甲状腺眼症のprobabilityを計算（classが0なら1から減算、classが1ならそのまま）\n",
        "    prob = abs(1-float(prob)-float(pred))\n",
        " \n",
        "    return model_pred, prob, pred\n",
        "\n",
        "\n",
        "def show_image(image_path):\n",
        "    \"\"\"\n",
        "    #画像のインポート\n",
        "    img = cv2.imread(image_path, cv2.IMREAD_UNCHANGED)\n",
        "    #画像のリサイズ\n",
        "    height = img.shape[0]\n",
        "    width = img.shape[1]\n",
        "    resized_img = cv2.resize(img, (int(width*300/height), 300))\n",
        "    cv2.imshow(\"title\", resized_img)\n",
        "    \"\"\"\n",
        "    img = Image.open(image_path)\n",
        "    width, height = img.size\n",
        "    resized_img = img.resize((int(width*300/height), 300))\n",
        "    #画像をarrayに変換\n",
        "    im_list = np.asarray(resized_img)\n",
        "    #貼り付け\n",
        "    plt.imshow(im_list)\n",
        "    #表示\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "#ここからがメイン\n",
        "for i in image_path:\n",
        "      show_image(i) #画像を表示\n",
        "      image_tensor = image_transform(i)  #予測のための画像下処理\n",
        "      model_pred, prob, pred = image_eval(image_tensor, class_names)  #予測結果を出力   \n",
        "      print('Image: '+ str(i))\n",
        "      print('Pred: '+ model_pred)\n",
        "      print() #空白行を入れる\n",
        "      time.sleep(0.1)\n",
        "\n",
        "      #ファイルを判定結果に従ってフォルダ分けする\n",
        "      dst_name = os.path.basename(i)\n",
        "      shutil.copy(i, os.path.join(dst_path_parent, class_names[pred], os.path.basename(i)))"
      ],
      "metadata": {
        "id": "yYDu2D7Fgekn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "cc-O10kdJMtV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}