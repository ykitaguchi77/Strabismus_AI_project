{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled90.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN2+5MZ88vl1pUSdV4kPOiO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ykitaguchi77/Strabismus_AI_project/blob/main/DataSplit(stratified_one_subject_leave_out).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Data_split for one-subject-leave-out stratified 5-fold crossvalidation**"
      ],
      "metadata": {
        "id": "Dxlpd0AbAWf7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Leave one subject out cross validation + 5-fold stratified cross validation\n",
        "\n",
        "・1症例を抜き出し、その症例のすべての画像をテスト画像とする\n",
        "・残りの症例の内斜視、外斜視、斜視なし群を、同じ症例が群をまたがないように5分割する。\n",
        "・5分割したデータセットのうち4つをtraining、1つをvalidationとして用いてトレーニングを行い、抜き出した1症例のそれぞれの画像のおける正解率を算出する。これを5回繰り返してcross validationとする。\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "TkRaZnYjAjZ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "nPSM5f-yyQfC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        },
        "outputId": "442dbee2-78f6-4508-ba6c-ee4fb8392cda"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Input \u001b[1;32mIn [17]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m#症例のリストをpandasで開く\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m df_gla_ortho \u001b[38;5;241m=\u001b[39m \u001b[43mopencsv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgla_ortho_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgla_ortho\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \n\u001b[0;32m     34\u001b[0m df_gla_eso \u001b[38;5;241m=\u001b[39m opencsv(gla_eso_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgla_eso\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     35\u001b[0m df_gla_exo \u001b[38;5;241m=\u001b[39m opencsv(gla_exo_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgla_exo\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "Input \u001b[1;32mIn [17]\u001b[0m, in \u001b[0;36mopencsv\u001b[1;34m(path, classname)\u001b[0m\n\u001b[0;32m     26\u001b[0m         df\u001b[38;5;241m.\u001b[39miloc[row,\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m classname \u001b[38;5;66;03m#class\u001b[39;00m\n\u001b[0;32m     27\u001b[0m         df\u001b[38;5;241m.\u001b[39miloc[row,\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(df\u001b[38;5;241m.\u001b[39miloc[row,\u001b[38;5;241m2\u001b[39m])\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;66;03m#ID\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m     \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclose\u001b[49m()\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
            "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\generic.py:5487\u001b[0m, in \u001b[0;36mNDFrame.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5480\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   5481\u001b[0m     name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_internal_names_set\n\u001b[0;32m   5482\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_metadata\n\u001b[0;32m   5483\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_accessors\n\u001b[0;32m   5484\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis\u001b[38;5;241m.\u001b[39m_can_hold_identifiers_and_holds_name(name)\n\u001b[0;32m   5485\u001b[0m ):\n\u001b[0;32m   5486\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m[name]\n\u001b[1;32m-> 5487\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'close'"
          ]
        }
      ],
      "source": [
        "import codecs\n",
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "import shutil\n",
        "from sklearn.model_selection import LeaveOneGroupOut\n",
        "from sklearn.model_selection import StratifiedGroupKFold\n",
        "import pandas as pd\n",
        "pd.set_option('display.max_rows', 500)\n",
        "\n",
        "gla_ortho_path = r\"F:\\先天性緑内障\\data_list\\Disease_ortho.csv\"\n",
        "gla_eso_path = r\"F:\\先天性緑内障\\data_list\\Disease_ET.csv\"\n",
        "gla_exo_path = r\"F:\\先天性緑内障\\data_list\\Disease_XT.csv\"\n",
        "cont_ortho_path = r\"F:\\先天性緑内障\\data_list\\Disease_ortho.csv\"\n",
        "cont_eso_path = r\"F:\\先天性緑内障\\data_list\\Control_ET.csv\"\n",
        "cont_exo_path = r\"F:\\先天性緑内障\\data_list\\Control_XT.csv\"\n",
        "dst_path = r\"F:\\先天性緑内障\\OneGroupLeaveOut\"\n",
        "\n",
        "def opencsv(path, classname):\n",
        "    #with codecs.open(path, \"r\", \"utf-8\", \"ignore\") as file:\n",
        "    with codecs.open(path, \"r\", \"Shift-JIS\", \"ignore\") as file:\n",
        "        df = pd.read_csv(file, index_col=None, header=None)\n",
        "        df.insert(0, 'ID', '')\n",
        "        df.insert(0, 'classes', '')\n",
        "        for row in range(len(df)):\n",
        "            df.iloc[row,0] = classname #class\n",
        "            df.iloc[row,1] = os.path.basename(df.iloc[row,2]).split(\"_\")[0] #ID\n",
        "    return df\n",
        "\n",
        "\n",
        "#症例のリストをpandasで開く\n",
        "df_gla_ortho = opencsv(gla_ortho_path, \"gla_ortho\") \n",
        "df_gla_eso = opencsv(gla_eso_path, \"gla_eso\")\n",
        "df_gla_exo = opencsv(gla_exo_path, \"gla_exo\")\n",
        "df_cont_ortho = opencsv(cont_ortho_path, \"cont_ortho\")\n",
        "df_cont_eso = opencsv(cont_eso_path, \"gla_eso\")\n",
        "df_cont_exo = opencsv(cont_exo_path, \"gla_exo\")\n",
        "\n",
        "df_gla_all = pd.concat([df_gla_ortho, df_gla_eso, df_gla_exo], axis=0)\n",
        "df_cont_all = pd.concat([df_cont_ortho, df_cont_eso, df_cont_exo], axis=0)\n",
        "df_all = pd.concat([df_cont_ortho, df_cont_eso, df_cont_exo], axis=0)\n",
        "\n",
        "#df_all.to_csv(r\"F:\\先天性緑内障\\data_list\\df_all.csv\", encoding='utf-8-sig', index=0, header=None)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#それぞれの項目（path, classes, ID）をリスト化\n",
        "gla_dataset_path = df_gla_all.iloc[:,2].transpose().values\n",
        "gla_classes = df_gla_all.iloc[:,0].transpose().values\n",
        "gla_id = df_gla_all.iloc[:,1].transpose().values\n",
        "cont_dataset_path = df_cont_all.iloc[:,2].transpose().values\n",
        "cont_classes = df_cont_all.iloc[:,0].transpose().values\n",
        "cont_id = df_cont_all.iloc[:,1].transpose().values\n",
        "\n",
        "#print(len(gla_dataset_path))\n",
        "\n",
        "\n",
        "\n",
        "#保存先フォルダを作成\n",
        "if os.path.exists(dst_path):\n",
        "    pass\n",
        "    #shutil.rmtree(dst_path)\n",
        "os.makedirs(dst_path, exist_ok=True)\n",
        "\n",
        "\n",
        "#まずglaのデータセットから1人分を抜き出す（LeaveOneGroupOut)\n",
        "logo = LeaveOneGroupOut()\n",
        "logo.get_n_splits(gla_dataset_path, gla_classes, gla_id)\n",
        "logo.get_n_splits(groups=gla_id)  # 'groups' is always required\n",
        "\n",
        "for remain_index, test_index in logo.split(gla_dataset_path, gla_classes, gla_id):\n",
        "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
        "    gla_dataset_path_remain, gla_dataset_path_test = gla_dataset_path[remain_index], gla_dataset_path[test_index]\n",
        "    gla_classes_remain, gla_classes_test = gla_classes[remain_index], gla_classes[test_index]\n",
        "    gla_id_remain, gla_id_test = gla_id[remain_index], gla_id[test_index]\n",
        "    #print(gla_dataset_path, gla_dataset_path_test, gla_id_train, gla_id_test)\n",
        "    print(gla_id_test)\n",
        "    #print(gla_id_train)\n",
        "\n",
        "    #抜き出したデータのIDでフォルダを作成\n",
        "    os.makedirs(os.path.join(dst_path, gla_id_test[0]), exist_ok=True)\n",
        "    os.chdir(os.path.join(dst_path, gla_id_test[0]))\n",
        "    for i in range(5):\n",
        "        for j in [\"train\", \"val\"]:\n",
        "            for k in [\"gla\", \"cont\"]:\n",
        "                os.makedirs(os.path.join(str(i), j, k), exist_ok=True)\n",
        "    os.makedirs(\"test\", exist_ok=True) #判定のための画像\n",
        "    \n",
        "    #testフォルダにコピー\n",
        "    for file in gla_dataset_path_test:\n",
        "        #print(file)\n",
        "        shutil.copyfile(file, \"./test/\"+ os.path.basename(file))\n",
        "    \n",
        "\n",
        "    #抜き出した残りのデータセットについてStratified group 5-foldをかける\n",
        "    cv = StratifiedGroupKFold(n_splits=5)\n",
        "\n",
        "    m=0\n",
        "    for train_idxs, val_idxs in cv.split(gla_dataset_path_remain, gla_classes_remain, gla_id_remain):\n",
        "        #print(\"TRAIN:\", gla_classes_remain[train_idxs])\n",
        "        #print(\"      \", gla_id_remain[train_idxs])\n",
        "        #print(\"      \", gla_dataset_path_remain[train_idxs])\n",
        "        #print(\" TEST:\", gla_classes_remain[val_idxs])\n",
        "        #print(\"      \", gla_id_remain[val_idxs])\n",
        "        #print(\"      \", gla_dataset_path_remain[val_idxs])\n",
        "        for idx in train_idxs:\n",
        "            #print(gla_dataset_path_remain[idx])\n",
        "            #print(\"./\"+str(m)+\"/train/gla/\"+os.path.basename(gla_dataset_path_remain[idx]))\n",
        "            shutil.copyfile(gla_dataset_path_remain[idx], \"./\"+str(m)+\"/train/gla/\"+os.path.basename(gla_dataset_path_remain[idx]))\n",
        "        for idx in val_idxs:\n",
        "            pass\n",
        "            shutil.copyfile(gla_dataset_path_remain[idx], \"./\"+str(m)+\"/val/gla/\"+os.path.basename(gla_dataset_path_remain[idx]))\n",
        "        print(\"Making \"+str(m+1)+\"/5 crossvalidation folders\")\n",
        "        m+=1\n",
        "\n",
        "\n",
        "#Contのデータセットでも同じことをやる\n",
        "#まずcontのデータセットから1人分を抜き出す（LeaveOneGroupOut)\n",
        "logo = LeaveOneGroupOut()\n",
        "logo.get_n_splits(cont_dataset_path, cont_classes, cont_id)\n",
        "logo.get_n_splits(groups=cont_id)  # 'groups' is always required\n",
        "\n",
        "for remain_index, test_index in logo.split(cont_dataset_path, cont_classes, cont_id):\n",
        "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
        "    cont_dataset_path_remain, cont_dataset_path_test = cont_dataset_path[remain_index], cont_dataset_path[test_index]\n",
        "    cont_classes_remain, cont_classes_test = cont_classes[remain_index], cont_classes[test_index]\n",
        "    cont_id_remain, cont_id_test = cont_id[remain_index], cont_id[test_index]\n",
        "    #print(cont_dataset_path, cont_dataset_path_test, cont_id_train, cont_id_test)\n",
        "    print(cont_id_test)\n",
        "    #print(cont_id_train)\n",
        "\n",
        "    #抜き出したデータのIDでフォルダを作成\n",
        "    os.makedirs(os.path.join(dst_path, cont_id_test[0]), exist_ok=True)\n",
        "    os.chdir(os.path.join(dst_path, cont_id_test[0]))\n",
        "    for i in range(5):\n",
        "        for j in [\"train\", \"val\"]:\n",
        "            for k in [\"cont\", \"cont\"]:\n",
        "                os.makedirs(os.path.join(str(i), j, k), exist_ok=True)\n",
        "    os.makedirs(\"test\", exist_ok=True) #判定のための画像\n",
        "    \n",
        "    #testフォルダにコピー\n",
        "    for file in cont_dataset_path_test:\n",
        "        #print(file)\n",
        "        shutil.copyfile(file, \"./test/\"+ os.path.basename(file))\n",
        "    \n",
        "\n",
        "    #抜き出した残りのデータセットについてStratified group 5-foldをかける\n",
        "    cv = StratifiedGroupKFold(n_splits=5)\n",
        "\n",
        "    m=0\n",
        "    for train_idxs, val_idxs in cv.split(cont_dataset_path_remain, cont_classes_remain, cont_id_remain):\n",
        "        #print(\"TRAIN:\", cont_classes_remain[train_idxs])\n",
        "        #print(\"      \", cont_id_remain[train_idxs])\n",
        "        #print(\"      \", cont_dataset_path_remain[train_idxs])\n",
        "        #print(\" TEST:\", cont_classes_remain[val_idxs])\n",
        "        #print(\"      \", cont_id_remain[val_idxs])\n",
        "        #print(\"      \", cont_dataset_path_remain[val_idxs])\n",
        "        for idx in train_idxs:\n",
        "            #print(cont_dataset_path_remain[idx])\n",
        "            #print(\"./\"+str(m)+\"/train/cont/\"+os.path.basename(cont_dataset_path_remain[idx]))\n",
        "            shutil.copyfile(cont_dataset_path_remain[idx], \"./\"+str(m)+\"/train/cont/\"+os.path.basename(cont_dataset_path_remain[idx]))\n",
        "        for idx in val_idxs:\n",
        "            pass\n",
        "            shutil.copyfile(cont_dataset_path_remain[idx], \"./\"+str(m)+\"/val/cont/\"+os.path.basename(cont_dataset_path_remain[idx]))\n",
        "        print(\"Making \"+str(m+1)+\"/5 crossvalidation folders\")\n",
        "        m+=1"
      ],
      "metadata": {
        "id": "0CmLwRFybHpa",
        "outputId": "739c21fc-6890-4e2f-820b-1f036e1e626d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 828
        }
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['1546' '1546' '1546' '1546' '1546' '1546' '1546']\n",
            "Making 0/5 crossvalidation folders\n",
            "Making 1/5 crossvalidation folders\n",
            "Making 2/5 crossvalidation folders\n",
            "Making 3/5 crossvalidation folders\n",
            "Making 4/5 crossvalidation folders\n",
            "['1962']\n",
            "Making 0/5 crossvalidation folders\n",
            "Making 1/5 crossvalidation folders\n",
            "Making 2/5 crossvalidation folders\n",
            "Making 3/5 crossvalidation folders\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Input \u001b[1;32mIn [39]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m train_idxs, val_idxs \u001b[38;5;129;01min\u001b[39;00m cv\u001b[38;5;241m.\u001b[39msplit(gla_dataset_path_remain, gla_classes_remain, gla_id_remain):\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;66;03m#print(\"TRAIN:\", gla_classes_remain[train_idxs])\u001b[39;00m\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;66;03m#print(\"      \", gla_id_remain[train_idxs])\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[38;5;66;03m#print(\"      \", gla_id_remain[val_idxs])\u001b[39;00m\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;66;03m#print(\"      \", gla_dataset_path_remain[val_idxs])\u001b[39;00m\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m train_idxs:\n\u001b[0;32m     61\u001b[0m         \u001b[38;5;66;03m#print(gla_dataset_path_remain[idx])\u001b[39;00m\n\u001b[0;32m     62\u001b[0m         \u001b[38;5;66;03m#print(\"./\"+str(m)+\"/train/gla/\"+os.path.basename(gla_dataset_path_remain[idx]))\u001b[39;00m\n\u001b[1;32m---> 63\u001b[0m         \u001b[43mshutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopyfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgla_dataset_path_remain\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mm\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/train/gla/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbasename\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgla_dataset_path_remain\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m val_idxs:\n\u001b[0;32m     65\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\shutil.py:274\u001b[0m, in \u001b[0;36mcopyfile\u001b[1;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[0;32m    271\u001b[0m \u001b[38;5;66;03m# Windows, see:\u001b[39;00m\n\u001b[0;32m    272\u001b[0m \u001b[38;5;66;03m# https://github.com/python/cpython/pull/7160#discussion_r195405230\u001b[39;00m\n\u001b[0;32m    273\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m _WINDOWS \u001b[38;5;129;01mand\u001b[39;00m file_size \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 274\u001b[0m     \u001b[43m_copyfileobj_readinto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfsrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfdst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mmin\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCOPY_BUFSIZE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    275\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dst\n\u001b[0;32m    277\u001b[0m copyfileobj(fsrc, fdst)\n",
            "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\shutil.py:185\u001b[0m, in \u001b[0;36m_copyfileobj_readinto\u001b[1;34m(fsrc, fdst, length)\u001b[0m\n\u001b[0;32m    183\u001b[0m         fdst\u001b[38;5;241m.\u001b[39mwrite(smv)\n\u001b[0;32m    184\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 185\u001b[0m     \u001b[43mfdst_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmv\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "sbI77weEl8i-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "EZOT3BB7lXY8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.getcwd()\n",
        "os.listdir()\n",
        "shutil.copyfile(r\"F:\\先天性緑内障\\データ引継ぎ\\children_control\\8_1.jpg\", \"./\"+str(1)+\"/train/gla/\"+os.path.basename(r\"F:\\先天性緑内障\\データ引継ぎ\\children_control\\8_1.jpg\"))"
      ],
      "metadata": {
        "id": "0045hL8olAmH",
        "outputId": "5080bc11-b3f4-4207-fc00-e60eff099b3d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'./1/train/gla/8_1.jpg'"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.getcwd()\n",
        "\n",
        "path = \"./test\"\n",
        "os.listdir(path)"
      ],
      "metadata": {
        "id": "fIwmAKMrmOKC",
        "outputId": "79fd8627-ed0a-4e3f-d016-ff9baa6dd115",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['2004_12.jpg',\n",
              " '2004_28.jpg',\n",
              " '2004_33.jpg',\n",
              " '2004_34.jpg',\n",
              " '2004_14.jpg',\n",
              " '2004_17.jpg',\n",
              " '2004_19.jpg',\n",
              " '2004_22.jpg',\n",
              " '2004_24.jpg',\n",
              " '2004_30.jpg']"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# one group leave out 見本\n",
        "# https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.LeaveOneGroupOut.html#sklearn.model_selection.LeaveOneGroupOut\n",
        "# 今回のケースでは、groupがIDに該当\n",
        "import numpy as np\n",
        "from sklearn.model_selection import LeaveOneGroupOut\n",
        "X = np.array([[1, 2], [3, 4], [5, 6], [7, 8], [9, 10], [11, 12]])\n",
        "y = np.array([1, 2, 1, 2, 1, 1])\n",
        "groups = np.array([1, 1, 2, 3, 3, 4])\n",
        "logo = LeaveOneGroupOut()\n",
        "logo.get_n_splits(X, y, groups)\n",
        "logo.get_n_splits(groups=groups)  # 'groups' is always required\n",
        "print(logo)\n",
        "LeaveOneGroupOut()\n",
        "for train_index, test_index in logo.split(X, y, groups):\n",
        "     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
        "     X_train, X_test = X[train_index], X[test_index]\n",
        "     y_train, y_test = y[train_index], y[test_index]\n",
        "     print(X_train, X_test, y_train, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c115c0e3-04da-4561-c1ac-a90b1d2cafd1",
        "id": "_MvzPiyBl6x6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LeaveOneGroupOut()\n",
            "TRAIN: [2 3 4 5] TEST: [0 1]\n",
            "[[ 5  6]\n",
            " [ 7  8]\n",
            " [ 9 10]\n",
            " [11 12]] [[1 2]\n",
            " [3 4]] [1 2 1 1] [1 2]\n",
            "TRAIN: [0 1 3 4 5] TEST: [2]\n",
            "[[ 1  2]\n",
            " [ 3  4]\n",
            " [ 7  8]\n",
            " [ 9 10]\n",
            " [11 12]] [[5 6]] [1 2 2 1 1] [1]\n",
            "TRAIN: [0 1 2 5] TEST: [3 4]\n",
            "[[ 1  2]\n",
            " [ 3  4]\n",
            " [ 5  6]\n",
            " [11 12]] [[ 7  8]\n",
            " [ 9 10]] [1 2 1 1] [2 1]\n",
            "TRAIN: [0 1 2 3 4] TEST: [5]\n",
            "[[ 1  2]\n",
            " [ 3  4]\n",
            " [ 5  6]\n",
            " [ 7  8]\n",
            " [ 9 10]] [[11 12]] [1 2 1 2 1] [1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# example of stratified group Kfold　見本\n",
        "# 今回のケースでは、groupがID、yがclassesに該当\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedGroupKFold\n",
        "X = np.ones((17, 2))\n",
        "y = np.array([0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
        "groups = np.array([1, 1, 2, 2, 3, 3, 3, 4, 5, 5, 5, 5, 6, 6, 7, 8, 8])\n",
        "cv = StratifiedGroupKFold(n_splits=3)\n",
        "\n",
        "print(X)\n",
        "print(y)\n",
        "print(groups)\n",
        "\n",
        "for train_idxs, test_idxs in cv.split(X, y, groups):\n",
        "    print(\"TRAIN:\", groups[train_idxs])\n",
        "    print(\"      \", y[train_idxs])\n",
        "    print(\" TEST:\", groups[test_idxs])\n",
        "    print(\"      \", y[test_idxs])"
      ],
      "metadata": {
        "id": "ExOzNLzIIi2a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# one group leave out \n",
        "# https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.LeaveOneGroupOut.html#sklearn.model_selection.LeaveOneGroupOut\n",
        "# 今回のケースでは、groupがIDに該当\n",
        "import numpy as np\n",
        "from sklearn.model_selection import LeaveOneGroupOut\n",
        "X = np.array([[1, 2], [3, 4], [5, 6], [7, 8], [9, 10], [11, 12]])\n",
        "y = np.array([1, 2, 1, 2, 1, 1])\n",
        "groups = np.array([1, 1, 2, 3, 3, 4])\n",
        "logo = LeaveOneGroupOut()\n",
        "logo.get_n_splits(X, y, groups)\n",
        "logo.get_n_splits(groups=groups)  # 'groups' is always required\n",
        "print(logo)\n",
        "LeaveOneGroupOut()\n",
        "for train_index, test_index in logo.split(X, y, groups):\n",
        "     print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
        "     X_train, X_test = X[train_index], X[test_index]\n",
        "     y_train, y_test = y[train_index], y[test_index]\n",
        "     print(X_train, X_test, y_train, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nBJvTB_5TKqO",
        "outputId": "fcd4f0b2-083f-4a88-da6a-f2d3a071e17d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LeaveOneGroupOut()\n",
            "TRAIN: [2 3 4 5] TEST: [0 1]\n",
            "[[ 5  6]\n",
            " [ 7  8]\n",
            " [ 9 10]\n",
            " [11 12]] [[1 2]\n",
            " [3 4]] [1 2 1 1] [1 2]\n",
            "TRAIN: [0 1 3 4 5] TEST: [2]\n",
            "[[ 1  2]\n",
            " [ 3  4]\n",
            " [ 7  8]\n",
            " [ 9 10]\n",
            " [11 12]] [[5 6]] [1 2 2 1 1] [1]\n",
            "TRAIN: [0 1 2 5] TEST: [3 4]\n",
            "[[ 1  2]\n",
            " [ 3  4]\n",
            " [ 5  6]\n",
            " [11 12]] [[ 7  8]\n",
            " [ 9 10]] [1 2 1 1] [2 1]\n",
            "TRAIN: [0 1 2 3 4] TEST: [5]\n",
            "[[ 1  2]\n",
            " [ 3  4]\n",
            " [ 5  6]\n",
            " [ 7  8]\n",
            " [ 9 10]] [[11 12]] [1 2 1 2 1] [1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "pFKghBCLiuK2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}